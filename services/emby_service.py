import os
import json
import re
import time
import asyncio
import httpx
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from config import Settings
import importlib
from urllib.parse import urlencode, quote

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

class EmbyRefreshItem:
    """è¡¨ç¤ºéœ€è¦åˆ·æ–°çš„Embyé¡¹ç›®"""
    def __init__(self, strm_path: str, timestamp: float = None, retry_count: int = 0, media_info: dict = None):
        self.strm_path = strm_path  # STRMæ–‡ä»¶è·¯å¾„
        self.timestamp = timestamp or time.time()  # è®¡åˆ’åˆ·æ–°æ—¶é—´
        self.retry_count = retry_count  # é‡è¯•æ¬¡æ•°
        self.item_id = None  # Embyä¸­çš„ItemIDï¼Œå¦‚æœæ‰¾åˆ°
        self.status = "pending"  # çŠ¶æ€ï¼špending, processing, success, failed
        self.last_error = None  # æœ€åçš„é”™è¯¯ä¿¡æ¯
        self.next_retry_time = self.timestamp  # ä¸‹æ¬¡é‡è¯•æ—¶é—´
        self.media_info = media_info or {}  # åª’ä½“ä¿¡æ¯ï¼ŒåŒ…å«åŸå§‹è·¯å¾„ã€æ–‡ä»¶åç­‰

    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸ï¼Œç”¨äºåºåˆ—åŒ–"""
        return {
            "strm_path": self.strm_path,
            "timestamp": self.timestamp,
            "retry_count": self.retry_count,
            "item_id": self.item_id,
            "status": self.status,
            "last_error": self.last_error,
            "next_retry_time": getattr(self, "next_retry_time", self.timestamp),
            "media_info": self.media_info
        }

    @classmethod
    def from_dict(cls, data: Dict) -> 'EmbyRefreshItem':
        """ä»å­—å…¸åˆ›å»ºå®ä¾‹ï¼Œç”¨äºååºåˆ—åŒ–"""
        item = cls(
            strm_path=data["strm_path"],
            timestamp=data.get("timestamp", time.time()),
            retry_count=data.get("retry_count", 0),
            media_info=data.get("media_info", {})
        )
        item.item_id = data.get("item_id")
        item.status = data.get("status", "pending")
        item.last_error = data.get("last_error")
        item.next_retry_time = data.get("next_retry_time", item.timestamp)
        return item

class EmbyService:
    """EmbyæœåŠ¡ï¼Œç”¨äºä¸Emby APIé€šä¿¡å’Œåˆ·æ–°å…ƒæ•°æ®"""
    
    def __init__(self):
        """åˆå§‹åŒ–EmbyæœåŠ¡"""
        # ä»é…ç½®è·å–è®¾ç½®
        self.settings = Settings()
        self.emby_url = self.settings.emby_api_url
        self.api_key = self.settings.emby_api_key
        self.strm_root_path = self.settings.strm_root_path
        self.emby_root_path = self.settings.emby_root_path
        self.emby_enabled = self.settings.emby_enabled
        
        # éªŒè¯å¿…è¦çš„é…ç½®
        if not self.emby_url or not self.api_key:
            logger.warning("Embyé…ç½®ä¸å®Œæ•´ï¼ŒæœåŠ¡å°†ä¸å¯ç”¨")
            self.emby_enabled = False
        
        # åˆ›å»ºç¼“å­˜ç›®å½•
        cache_dir = "/app/cache"
        os.makedirs(cache_dir, exist_ok=True)
        
        # åˆ·æ–°é˜Ÿåˆ—
        self.refresh_queue: List[EmbyRefreshItem] = []
        self.queue_file = Path(os.path.join(cache_dir, "emby_refresh_queue.json"))
        
        # åŠ è½½åˆ·æ–°é˜Ÿåˆ—
        self._load_refresh_queue()
        
        # æ ‡å¿—ä½
        self._is_processing = False
        self._stop_flag = False
        
        # åˆ·æ–°ä»»åŠ¡çš„é…ç½® - å¢åŠ å»¶è¿Ÿï¼Œç»™Embyæ›´å¤šæ—¶é—´æ‰«æ
        self.initial_delay = 1800  # 30åˆ†é’Ÿ
        self.retry_delays = [3600, 7200, 14400, 28800]  # 1å°æ—¶, 2å°æ—¶, 4å°æ—¶, 8å°æ—¶
        self.max_retries = len(self.retry_delays)
        
        # åª’ä½“è·¯å¾„åˆ°Emby IDçš„æ˜ å°„ç¼“å­˜
        self.path_to_id_cache = {}
        self.cache_file = Path(os.path.join(cache_dir, "emby_path_cache.json"))
        self._load_path_cache()
        
        # è·Ÿè¸ªæœ€è¿‘ä¸€æ¬¡åˆ·æ–°çš„é¡¹ç›®
        self.last_refresh_items = []
        self.last_refresh_time = None
        self.last_refresh_file = Path(os.path.join(cache_dir, "emby_last_refresh.json"))
        self._load_last_refresh()
    
    def _load_refresh_queue(self):
        """ä»æ–‡ä»¶åŠ è½½åˆ·æ–°é˜Ÿåˆ—"""
        try:
            # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(self.queue_file), exist_ok=True)
            
            if self.queue_file.exists():
                with open(self.queue_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.refresh_queue = [EmbyRefreshItem.from_dict(item) for item in data]
                logger.info(f"å·²åŠ è½½åˆ·æ–°é˜Ÿåˆ—ï¼Œå…±{len(self.refresh_queue)}ä¸ªé¡¹ç›®")
            else:
                self.refresh_queue = []
                logger.info("åˆ·æ–°é˜Ÿåˆ—æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°é˜Ÿåˆ—")
        except Exception as e:
            logger.error(f"åŠ è½½åˆ·æ–°é˜Ÿåˆ—å¤±è´¥: {e}")
            self.refresh_queue = []
    
    def _save_refresh_queue(self):
        """ä¿å­˜åˆ·æ–°é˜Ÿåˆ—åˆ°æ–‡ä»¶"""
        try:
            # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(self.queue_file), exist_ok=True)
            
            data = [item.to_dict() for item in self.refresh_queue]
            with open(self.queue_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            logger.debug(f"å·²ä¿å­˜åˆ·æ–°é˜Ÿåˆ—ï¼Œå…±{len(self.refresh_queue)}ä¸ªé¡¹ç›®")
        except Exception as e:
            logger.error(f"ä¿å­˜åˆ·æ–°é˜Ÿåˆ—å¤±è´¥: {e}")
    
    def add_to_refresh_queue(self, strm_path: str, media_info: dict = None):
        """æ·»åŠ STRMæ–‡ä»¶åˆ°åˆ·æ–°é˜Ÿåˆ—"""
        # å¦‚æœEmbyåŠŸèƒ½æœªå¼€å¯ï¼Œä¸æ·»åŠ åˆ°é˜Ÿåˆ—
        if not self.emby_enabled:
            logger.debug(f"Embyåˆ·åº“åŠŸèƒ½æœªå¯ç”¨ï¼Œä¸æ·»åŠ åˆ°åˆ·æ–°é˜Ÿåˆ—")
            return
            
        try:
            # è§„èŒƒåŒ–è·¯å¾„æ ¼å¼ï¼Œç¡®ä¿Windowså’ŒLinuxè·¯å¾„æ ¼å¼ä¸€è‡´
            strm_path = str(strm_path).replace('\\', '/')
            # è®°å½•è¯¦ç»†çš„æ–‡ä»¶ä¿¡æ¯
            file_exists = os.path.exists(strm_path)
            logger.debug(f"æ·»åŠ åˆ°åˆ·æ–°é˜Ÿåˆ—: {strm_path}")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™è®°å½•è­¦å‘Šä½†ä»å°è¯•æ·»åŠ åˆ°é˜Ÿåˆ—
            if not file_exists:
                logger.warning(f"STRMæ–‡ä»¶ä¸å­˜åœ¨: {strm_path}ï¼Œä½†ä»å°†æ·»åŠ åˆ°é˜Ÿåˆ—")
                
            # æ£€æŸ¥æ˜¯å¦å·²åœ¨é˜Ÿåˆ—ä¸­
            duplicate = False
            for item in self.refresh_queue:
                if item.strm_path == strm_path and item.status in ["pending", "processing"]:
                    logger.debug(f"STRMæ–‡ä»¶å·²åœ¨åˆ·æ–°é˜Ÿåˆ—ä¸­: {strm_path}")
                    duplicate = True
                    break
                    
            if duplicate:
                return
            
            # åˆ†ææ–‡ä»¶ä»¥è·å–æ›´å¤šè°ƒè¯•ä¿¡æ¯
            filename = os.path.basename(strm_path)
            dirname = os.path.dirname(strm_path)
            
            # è¡¥å……åª’ä½“ä¿¡æ¯(å¦‚æœæœªæä¾›)
            if not media_info:
                media_info = {
                    "path": strm_path,
                    "filename": filename,
                    "dirname": dirname,
                    "created_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                }
            
            # å°è¯•ä»æ–‡ä»¶åä¸­è§£æåª’ä½“ä¿¡æ¯
            if not media_info.get("title"):
                name_without_ext = os.path.splitext(filename)[0]
                media_info["title"] = name_without_ext
            
            # æ·»åŠ åˆ°é˜Ÿåˆ—ï¼Œè®¾ç½®å»¶è¿Ÿæ—¶é—´
            refresh_time = time.time() + self.initial_delay
            next_time_str = datetime.fromtimestamp(refresh_time).strftime('%Y-%m-%d %H:%M:%S')
            logger.debug(f"è®¡åˆ’åˆ·æ–°æ—¶é—´: {next_time_str}")
            
            item = EmbyRefreshItem(strm_path, refresh_time, 0, media_info)
            self.refresh_queue.append(item)
            
            # ä¿å­˜é˜Ÿåˆ—
            self._save_refresh_queue()
            
        except Exception as e:
            logger.error(f"æ·»åŠ STRMæ–‡ä»¶åˆ°åˆ·æ–°é˜Ÿåˆ—æ—¶å‡ºé”™: {strm_path}, é”™è¯¯: {str(e)}")
            # è®°å½•å¼‚å¸¸å †æ ˆ
            import traceback
            logger.error(f"å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
    
    def convert_to_emby_path(self, strm_path: str) -> str:
        """å°†STRMæ–‡ä»¶è·¯å¾„è½¬æ¢ä¸ºEmbyä¸­çš„è·¯å¾„"""
        # ç»Ÿä¸€è·¯å¾„æ ¼å¼ï¼šä½¿ç”¨æ­£æ–œæ ï¼Œå»é™¤æœ«å°¾æ–œæ 
        strm_path = strm_path.replace('\\', '/')
        strm_root = self.strm_root_path.replace('\\', '/')
        emby_root = self.emby_root_path.replace('\\', '/')
        
        # å»é™¤è·¯å¾„æœ«å°¾çš„æ–œæ 
        strm_root = strm_root.rstrip('/')
        emby_root = emby_root.rstrip('/')
        
        # æ ‡å‡†åŒ–è·¯å¾„ï¼ˆç¡®ä¿å¤„ç†å„ç§è·¯å¾„æ ¼å¼ï¼‰
        normalized_strm_path = '/' + strm_path.lstrip('/')
        normalized_strm_root = '/' + strm_root.lstrip('/')
        
        # ç›´æ¥æ›¿æ¢æ ¹è·¯å¾„éƒ¨åˆ†
        if normalized_strm_path.startswith(normalized_strm_root):
            # æå–ç›¸å¯¹è·¯å¾„
            relative_path = normalized_strm_path[len(normalized_strm_root):].lstrip('/')
            emby_path = f"{emby_root}/{relative_path}"
            return emby_path
        
        # å°è¯•ä»è·¯å¾„æå–åª’ä½“ç›¸å¯¹è·¯å¾„
        try:
            # åˆ†æè·¯å¾„ç»“æ„
            strm_parts = strm_path.split('/')
            # æŸ¥æ‰¾å¸¸è§åª’ä½“ç±»å‹ç›®å½•å
            media_types = ['ç”µå½±', 'ç”µè§†å‰§', 'åŠ¨æ¼«', 'Movies', 'TV Shows', 'Anime']
            
            for idx, part in enumerate(strm_parts):
                if part in media_types and idx < len(strm_parts) - 1:
                    # æ‰¾åˆ°åª’ä½“ç±»å‹ç›®å½•ï¼Œå–å…¶åçš„è·¯å¾„ä½œä¸ºç›¸å¯¹è·¯å¾„
                    relative_path = '/'.join(strm_parts[idx:])
                    emby_path = f"{emby_root}/{relative_path}"
                    return emby_path
            
            # æœ€åå°è¯•ï¼šå¦‚æœæ˜¯å¤šå±‚è·¯å¾„ï¼Œå°è¯•ä½¿ç”¨æœ€å2-3å±‚
            if len(strm_parts) >= 3:
                # å–æœ€å3å±‚è·¯å¾„ï¼ˆé€šå¸¸æ˜¯åª’ä½“ç±»å‹/æ ‡é¢˜/æ–‡ä»¶ï¼‰
                relative_path = '/'.join(strm_parts[-3:])
                emby_path = f"{emby_root}/{relative_path}"
                return emby_path
                
            # å¦‚æœæ‰€æœ‰å°è¯•éƒ½å¤±è´¥ï¼Œè¿”å›åŸå§‹è·¯å¾„
            logger.warning(f"æ— æ³•è½¬æ¢è·¯å¾„ï¼Œä½¿ç”¨åŸå§‹è·¯å¾„: {strm_path}")
            return strm_path
        except Exception as e:
            logger.error(f"è·¯å¾„è½¬æ¢å¤±è´¥: {str(e)}")
            return strm_path
    
    def parse_media_info_from_path(self, path: str) -> Dict[str, Any]:
        """ä»è·¯å¾„è§£æåª’ä½“ä¿¡æ¯"""
        import re
        
        path = Path(path)
        filename = path.name
        parent = path.parent.name
        
        info = {
            "type": None,  # movie, series, episode
            "title": None,
            "year": None,
            "season": None,
            "episode": None
        }
        
        # ç§»é™¤æ‰©å±•å
        name_without_ext = os.path.splitext(filename)[0]
        
        # å°è¯•è¯†åˆ«ç”µè§†å‰§æ ¼å¼ (ä¾‹å¦‚: "Show Name - S01E01 - Episode Title.strm")
        tv_match = re.search(r'(.+?)\s*-\s*S(\d+)E(\d+)(?:\s*-\s*(.+))?', name_without_ext)
        if tv_match:
            info["type"] = "episode"
            info["title"] = tv_match.group(1).strip()
            info["season"] = int(tv_match.group(2))
            info["episode"] = int(tv_match.group(3))
            if tv_match.group(4):
                info["episode_title"] = tv_match.group(4).strip()
            return info
        
        # å°è¯•è¯†åˆ«ç”µå½±æ ¼å¼ (ä¾‹å¦‚: "Movie Name (2020).strm")
        movie_match = re.search(r'(.+?)(?:\s*\((\d{4})\))?$', name_without_ext)
        if movie_match:
            info["type"] = "movie"
            info["title"] = movie_match.group(1).strip()
            if movie_match.group(2):
                info["year"] = int(movie_match.group(2))
            
            # æ£€æŸ¥çˆ¶ç›®å½•æ˜¯å¦åŒ…å«å¹´ä»½ï¼Œå¦‚æœæ–‡ä»¶åæ²¡æœ‰
            if not info["year"] and re.search(r'\(\d{4}\)', parent):
                year_match = re.search(r'\((\d{4})\)', parent)
                if year_match:
                    info["year"] = int(year_match.group(1))
        
        return info
    
    async def query_item_by_path(self, path: str) -> Optional[Dict]:
        """é€šè¿‡è·¯å¾„æŸ¥è¯¢Embyä¸­çš„åª’ä½“é¡¹"""
        try:
            # ç¡®ä¿emby_urlæ˜¯åˆæ³•çš„URL
            if not self.emby_url or not self.emby_url.startswith(('http://', 'https://')):
                logger.error(f"æ— æ•ˆçš„Emby API URL: {self.emby_url}")
                return None
            
            # URLç¼–ç è·¯å¾„
            from urllib.parse import quote
            encoded_path = quote(path)
            
            # æ„å»ºAPI URL
            url = f"{self.emby_url}/Items"
            params = {
                "Path": encoded_path,  # ä½¿ç”¨ç¼–ç åçš„è·¯å¾„
                "api_key": self.api_key
            }
            
            # å‘é€è¯·æ±‚
            async with httpx.AsyncClient() as client:
                response = await client.get(url, params=params, timeout=30)
                
                if response.status_code == 200:
                    data = response.json()
                    if data.get("Items") and len(data["Items"]) > 0:
                        return data["Items"][0]
                    else:
                        return None
                else:
                    logger.error(f"æŸ¥è¯¢è·¯å¾„å¤±è´¥: {path}, çŠ¶æ€ç : {response.status_code}")
                    return None
            
            return None
        except Exception as e:
            logger.error(f"æŸ¥è¯¢Embyé¡¹ç›®å¤±è´¥: {path}, é”™è¯¯: {str(e)}")
            return None
    
    async def search_items_by_info(self, media_info: Dict[str, Any]) -> List[Dict]:
        """é€šè¿‡åª’ä½“ä¿¡æ¯æœç´¢Embyä¸­çš„é¡¹ç›®"""
        try:
            # ç¡®ä¿emby_urlæ˜¯åˆæ³•çš„URL
            if not self.emby_url or not self.emby_url.startswith(('http://', 'https://')):
                logger.error(f"æ— æ•ˆçš„Emby API URL: {self.emby_url}")
                return []
            
            # æ„å»ºAPI URLå’Œå‚æ•°
            url = f"{self.emby_url}/Items"
            params = {"api_key": self.api_key}
            
            # æ ¹æ®åª’ä½“ç±»å‹æ·»åŠ ä¸åŒçš„æŸ¥è¯¢å‚æ•°
            if media_info["type"] == "episode" and media_info.get("title") and media_info.get("season") and media_info.get("episode"):
                params["SearchTerm"] = media_info["title"]
                params["IncludeItemTypes"] = "Episode"
                params["RecursiveItemTypes"] = "true"
                
            elif media_info["type"] == "movie" and media_info.get("title"):
                params["SearchTerm"] = media_info["title"]
                params["IncludeItemTypes"] = "Movie"
                
                if media_info.get("year"):
                    params["Years"] = str(media_info["year"])
            else:
                logger.debug(f"åª’ä½“ä¿¡æ¯ä¸å®Œæ•´æˆ–ç±»å‹ä¸æ”¯æŒ: {media_info}")
                return []
            
            logger.debug(f"æœç´¢Embyé¡¹ç›®: URL={url}, å‚æ•°={params}")
            
            # å‘é€è¯·æ±‚
            async with httpx.AsyncClient() as client:
                response = await client.get(url, params=params, timeout=30)
                
                if response.status_code == 200:
                    data = response.json()
                    items = data.get("Items", [])
                    if items:
                        logger.info(f"æœç´¢åˆ° {len(items)} ä¸ªåŒ¹é…é¡¹: {media_info.get('title', '')}")
                    return items
                else:
                    logger.error(f"æœç´¢åª’ä½“å¤±è´¥, çŠ¶æ€ç : {response.status_code}, å“åº”: {response.text[:200]}")
            
            return []
        except Exception as e:
            logger.error(f"æœç´¢Embyé¡¹ç›®å¤±è´¥, é”™è¯¯: {str(e)}")
            return []
    
    def find_best_match(self, items: List[Dict], strm_path: str) -> Optional[Dict]:
        """ä»æœç´¢ç»“æœä¸­æ‰¾åˆ°æœ€åŒ¹é…çš„é¡¹ç›®"""
        if not items:
            return None
        
        # è§£æSTRMè·¯å¾„ä¸­çš„åª’ä½“ä¿¡æ¯
        media_info = self.parse_media_info_from_path(strm_path)
        
        best_score = 0
        best_item = None
        
        for item in items:
            score = 0
            
            # å¯¹ç”µè§†å‰§é›†è¿›è¡ŒåŒ¹é…
            if media_info["type"] == "episode":
                if item.get("Type") == "Episode":
                    # æ£€æŸ¥å­£å’Œé›†æ˜¯å¦åŒ¹é…
                    if item.get("ParentIndexNumber") == media_info.get("season") and item.get("IndexNumber") == media_info.get("episode"):
                        score += 50
                    
                    # æ£€æŸ¥æ ‡é¢˜æ˜¯å¦åŒ¹é…
                    if media_info.get("episode_title") and media_info["episode_title"].lower() in item.get("Name", "").lower():
                        score += 30
            
            # å¯¹ç”µå½±è¿›è¡ŒåŒ¹é…
            elif media_info["type"] == "movie":
                if item.get("Type") == "Movie":
                    # æ£€æŸ¥æ ‡é¢˜
                    if media_info["title"].lower() in item.get("Name", "").lower():
                        score += 40
                    
                    # æ£€æŸ¥å¹´ä»½
                    if media_info.get("year") and item.get("ProductionYear") == media_info["year"]:
                        score += 40
            
            # æ›´æ–°æœ€ä½³åŒ¹é…
            if score > best_score:
                best_score = score
                best_item = item
        
        # è¦æ±‚æœ€ä½åŒ¹é…åˆ†æ•°
        if best_score >= 40:
            return best_item
        
        return None
    
    async def search_by_name(self, name: str) -> List[Dict]:
        """é€šè¿‡åç§°æœç´¢Embyåª’ä½“é¡¹ç›®"""
        try:
            # ç©ºç™½æ£€æŸ¥
            if not name or len(name.strip()) < 2:
                logger.warning(f"æœç´¢åç§°å¤ªçŸ­æˆ–ä¸ºç©º: '{name}'")
                return []
                
            # é¢„å¤„ç†åç§°ï¼Œå»é™¤å¸¸è§çš„å™ªéŸ³å­—ç¬¦
            original_name = name
            name = name.replace('.', ' ').replace('_', ' ')  # æ›¿æ¢å¸¸è§åˆ†éš”ç¬¦ä¸ºç©ºæ ¼
            name = re.sub(r'\s+', ' ', name).strip()  # åˆå¹¶å¤šä¸ªç©ºæ ¼å¹¶å»é™¤é¦–å°¾ç©ºæ ¼
            
            # ç¡®ä¿emby_urlæ˜¯åˆæ³•çš„URL
            if not self.emby_url or not self.emby_url.startswith(('http://', 'https://')):
                logger.error(f"æ— æ•ˆçš„Emby API URL: {self.emby_url}")
                return []
            
            # æ„å»ºæœç´¢API URL
            base_url = self.emby_url.rstrip('/')
            url = f"{base_url}/Items"
            
            # URLç¼–ç æœç´¢åç§°
            encoded_name = quote(name)
            
            params = {
                "api_key": self.api_key,
                "SearchTerm": encoded_name,
                "Recursive": "true",
                "IncludeItemTypes": "Movie,Series,Episode,Season",
                "Limit": 15,  # å¢åŠ è¿”å›æ•°é‡
                "Fields": "Path,ParentId,Overview,ProductionYear",
                "EnableTotalRecordCount": "false"  # æé«˜æ€§èƒ½
            }
            
            # å‘é€è¯·æ±‚
            async with httpx.AsyncClient() as client:
                response = await client.get(url, params=params, timeout=30)
                
                if response.status_code == 200:
                    data = response.json()
                    items = data.get("Items", [])
                    return items
                else:
                    logger.error(f"æœç´¢å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                    return []
            
            return []
        except Exception as e:
            logger.error(f"æœç´¢'{name}'å¤±è´¥: {str(e)}")
            return []
    
    async def find_episode_by_info(self, series_name: str, season_num: int, episode_num: int) -> Optional[Dict]:
        """é€šè¿‡ç³»åˆ—åç§°å’Œé›†æ•°æŸ¥æ‰¾å‰§é›†"""
        try:
            logger.debug(f"æŸ¥æ‰¾å‰§é›†: {series_name} S{season_num:02d}E{episode_num:02d}")
            
            # é¦–å…ˆæœç´¢ç³»åˆ—
            series_items = await self.search_by_name(series_name)
            series_id = None
            
            # æ‰¾åˆ°åŒ¹é…çš„ç³»åˆ—
            for item in series_items:
                if item.get("Type") == "Series":
                    item_name = item.get("Name", "").lower()
                    search_name = series_name.lower()
                    
                    # æ·»åŠ åç§°æ¨¡ç³ŠåŒ¹é…
                    if item_name == search_name or search_name in item_name or item_name in search_name:
                        series_id = item.get("Id")
                        logger.debug(f"æ‰¾åˆ°åŒ¹é…çš„ç³»åˆ—: {item.get('Name')}")
                        break
            
            if not series_id:
                logger.debug(f"æœªæ‰¾åˆ°ç³»åˆ—: {series_name}")
                return None
            
            # æ„å»ºåŸºç¡€URL
            base_url = self.emby_url
            if base_url.endswith('/'):
                base_url = base_url[:-1]  # ç§»é™¤æœ«å°¾çš„æ–œæ 
                
            # æŸ¥æ‰¾è¯¥ç³»åˆ—çš„å­£
            try:
                # ä¿®å¤URLæ‹¼æ¥ 
                url = f"{base_url}/Shows/{series_id}/Seasons"
                params = {"api_key": self.api_key}
                
                async with httpx.AsyncClient() as client:
                    response = await client.get(url, params=params, timeout=30)
                    
                    if response.status_code != 200:
                        logger.error(f"è·å–å­£å¤±è´¥: çŠ¶æ€ç ={response.status_code}")
                        return None
                    
                    seasons_data = response.json()
                    seasons = seasons_data.get("Items", [])
                    
                    # æ‰¾åˆ°å¯¹åº”çš„å­£
                    season_id = None
                    for season in seasons:
                        if season.get("IndexNumber") == season_num:
                            season_id = season.get("Id")
                            logger.debug(f"æ‰¾åˆ°å­£: {season.get('Name')}")
                            break
            except Exception as e:
                logger.error(f"è·å–å­£åˆ—è¡¨å¤±è´¥: {str(e)}")
                return None
            
            if not season_id:
                logger.debug(f"æœªæ‰¾åˆ°å­£: {series_name} S{season_num:02d}ï¼Œå°è¯•ä½¿ç”¨ç¬¬ä¸€ä¸ªå­£")
                if seasons:
                    season_id = seasons[0].get("Id")
                else:
                    return None
            
            # æŸ¥æ‰¾è¯¥å­£çš„é›†
            try:
                # ä¿®å¤URLæ‹¼æ¥
                url = f"{base_url}/Shows/{series_id}/Episodes"
                params = {
                    "api_key": self.api_key,
                    "SeasonId": season_id
                }
                
                async with httpx.AsyncClient() as client:
                    response = await client.get(url, params=params, timeout=30)
                    
                    if response.status_code != 200:
                        logger.error(f"è·å–å‰§é›†å¤±è´¥: çŠ¶æ€ç ={response.status_code}")
                        return None
                    
                    episodes_data = response.json()
                    episodes = episodes_data.get("Items", [])
                    
                    # æ‰¾åˆ°å¯¹åº”çš„é›†
                    for episode in episodes:
                        if episode.get("IndexNumber") == episode_num:
                            logger.debug(f"æ‰¾åˆ°å‰§é›†: {episode.get('Name')}")
                            return episode
            except Exception as e:
                logger.error(f"è·å–å‰§é›†åˆ—è¡¨å¤±è´¥: {str(e)}")
                return None
            
            logger.debug(f"æœªæ‰¾åˆ°å‰§é›†: {series_name} S{season_num:02d}E{episode_num:02d}")
            return None
        except Exception as e:
            logger.error(f"æŸ¥æ‰¾å‰§é›†å¤±è´¥: {str(e)}")
            return None
    
    async def find_emby_item(self, strm_path: str) -> Optional[Dict]:
        """æŸ¥æ‰¾Embyä¸­å¯¹åº”äºSTRMæ–‡ä»¶çš„åª’ä½“é¡¹"""
        try:
            # ä¿å­˜åŸå§‹è·¯å¾„ç”¨äºå¤‡ç”¨æ–¹æ¡ˆ
            original_path = strm_path
            
            # å°è¯•æ–¹æ¡ˆ1ï¼šé€šè¿‡è·¯å¾„ç›´æ¥æŸ¥è¯¢
            try:
                emby_path = self.convert_to_emby_path(strm_path)
                if emby_path:
                    item = await self.query_item_by_path(emby_path)
                    if item:
                        return item
            except Exception as e:
                pass
            
            # å°è¯•æ–¹æ¡ˆ2ï¼šä»STRMæå–åª’ä½“ä¿¡æ¯å¹¶æœç´¢
            try:
                media_info = await self.extract_media_name_from_strm(strm_path)
                
                if media_info.get("type") == "Episode" and media_info.get("series_name"):
                    episode = await self.find_episode_by_info(
                        media_info.get("series_name", ""),
                        media_info.get("season", 1),
                        media_info.get("episode", 1)
                    )
                    
                    if episode:
                        return episode
                    
                elif media_info.get("type") == "Movie" and media_info.get("title"):
                    title = media_info.get("title", "")
                    year = media_info.get("year", None)
                    search_text = f"{title}" if not year else f"{title} {year}"
                    
                    items = await self.search_by_name(search_text)
                    
                    if items:
                        # ç­›é€‰ç”µå½±ç±»å‹çš„ç»“æœ
                        movie_items = [item for item in items if item.get("Type") == "Movie"]
                        if movie_items:
                            # å¦‚æœæœ‰å¹´ä»½ï¼Œä¼˜å…ˆåŒ¹é…å¹´ä»½ç›¸åŒçš„ç”µå½±
                            if year:
                                exact_year_items = [item for item in movie_items if item.get("ProductionYear") == year]
                                if exact_year_items:
                                    return exact_year_items[0]
                            
                            # è¿”å›ç¬¬ä¸€ä¸ªåŒ¹é…çš„ç”µå½±
                            return movie_items[0]
            except Exception as e:
                pass
            
            # å°è¯•æ–¹æ¡ˆ3ï¼šä½¿ç”¨æ–‡ä»¶åå’Œç›®å½•åè¿›è¡Œå¤šç§ç»„åˆæœç´¢
            try:
                filename = os.path.basename(strm_path)
                name_without_ext = os.path.splitext(filename)[0]
                parent_dir = os.path.dirname(strm_path)
                parent_name = os.path.basename(parent_dir)
                
                # å°è¯•å¤šç§æœç´¢ç»„åˆ
                search_terms = [
                    name_without_ext,  # æ–‡ä»¶å
                    parent_name,       # çˆ¶ç›®å½•å
                ]
                
                # å¦‚æœæ–‡ä»¶ååŒ…å« S00E00 æ ¼å¼ï¼Œæå–ç³»åˆ—å
                series_match = re.search(r'^(.+?)\s*-\s*S\d+E\d+', name_without_ext)
                if series_match:
                    search_terms.append(series_match.group(1).strip())
                
                # å¦‚æœçˆ¶ç›®å½•æ˜¯å­£ç›®å½•ï¼Œä½¿ç”¨ç¥–çˆ¶ç›®å½•ä½œä¸ºç³»åˆ—å
                if re.search(r'^(?:Season\s*\d+|S\d+|ç¬¬.+?å­£)$', parent_name, re.IGNORECASE):
                    grandparent_dir = os.path.dirname(parent_dir)
                    grandparent_name = os.path.basename(grandparent_dir)
                    search_terms.append(grandparent_name)
                
                # æœç´¢ä¸åŒçš„åç§°ç»„åˆ
                for term in search_terms:
                    if not term or len(term) < 2:
                        continue
                        
                    items = await self.search_by_name(term)
                    if items:
                        return items[0]
            except Exception as e:
                pass
            
            # å°è¯•æ–¹æ¡ˆ4ï¼šä½¿ç”¨è·¯å¾„çš„ç›¸ä¼¼æ€§æœç´¢
            try:
                # å°†strmè·¯å¾„åˆ†è§£ä¸ºç›®å½•å’Œæ–‡ä»¶å
                filename = os.path.basename(strm_path)
                dirname = os.path.dirname(strm_path)
            except Exception as e:
                pass
            
            # å¦‚æœä¸Šè¿°æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œå°è¯•æœ€åçš„æ–¹æ³•ï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–ç®€åŒ–åç§°è¿›è¡Œæœç´¢
            try:
                filename = os.path.basename(strm_path)
                name_without_ext = os.path.splitext(filename)[0]
                
                # ç§»é™¤å¸¸è§çš„æ ¼å¼æ ‡è®°å’Œæ— å…³å­—ç¬¦ï¼Œåªä¿ç•™å…³é”®æ ‡é¢˜
                simplified_name = re.sub(r'\s*-\s*.*$', '', name_without_ext)  # ç§»é™¤ - ä¹‹åçš„å†…å®¹
                simplified_name = re.sub(r'\s*\(.*\)', '', simplified_name)    # ç§»é™¤æ‹¬å·å†…å®¹
                simplified_name = re.sub(r'\s*\[.*\]', '', simplified_name)    # ç§»é™¤æ–¹æ‹¬å·å†…å®¹
                simplified_name = re.sub(r'\s*\d+p\s*', '', simplified_name)   # ç§»é™¤åˆ†è¾¨ç‡
                simplified_name = re.sub(r'\s+', ' ', simplified_name)         # åˆå¹¶ç©ºæ ¼
                simplified_name = simplified_name.strip()
                
                if simplified_name and len(simplified_name) >= 3 and simplified_name != name_without_ext:
                    items = await self.search_by_name(simplified_name)
                    if items:
                        return items[0]
            except Exception as e:
                pass
            
            logger.warning(f"æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œæ— æ³•æ‰¾åˆ°Embyé¡¹ç›®: {strm_path}")
            return None
        except Exception as e:
            logger.error(f"æŸ¥æ‰¾Embyé¡¹ç›®è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}, strmæ–‡ä»¶: {strm_path}")
            return None
    
    async def refresh_emby_item(self, item_id: str) -> bool:
        """åˆ·æ–°Embyä¸­çš„åª’ä½“é¡¹"""
        try:
            # ç¡®ä¿emby_urlæ˜¯åˆæ³•çš„URL
            if not self.emby_url or not self.emby_url.startswith(('http://', 'https://')):
                logger.error(f"æ— æ•ˆçš„Emby API URL: {self.emby_url}")
                return False
            
            # æ„å»ºAPI URL - ä¿®å¤è·¯å¾„é‡å¤é—®é¢˜
            base_url = self.emby_url
            if base_url.endswith('/'):
                base_url = base_url[:-1]  # ç§»é™¤æœ«å°¾çš„æ–œæ 
                
            # æ£€æŸ¥å¹¶è°ƒæ•´APIè·¯å¾„
            url = f"{base_url}/Items/{item_id}/Refresh"
            
            params = {
                "api_key": self.api_key,
                "Recursive": "true",
                "MetadataRefreshMode": "FullRefresh",
                "ImageRefreshMode": "FullRefresh"
            }
            
            logger.debug(f"åˆ·æ–°Embyé¡¹ç›®: ID={item_id}")
            
            # å‘é€è¯·æ±‚
            async with httpx.AsyncClient() as client:
                response = await client.post(url, params=params, timeout=30)
                
                if response.status_code in (200, 204):
                    logger.debug(f"æˆåŠŸåˆ·æ–°Embyé¡¹ç›®: {item_id}")
                    return True
                else:
                    logger.error(f"åˆ·æ–°Embyé¡¹ç›®å¤±è´¥: {item_id}, çŠ¶æ€ç : {response.status_code}")
                    return False
            
            return False
        except Exception as e:
            logger.error(f"åˆ·æ–°Embyé¡¹ç›®å¤±è´¥: {item_id}, é”™è¯¯: {str(e)}")
            return False
    
    async def process_refresh_queue(self):
        """å¤„ç†åˆ·æ–°é˜Ÿåˆ—ä¸­çš„æ¡ç›®"""
        if not self.emby_enabled:
            logger.debug("EmbyæœåŠ¡æœªå¯ç”¨ï¼Œè·³è¿‡å¤„ç†åˆ·æ–°é˜Ÿåˆ—")
            return
        
        if self._is_processing:
            logger.debug("é˜Ÿåˆ—æ­£åœ¨å¤„ç†ä¸­ï¼Œè·³è¿‡")
            return
        
        current_time = time.time()
        self._is_processing = True
        try:
            logger.info("å¼€å§‹å¤„ç†Embyåˆ·æ–°é˜Ÿåˆ—...")
            
            # ç»Ÿè®¡åˆå§‹é˜Ÿåˆ—çŠ¶æ€
            total_items = len(self.refresh_queue)
            pending_items = sum(1 for item in self.refresh_queue if item.status == "pending" and item.timestamp <= current_time)
            
            logger.info(f"å½“å‰é˜Ÿåˆ—å…±æœ‰ {total_items} ä¸ªé¡¹ç›®ï¼Œå…¶ä¸­ {pending_items} ä¸ªå¾…å¤„ç†")
            
            processed_count = 0
            success_count = 0
            for item in self.refresh_queue:
                if self._stop_flag:
                    logger.info("æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œä¸­æ–­é˜Ÿåˆ—å¤„ç†")
                    break
                
                # åªå¤„ç†çŠ¶æ€ä¸ºpendingä¸”æ—¶é—´å·²åˆ°çš„é¡¹ç›®
                if item.status == "pending" and item.timestamp <= current_time:
                    processed_count += 1
                    
                    # æ›´æ–°çŠ¶æ€ä¸ºprocessing
                    item.status = "processing"
                    self._save_refresh_queue()
                    
                    try:
                        # ä¼˜å…ˆä½¿ç”¨å·²æœ‰çš„item_idï¼ˆæ–°æ–¹æ³•ç›´æ¥è·å–äº†IDï¼‰
                        item_id = item.item_id
                        
                        # å¦‚æœæ²¡æœ‰item_idï¼Œå†å°è¯•ä»ç¼“å­˜æˆ–é€šè¿‡æŸ¥æ‰¾è·å–
                        if not item_id:
                            # ä»ç¼“å­˜ä¸­æŸ¥æ‰¾
                            cached_id = self.get_from_path_cache(item.strm_path)
                            if cached_id:
                                logger.debug(f"ä»ç¼“å­˜æ‰¾åˆ°ItemID: {cached_id}")
                                item_id = cached_id
                                item.item_id = item_id
                            else:
                                # åªæœ‰åœ¨ç¼“å­˜ä¸­æ‰¾ä¸åˆ°æ—¶æ‰ä½¿ç”¨find_emby_item
                                logger.debug(f"ç¼“å­˜ä¸­æœªæ‰¾åˆ°ï¼Œå°è¯•æœç´¢Embyé¡¹ç›®: {item.strm_path}")
                                emby_item = await self.find_emby_item(item.strm_path)
                                if emby_item:
                                    item_id = emby_item.get("Id")
                                    item.item_id = item_id
                                    # æ·»åŠ åˆ°ç¼“å­˜
                                    self.add_to_path_cache(
                                        item.strm_path, 
                                        item_id,
                                        emby_item.get("Type"),
                                        emby_item.get("Name")
                                    )
                        
                        # åˆ·æ–°Embyé¡¹ç›®
                        if item_id:
                            refresh_success = await self.refresh_emby_item(item_id)
                            
                            if refresh_success:
                                # åˆ·æ–°æˆåŠŸ
                                item.status = "success"
                                success_count += 1
                                logger.info(f"æˆåŠŸåˆ·æ–°Embyé¡¹ç›®ID: {item_id}")
                            else:
                                # åˆ·æ–°å¤±è´¥ï¼Œè®¾ç½®ä¸ºå¤±è´¥çŠ¶æ€
                                item.status = "failed"
                                item.last_error = "åˆ·æ–°APIè°ƒç”¨å¤±è´¥"
                                
                                # è®¾ç½®ä¸‹æ¬¡é‡è¯•æ—¶é—´
                                if item.retry_count < self.max_retries:
                                    delay = self.retry_delays[item.retry_count]
                                    item.next_retry_time = current_time + delay
                                    logger.warning(f"åˆ·æ–°å¤±è´¥ï¼Œå°†åœ¨ {delay/3600:.1f} å°æ—¶åé‡è¯•: {item.strm_path}")
                                else:
                                    logger.error(f"åˆ·æ–°å¤±è´¥ï¼Œè¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°: {item.strm_path}")
                        else:
                            # æœªæ‰¾åˆ°é¡¹ç›®ï¼Œè®¾ç½®ä¸ºå¤±è´¥çŠ¶æ€
                            item.status = "failed"
                            item.last_error = "æœªæ‰¾åˆ°Embyä¸­çš„åª’ä½“é¡¹ç›®"
                            
                            # è®¾ç½®ä¸‹æ¬¡é‡è¯•æ—¶é—´
                            if item.retry_count < self.max_retries:
                                delay = self.retry_delays[item.retry_count]
                                item.next_retry_time = current_time + delay
                                item.timestamp = item.next_retry_time  # æ›´æ–°è®¡åˆ’æ—¶é—´ä¸ºä¸‹æ¬¡é‡è¯•æ—¶é—´
                                item.retry_count += 1
                                logger.warning(f"æœªæ‰¾åˆ°åª’ä½“é¡¹ç›®ï¼Œå°†åœ¨ {delay/3600:.1f} å°æ—¶åé‡è¯• (ç¬¬{item.retry_count}æ¬¡): {item.strm_path}")
                            else:
                                logger.error(f"æœªæ‰¾åˆ°åª’ä½“é¡¹ç›®ï¼Œè¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä¸å†å°è¯•: {item.strm_path}")
                    
                    except Exception as e:
                        # å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™ï¼Œè®¾ç½®ä¸ºå¤±è´¥çŠ¶æ€
                        item.status = "failed"
                        item.last_error = str(e)
                        
                        # è®¾ç½®ä¸‹æ¬¡é‡è¯•æ—¶é—´
                        if item.retry_count < self.max_retries:
                            delay = self.retry_delays[item.retry_count]
                            item.next_retry_time = current_time + delay
                            item.timestamp = item.next_retry_time  # æ›´æ–°è®¡åˆ’æ—¶é—´ä¸ºä¸‹æ¬¡é‡è¯•æ—¶é—´
                            item.retry_count += 1
                            logger.error(f"å¤„ç†åˆ·æ–°é¡¹ç›®æ—¶å‡ºé”™ï¼Œå°†åœ¨ {delay/3600:.1f} å°æ—¶åé‡è¯• (ç¬¬{item.retry_count}æ¬¡): {item.strm_path}, é”™è¯¯: {str(e)}")
                        else:
                            logger.error(f"å¤„ç†åˆ·æ–°é¡¹ç›®æ—¶å‡ºé”™ï¼Œè¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä¸å†å°è¯•: {item.strm_path}, é”™è¯¯: {str(e)}")
                    
                    # ä¿å­˜é˜Ÿåˆ—
                    self._save_refresh_queue()
                    
                    # æ·»åŠ ä¸€ç‚¹å»¶è¿Ÿï¼Œé¿å…è¿‡å¿«è¯·æ±‚
                    await asyncio.sleep(1)
            
            # æ›´æ–°å¤±è´¥é¡¹çš„é‡è¯•æ—¶é—´
            if processed_count > 0:
                # æ£€æŸ¥æ˜¯å¦æœ‰éœ€è¦é‡è¯•çš„é¡¹ç›®ï¼Œå¹¶è®¾ç½®å®ƒä»¬çš„æ—¶é—´æˆ³
                for item in self.refresh_queue:
                    if item.status == "failed" and item.retry_count < self.max_retries:
                        # ä¸‹æ¬¡å¤„ç†æ—¶é—´å·²ç»åœ¨ä¸Šé¢è®¾ç½®å¥½äº†ï¼Œä¸éœ€è¦å†æ¬¡è®¾ç½®
                        pass
                
                # ä¿å­˜é˜Ÿåˆ—
                self._save_refresh_queue()
            
            logger.info(f"å®Œæˆé˜Ÿåˆ—å¤„ç†ï¼Œå…±å¤„ç† {processed_count} ä¸ªé¡¹ç›®ï¼ŒæˆåŠŸ {success_count} ä¸ª")
        
        finally:
            self._is_processing = False
    
    async def start_refresh_task(self):
        """å¯åŠ¨å®šæœŸåˆ·æ–°ä»»åŠ¡"""
        # å¦‚æœEmbyåŠŸèƒ½æœªå¯ç”¨ï¼Œä¸å¯åŠ¨ä»»åŠ¡
        if not self.emby_enabled:
            logger.info("Embyåˆ·åº“åŠŸèƒ½æœªå¯ç”¨ï¼Œä¸å¯åŠ¨åˆ·æ–°ä»»åŠ¡")
            return
            
        logger.info("å¯åŠ¨Embyåˆ·æ–°ä»»åŠ¡")
        self._stop_flag = False
        
        # å¯åŠ¨è‡ªåŠ¨æ‰«æä»»åŠ¡
        asyncio.create_task(self._auto_scan_task())
        
        while not self._stop_flag:
            await self.process_refresh_queue()
            await asyncio.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡é˜Ÿåˆ—
    
    async def _auto_scan_task(self):
        """å®šæœŸæ‰§è¡Œæ‰«ææœ€æ–°é¡¹ç›®çš„ä»»åŠ¡ï¼Œæ¯6å°æ—¶æ‰§è¡Œä¸€æ¬¡"""
        logger.info("å¯åŠ¨è‡ªåŠ¨æ‰«æEmbyæœ€æ–°é¡¹ç›®ä»»åŠ¡")
        
        while not self._stop_flag:
            try:
                # æ‰§è¡Œæ‰«æ
                logger.info("æ‰§è¡Œå®šæ—¶Embyæ–°é¡¹ç›®æ‰«æ")
                result = await self.scan_latest_items(hours=12)  # æ‰«ææœ€è¿‘12å°æ—¶çš„é¡¹ç›®
                
                if result["success"]:
                    logger.info(f"å®šæ—¶æ‰«æå®Œæˆ: {result['message']}")
                    # å‘é€é€šçŸ¥
                    try:
                        service_manager = self._get_service_manager()
                        if result["added_to_queue"] > 0:
                            await service_manager.telegram_service.send_message(
                                f"ğŸ”„ Embyè‡ªåŠ¨æ‰«æå®Œæˆ\n{result['message']}"
                            )
                    except Exception as e:
                        logger.error(f"å‘é€Telegramé€šçŸ¥å¤±è´¥: {str(e)}")
                else:
                    logger.error(f"å®šæ—¶æ‰«æå¤±è´¥: {result['message']}")
            except Exception as e:
                logger.error(f"æ‰§è¡Œå®šæ—¶æ‰«æä»»åŠ¡æ—¶å‡ºé”™: {str(e)}")
            
            # ç­‰å¾…6å°æ—¶
            await asyncio.sleep(6 * 60 * 60)  # 6å°æ—¶
    
    def stop_refresh_task(self):
        """åœæ­¢åˆ·æ–°ä»»åŠ¡"""
        logger.info("åœæ­¢Embyåˆ·æ–°ä»»åŠ¡")
        self._stop_flag = True 

    def _get_service_manager(self):
        """åŠ¨æ€è·å–service_managerä»¥é¿å…å¾ªç¯ä¾èµ–"""
        module = importlib.import_module('services.service_manager')
        return module.service_manager 

    def clear_refresh_queue(self):
        """æ¸…ç©ºåˆ·æ–°é˜Ÿåˆ—"""
        try:
            # è®°å½•å½“å‰é˜Ÿåˆ—å¤§å°
            queue_size = len(self.refresh_queue)
            logger.info(f"å¼€å§‹æ¸…ç©ºåˆ·æ–°é˜Ÿåˆ—ï¼Œå½“å‰é˜Ÿåˆ—å¤§å°: {queue_size}")
            
            # ä¿ç•™æˆåŠŸçš„é¡¹ç›®ï¼Œæ¸…é™¤å¾…å¤„ç†å’Œå¤±è´¥çš„é¡¹ç›®
            self.refresh_queue = [item for item in self.refresh_queue if item.status == "success"]
            
            # ä¿å­˜æ›´æ–°åçš„é˜Ÿåˆ—
            self._save_refresh_queue()
            
            removed_count = queue_size - len(self.refresh_queue)
            logger.info(f"å·²æ¸…ç©ºåˆ·æ–°é˜Ÿåˆ—ï¼Œç§»é™¤äº† {removed_count} ä¸ªé¡¹ç›®ï¼Œä¿ç•™ {len(self.refresh_queue)} ä¸ªæˆåŠŸé¡¹ç›®")
            
            return {
                "success": True,
                "message": f"å·²æ¸…ç©ºåˆ·æ–°é˜Ÿåˆ—ï¼Œç§»é™¤äº† {removed_count} ä¸ªå¾…å¤„ç†å’Œå¤±è´¥é¡¹ç›®ï¼Œä¿ç•™ {len(self.refresh_queue)} ä¸ªæˆåŠŸé¡¹ç›®",
                "removed_count": removed_count,
                "remaining_count": len(self.refresh_queue)
            }
        except Exception as e:
            logger.error(f"æ¸…ç©ºåˆ·æ–°é˜Ÿåˆ—å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "message": f"æ¸…ç©ºåˆ·æ–°é˜Ÿåˆ—å¤±è´¥: {str(e)}"
            }

    def clean_failed_refresh_queue(self):
        """æ¸…ç†å¤±è´¥çš„åˆ·æ–°é˜Ÿåˆ—é¡¹ï¼Œç§»é™¤404é”™è¯¯é¡¹"""
        try:
            # è®°å½•å½“å‰é˜Ÿåˆ—å¤§å°
            queue_size = len(self.refresh_queue)
            logger.info(f"å¼€å§‹æ¸…ç†å¤±è´¥çš„åˆ·æ–°é˜Ÿåˆ—é¡¹ï¼Œå½“å‰é˜Ÿåˆ—å¤§å°: {queue_size}")
            
            # ç§»é™¤404é”™è¯¯çš„é¡¹ç›®
            old_queue = self.refresh_queue.copy()
            self.refresh_queue = [
                item for item in old_queue 
                if not (item.status == "failed" and item.last_error and "404" in item.last_error)
            ]
            
            # ä¿å­˜æ›´æ–°åçš„é˜Ÿåˆ—
            self._save_refresh_queue()
            
            removed_count = queue_size - len(self.refresh_queue)
            logger.info(f"å·²æ¸…ç†å¤±è´¥çš„åˆ·æ–°é˜Ÿåˆ—é¡¹ï¼Œç§»é™¤äº† {removed_count} ä¸ª404é”™è¯¯é¡¹ï¼Œå‰©ä½™ {len(self.refresh_queue)} ä¸ªé¡¹ç›®")
            
            return {
                "success": True, 
                "message": f"å·²æ¸…ç†é˜Ÿåˆ—ä¸­çš„404é”™è¯¯é¡¹ï¼Œç§»é™¤äº† {removed_count} ä¸ªé¡¹ç›®",
                "removed_count": removed_count,
                "remaining_count": len(self.refresh_queue)
            }
        except Exception as e:
            logger.error(f"æ¸…ç†å¤±è´¥çš„åˆ·æ–°é˜Ÿåˆ—é¡¹å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "message": f"æ¸…ç†å¤±è´¥: {str(e)}"
            }

    # æ·»åŠ è·å–å•ä¸ªåª’ä½“é¡¹çš„æ–¹æ³•ï¼Œä½œä¸ºä¸´æ—¶æ–¹æ¡ˆ
    async def get_item(self, item_id: str) -> Optional[Dict]:
        """é€šè¿‡IDè·å–Embyåª’ä½“é¡¹ç›®çš„åŸºæœ¬ä¿¡æ¯ï¼ˆä¸è°ƒç”¨APIï¼‰"""
        try:
            # ä¸å†è°ƒç”¨/Items/{item_id} APIï¼Œç›´æ¥è¿”å›ç®€å•å¯¹è±¡
            logger.debug(f"ä½¿ç”¨item_id: {item_id}ï¼Œè¿”å›åŸºæœ¬ä¿¡æ¯å¯¹è±¡")
            return {"Id": item_id, "Name": f"åª’ä½“é¡¹ {item_id}", "Type": "Unknown"}
        except Exception as e:
            logger.error(f"å¤„ç†item_idæ—¶å‡ºé”™: {item_id}, é”™è¯¯: {str(e)}")
            return {"Id": item_id, "Name": "å¤„ç†å‡ºé”™", "Error": str(e)}

    def _load_path_cache(self):
        """åŠ è½½è·¯å¾„ç¼“å­˜"""
        try:
            # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(self.cache_file), exist_ok=True)
            
            if self.cache_file.exists():
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    self.path_to_id_cache = json.load(f)
                logger.info(f"å·²åŠ è½½è·¯å¾„ç¼“å­˜ï¼Œå…±{len(self.path_to_id_cache)}ä¸ªè®°å½•")
            else:
                self.path_to_id_cache = {}
                logger.info("è·¯å¾„ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°ç¼“å­˜")
        except Exception as e:
            logger.error(f"åŠ è½½è·¯å¾„ç¼“å­˜å¤±è´¥: {e}")
            self.path_to_id_cache = {}
    
    def _save_path_cache(self):
        """ä¿å­˜è·¯å¾„ç¼“å­˜åˆ°æ–‡ä»¶"""
        try:
            # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(self.cache_file), exist_ok=True)
            
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.path_to_id_cache, f, ensure_ascii=False, indent=2)
            logger.debug(f"å·²ä¿å­˜è·¯å¾„ç¼“å­˜ï¼Œå…±{len(self.path_to_id_cache)}ä¸ªè®°å½•")
        except Exception as e:
            logger.error(f"ä¿å­˜è·¯å¾„ç¼“å­˜å¤±è´¥: {e}")
            
    def add_to_path_cache(self, path: str, item_id: str, media_type: str = None, title: str = None):
        """æ·»åŠ è·¯å¾„åˆ°IDçš„æ˜ å°„
        
        Args:
            path: è·¯å¾„ï¼ˆå¯ä»¥æ˜¯STRMè·¯å¾„æˆ–æºæ–‡ä»¶è·¯å¾„ï¼‰
            item_id: Embyåª’ä½“é¡¹ID
            media_type: åª’ä½“ç±»å‹ï¼ˆå¦‚Movie, Episodeï¼‰
            title: åª’ä½“æ ‡é¢˜
        """
        if not path or not item_id:
            return
            
        # æ ‡å‡†åŒ–è·¯å¾„
        path = str(path).replace('\\', '/').rstrip('/')
        
        # åˆ›å»ºæˆ–æ›´æ–°ç¼“å­˜æ¡ç›®
        cache_entry = {
            "item_id": item_id,
            "updated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        if media_type:
            cache_entry["media_type"] = media_type
            
        if title:
            cache_entry["title"] = title
            
        # æ·»åŠ åˆ°ç¼“å­˜
        self.path_to_id_cache[path] = cache_entry
        self._save_path_cache()
        logger.debug(f"æ·»åŠ è·¯å¾„æ˜ å°„åˆ°ç¼“å­˜: {path} -> {item_id}")
        
    def get_from_path_cache(self, path: str) -> Optional[str]:
        """ä»è·¯å¾„ç¼“å­˜ä¸­è·å–Embyåª’ä½“é¡¹ID
        
        Args:
            path: è·¯å¾„ï¼ˆå¯ä»¥æ˜¯STRMè·¯å¾„æˆ–æºæ–‡ä»¶è·¯å¾„ï¼‰
            
        Returns:
            Optional[str]: Embyåª’ä½“é¡¹IDï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        if not path:
            return None
            
        # æ ‡å‡†åŒ–è·¯å¾„
        path = str(path).replace('\\', '/').rstrip('/')
        
        # ä»ç¼“å­˜ä¸­è·å–
        cache_entry = self.path_to_id_cache.get(path)
        if cache_entry:
            logger.debug(f"ä»ç¼“å­˜ä¸­æ‰¾åˆ°è·¯å¾„æ˜ å°„: {path} -> {cache_entry.get('item_id')}")
            return cache_entry.get("item_id")
        
        return None
        
    def clear_path_cache(self):
        """æ¸…ç©ºè·¯å¾„ç¼“å­˜"""
        self.path_to_id_cache = {}
        self._save_path_cache()
        logger.info("å·²æ¸…ç©ºè·¯å¾„ç¼“å­˜")

    def _load_last_refresh(self):
        """ä»æ–‡ä»¶åŠ è½½æœ€è¿‘ä¸€æ¬¡åˆ·æ–°è®°å½•"""
        try:
            if self.last_refresh_file.exists():
                with open(self.last_refresh_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.last_refresh_time = data.get('time')
                    self.last_refresh_items = data.get('items', [])
                logger.info(f"å·²åŠ è½½æœ€è¿‘åˆ·æ–°è®°å½•ï¼Œå…±{len(self.last_refresh_items)}ä¸ªé¡¹ç›®")
            else:
                self.last_refresh_time = None
                self.last_refresh_items = []
                logger.info("æœ€è¿‘åˆ·æ–°è®°å½•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨ç©ºè®°å½•")
        except Exception as e:
            logger.error(f"åŠ è½½æœ€è¿‘åˆ·æ–°è®°å½•å¤±è´¥: {e}")
            self.last_refresh_time = None
            self.last_refresh_items = []
    
    def _save_last_refresh(self, items=None):
        """ä¿å­˜æœ€è¿‘ä¸€æ¬¡åˆ·æ–°è®°å½•åˆ°æ–‡ä»¶"""
        try:
            # å¦‚æœæä¾›äº†æ–°çš„é¡¹ç›®åˆ—è¡¨ï¼Œæ›´æ–°è®°å½•
            if items is not None:
                self.last_refresh_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                self.last_refresh_items = items
                
            data = {
                'time': self.last_refresh_time,
                'items': self.last_refresh_items
            }
            
            with open(self.last_refresh_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            logger.debug(f"å·²ä¿å­˜æœ€è¿‘åˆ·æ–°è®°å½•ï¼Œå…±{len(self.last_refresh_items)}ä¸ªé¡¹ç›®")
        except Exception as e:
            logger.error(f"ä¿å­˜æœ€è¿‘åˆ·æ–°è®°å½•å¤±è´¥: {e}")

    async def test_search(self, query: str, mode: str = "name") -> dict:
        """æµ‹è¯•æœç´¢åŠŸèƒ½
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            mode: æœç´¢æ¨¡å¼ (name: æŒ‰åç§°, path: æŒ‰è·¯å¾„)
            
        Returns:
            dict: æœç´¢ç»“æœ
        """
        try:
            if not self.emby_enabled:
                return {"success": False, "message": "EmbyæœåŠ¡æœªå¯ç”¨"}
            
            results = []
            
            if mode == "path":
                # è½¬æ¢è·¯å¾„
                emby_path = self.convert_to_emby_path(query)
                logger.info(f"æµ‹è¯•æŒ‰è·¯å¾„æœç´¢: åŸå§‹è·¯å¾„={query}, è½¬æ¢å={emby_path}")
                
                # æŸ¥è¯¢åª’ä½“é¡¹
                item = await self.query_item_by_path(emby_path)
                if item:
                    results.append({
                        "id": item.get("Id"),
                        "name": item.get("Name"),
                        "type": item.get("Type"),
                        "path": item.get("Path"),
                        "year": item.get("ProductionYear")
                    })
                
            else:  # é»˜è®¤æŒ‰åç§°æœç´¢
                logger.info(f"æµ‹è¯•æŒ‰åç§°æœç´¢: {query}")
                items = await self.search_by_name(query)
                
                # æå–ç»“æœ
                for item in items[:10]:  # æœ€å¤šè¿”å›10ä¸ªç»“æœ
                    results.append({
                        "id": item.get("Id"),
                        "name": item.get("Name"),
                        "type": item.get("Type"),
                        "path": item.get("Path"),
                        "year": item.get("ProductionYear")
                    })
            
            # ç¼“å­˜çŠ¶æ€
            cache_count = len(self.path_to_id_cache)
            
            return {
                "success": True,
                "query": query,
                "mode": mode,
                "result_count": len(results),
                "results": results,
                "cache_count": cache_count
            }
            
        except Exception as e:
            logger.error(f"æµ‹è¯•æœç´¢å¤±è´¥: {str(e)}")
            import traceback
            return {
                "success": False,
                "message": str(e),
                "error_detail": traceback.format_exc()
            }

    async def force_refresh(self, path: str) -> dict:
        """å¼ºåˆ¶åˆ·æ–°æŒ‡å®šæ–‡ä»¶
        
        Args:
            path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            dict: åˆ·æ–°ç»“æœ
        """
        try:
            if not self.emby_enabled:
                return {"success": False, "message": "EmbyæœåŠ¡æœªå¯ç”¨"}
            
            # æ ‡å‡†åŒ–è·¯å¾„
            path = str(path).replace('\\', '/')
            
            # é¦–å…ˆæ£€æŸ¥æ˜¯å¦å­˜åœ¨äºç¼“å­˜ä¸­
            emby_id = self.get_from_path_cache(path)
            
            if emby_id:
                logger.info(f"ä»ç¼“å­˜ä¸­æ‰¾åˆ°è·¯å¾„ {path} å¯¹åº”çš„Embyé¡¹ç›®ID: {emby_id}")
                # ç›´æ¥åˆ·æ–°
                refresh_result = await self.refresh_emby_item(emby_id)
                if refresh_result:
                    return {
                        "success": True,
                        "message": f"æˆåŠŸåˆ·æ–°Embyé¡¹ç›®ID: {emby_id}",
                        "refresh_method": "cache"
                    }
                else:
                    return {
                        "success": False,
                        "message": f"åˆ·æ–°Embyé¡¹ç›®å¤±è´¥: {emby_id}",
                        "refresh_method": "cache"
                    }
            
            # å¦‚æœä¸åœ¨ç¼“å­˜ä¸­ï¼Œå°è¯•æœç´¢
            logger.info(f"åœ¨ç¼“å­˜ä¸­æœªæ‰¾åˆ°è·¯å¾„ {path}ï¼Œå°è¯•æœç´¢Emby")
            
            # å°è¯•é€šè¿‡è·¯å¾„æŸ¥è¯¢
            emby_path = self.convert_to_emby_path(path)
            item = await self.query_item_by_path(emby_path)
            
            if item:
                # æ·»åŠ åˆ°ç¼“å­˜
                self.add_to_path_cache(path, item.get("Id"), item.get("Type"), item.get("Name"))
                
                # åˆ·æ–°
                refresh_result = await self.refresh_emby_item(item.get("Id"))
                if refresh_result:
                    return {
                        "success": True,
                        "message": f"æˆåŠŸåˆ·æ–°Embyé¡¹ç›®: {item.get('Name')} (ID: {item.get('Id')})",
                        "refresh_method": "path_query"
                    }
                else:
                    return {
                        "success": False,
                        "message": f"åˆ·æ–°Embyé¡¹ç›®å¤±è´¥: {item.get('Name')} (ID: {item.get('Id')})",
                        "refresh_method": "path_query"
                    }
            
            # å¦‚æœé€šè¿‡è·¯å¾„æŸ¥è¯¢å¤±è´¥ï¼Œå°è¯•é€šè¿‡æ–‡ä»¶åæœç´¢
            filename = os.path.basename(path)
            name_without_ext = os.path.splitext(filename)[0]
            
            items = await self.search_by_name(name_without_ext)
            if items:
                item = items[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªåŒ¹é…ç»“æœ
                
                # æ·»åŠ åˆ°ç¼“å­˜
                self.add_to_path_cache(path, item.get("Id"), item.get("Type"), item.get("Name"))
                
                # åˆ·æ–°
                refresh_result = await self.refresh_emby_item(item.get("Id"))
                if refresh_result:
                    return {
                        "success": True,
                        "message": f"æˆåŠŸåˆ·æ–°Embyé¡¹ç›®: {item.get('Name')} (ID: {item.get('Id')})",
                        "refresh_method": "name_search"
                    }
                else:
                    return {
                        "success": False,
                        "message": f"åˆ·æ–°Embyé¡¹ç›®å¤±è´¥: {item.get('Name')} (ID: {item.get('Id')})",
                        "refresh_method": "name_search"
                    }
            
            # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥
            return {
                "success": False,
                "message": f"æœªæ‰¾åˆ°è·¯å¾„ {path} å¯¹åº”çš„Embyé¡¹ç›®"
            }
            
        except Exception as e:
            logger.error(f"å¼ºåˆ¶åˆ·æ–°å¤±è´¥: {str(e)}")
            import traceback
            return {
                "success": False,
                "message": str(e),
                "error_detail": traceback.format_exc()
            }

    async def get_queue_status(self) -> dict:
        """è·å–åˆ·æ–°é˜Ÿåˆ—çŠ¶æ€
        
        Returns:
            dict: é˜Ÿåˆ—çŠ¶æ€
        """
        try:
            if not self.emby_enabled:
                return {"success": False, "message": "EmbyæœåŠ¡æœªå¯ç”¨"}
            
            # ç»Ÿè®¡å„çŠ¶æ€çš„æ•°é‡
            total = len(self.refresh_queue)
            pending = sum(1 for item in self.refresh_queue if item.status == "pending")
            processing = sum(1 for item in self.refresh_queue if item.status == "processing")
            success = sum(1 for item in self.refresh_queue if item.status == "success")
            failed = sum(1 for item in self.refresh_queue if item.status == "failed")
            
            # è·å–ä¸‹ä¸€ä¸ªå¾…å¤„ç†é¡¹çš„æ—¶é—´
            next_item = None
            current_time = time.time()
            for item in self.refresh_queue:
                if item.status == "pending" and item.timestamp > current_time:
                    if next_item is None or item.timestamp < next_item.timestamp:
                        next_item = item
            
            next_time = None
            if next_item:
                next_time = datetime.fromtimestamp(next_item.timestamp).strftime('%Y-%m-%d %H:%M:%S')
            
            # è·å–æœ€è¿‘çš„å‡ ä¸ªé¡¹ç›®è¯¦æƒ…
            recent_items = []
            for item in sorted(self.refresh_queue, key=lambda x: x.timestamp, reverse=True)[:10]:
                recent_items.append({
                    "path": item.strm_path,
                    "status": item.status,
                    "time": datetime.fromtimestamp(item.timestamp).strftime('%Y-%m-%d %H:%M:%S'),
                    "retry_count": item.retry_count,
                    "error": item.last_error
                })
            
            # ç¼“å­˜çŠ¶æ€
            cache_count = len(self.path_to_id_cache)
            
            return {
                "success": True,
                "queue_status": {
                    "total": total,
                    "pending": pending,
                    "processing": processing,
                    "success": success,
                    "failed": failed,
                    "next_time": next_time
                },
                "recent_items": recent_items,
                "cache_status": {
                    "total": cache_count
                }
            }
            
        except Exception as e:
            logger.error(f"è·å–åˆ·æ–°é˜Ÿåˆ—çŠ¶æ€å¤±è´¥: {str(e)}")
            import traceback
            return {
                "success": False,
                "message": str(e),
                "error_detail": traceback.format_exc()
            }
            
    async def get_last_refresh_info(self) -> dict:
        """è·å–æœ€è¿‘ä¸€æ¬¡åˆ·æ–°çš„ä¿¡æ¯
        
        Returns:
            dict: æœ€è¿‘ä¸€æ¬¡åˆ·æ–°çš„ä¿¡æ¯
        """
        try:
            if not self.emby_enabled:
                return {"success": False, "message": "EmbyæœåŠ¡æœªå¯ç”¨"}
            
            if not self.last_refresh_time:
                return {
                    "success": True,
                    "message": "å°šæœªæ‰§è¡Œè¿‡åˆ·æ–°",
                    "has_refresh": False
                }
            
            # è·å–é˜Ÿåˆ—ä¸­è¿™äº›é¡¹ç›®çš„å½“å‰çŠ¶æ€
            item_statuses = []
            for item in self.last_refresh_items:
                item_id = item.get("id")
                item_path = item.get("path")
                
                # æŸ¥æ‰¾åœ¨é˜Ÿåˆ—ä¸­çš„çŠ¶æ€
                queue_item = next((q for q in self.refresh_queue if q.strm_path == item_path), None)
                status = "unknown"
                last_error = None
                
                if queue_item:
                    status = queue_item.status
                    last_error = queue_item.last_error
                    
                item_statuses.append({
                    "id": item_id,
                    "name": item.get("name"),
                    "type": item.get("type"),
                    "status": status,
                    "error": last_error
                })
                
            return {
                "success": True,
                "message": "è·å–æœ€è¿‘åˆ·æ–°ä¿¡æ¯æˆåŠŸ",
                "has_refresh": True,
                "time": self.last_refresh_time,
                "items": item_statuses,
                "total_count": len(item_statuses)
            }
            
        except Exception as e:
            logger.error(f"è·å–æœ€è¿‘åˆ·æ–°ä¿¡æ¯å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "message": f"è·å–å¤±è´¥: {str(e)}"
            }

    async def get_latest_items(self, limit: int = 200, item_type: str = None) -> List[Dict]:
        """è·å–æœ€æ–°å…¥åº“çš„åª’ä½“é¡¹
        
        Args:
            limit: è¿”å›çš„æœ€å¤§é¡¹ç›®æ•°é‡
            item_type: åª’ä½“ç±»å‹è¿‡æ»¤ï¼ˆMovie, Series, Episodeç­‰ï¼‰
            
        Returns:
            List[Dict]: æœ€æ–°å…¥åº“çš„åª’ä½“é¡¹åˆ—è¡¨
        """
        try:
            if not self.emby_enabled:
                logger.warning("EmbyæœåŠ¡æœªå¯ç”¨ï¼Œæ— æ³•è·å–æœ€æ–°é¡¹ç›®")
                return []
            
            # æ„å»ºAPI URL
            base_url = self.emby_url.rstrip('/')
            url = f"{base_url}/Items"
            
            # æ„å»ºæŸ¥è¯¢å‚æ•°
            params = {
                "api_key": self.api_key,
                "Limit": limit,
                "Fields": "Path,ParentId,Overview,ProductionYear",
                "SortBy": "DateCreated,SortName",
                "SortOrder": "Descending",
                "HasTmdbId": "false"  # åªè·å–æ²¡æœ‰TMDB IDçš„é¡¹ç›®ï¼Œé¿å…åˆ·æ–°å·²æœ‰å…ƒæ•°æ®çš„æ–‡ä»¶
            }
            
            # å¦‚æœæŒ‡å®šäº†åª’ä½“ç±»å‹ï¼Œæ·»åŠ è¿‡æ»¤
            if item_type:
                params["IncludeItemTypes"] = item_type
            
            logger.debug(f"è·å–æœ€æ–°å…¥åº“é¡¹ç›®: ç±»å‹={item_type}, æ•°é‡={limit}, æ’åº={params['SortBy']}, ä»…æœªè¯†åˆ«={params['HasTmdbId']}")
            
            # å‘é€è¯·æ±‚
            async with httpx.AsyncClient() as client:
                response = await client.get(url, params=params, timeout=30)
                
                if response.status_code == 200:
                    data = response.json()
                    items = data.get("Items", [])
                    logger.debug(f"æˆåŠŸè·å– {len(items)} ä¸ªæœ€æ–°é¡¹ç›®")
                    return items
                else:
                    logger.error(f"è·å–æœ€æ–°é¡¹ç›®å¤±è´¥: çŠ¶æ€ç ={response.status_code}")
                    return []
                    
        except Exception as e:
            logger.error(f"è·å–æœ€æ–°é¡¹ç›®æ—¶å‡ºé”™: {str(e)}")
            return []

    async def scan_latest_items(self, hours: int = 24, force_refresh: bool = False) -> dict:
        """æ‰«ææŒ‡å®šæ—¶é—´èŒƒå›´å†…æ–°å…¥åº“çš„é¡¹ç›®å¹¶æ·»åŠ åˆ°åˆ·æ–°é˜Ÿåˆ—
        
        Args:
            hours: æ‰«ææœ€è¿‘å¤šå°‘å°æ—¶çš„é¡¹ç›®
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°(å¿½ç•¥HasTmdbId)
            
        Returns:
            dict: æ‰«æç»“æœ
        """
        try:
            if not self.emby_enabled:
                return {"success": False, "message": "EmbyæœåŠ¡æœªå¯ç”¨"}
            
            # è®¡ç®—æ—¶é—´èŒƒå›´
            current_time = time.time()
            start_time = current_time - (hours * 3600)
            
            # è·å–æœ€æ–°é¡¹ç›®ï¼Œä½¿ç”¨æ’åºå’Œè¿‡æ»¤
            params = {
                "limit": 300,  # è·å–è¾ƒå¤šé¡¹ç›®ä»¥ç¡®ä¿è¦†ç›–
                "item_type": None  # ä¸é™åˆ¶ç±»å‹
            }
            
            # è·å–æœ€æ–°é¡¹ç›®
            latest_items = await self.get_latest_items(**params)
            
            # è¿‡æ»¤æ—¶é—´èŒƒå›´å†…çš„é¡¹ç›®
            new_items = []
            for item in latest_items:
                # è·å–é¡¹ç›®çš„æ·»åŠ æ—¶é—´
                date_created = item.get("DateCreated")
                if date_created:
                    try:
                        # è§£æISOæ ¼å¼çš„æ—¶é—´
                        from datetime import datetime
                        created_time = datetime.fromisoformat(date_created.replace('Z', '+00:00'))
                        created_timestamp = created_time.timestamp()
                        
                        if created_timestamp >= start_time:
                            # å¦‚æœæ˜¯å¼ºåˆ¶åˆ·æ–°ï¼Œæˆ–è€…é¡¹ç›®æ²¡æœ‰å…ƒæ•°æ®ï¼Œåˆ™æ·»åŠ 
                            if force_refresh or not item.get("ProviderIds", {}).get("Tmdb"):
                                new_items.append(item)
                    except Exception as e:
                        logger.debug(f"è§£æé¡¹ç›®æ—¶é—´å‡ºé”™: {str(e)}")
            
            # æ·»åŠ åˆ°åˆ·æ–°é˜Ÿåˆ—
            added_count = 0
            added_items = []  # è®°å½•æ·»åŠ çš„é¡¹ç›®ä¿¡æ¯
            for item in new_items:
                item_path = item.get("Path")
                if item_path:
                    # æ£€æŸ¥æ˜¯å¦å·²åœ¨é˜Ÿåˆ—ä¸­
                    if not any(q_item.strm_path == item_path for q_item in self.refresh_queue):
                        # æ·»åŠ åˆ°é˜Ÿåˆ—
                        media_info = {
                            "title": item.get("Name"),
                            "type": item.get("Type"),
                            "year": item.get("ProductionYear"),
                            "source_path": item_path
                        }
                        self.add_to_refresh_queue(item_path, media_info)
                        added_count += 1
                        
                        # è®°å½•æ·»åŠ çš„é¡¹ç›®ç®€è¦ä¿¡æ¯
                        added_items.append({
                            "id": item.get("Id"),
                            "name": item.get("Name"),
                            "type": item.get("Type"),
                            "path": item_path,
                            "year": item.get("ProductionYear")
                        })
            
            # ä¿å­˜æœ¬æ¬¡åˆ·æ–°è®°å½•
            if added_items:
                self._save_last_refresh(added_items)
            
            return {
                "success": True,
                "message": f"æ‰«æå®Œæˆï¼Œå‘ç° {len(new_items)} ä¸ªæ–°é¡¹ç›®ï¼Œæ·»åŠ  {added_count} ä¸ªåˆ°åˆ·æ–°é˜Ÿåˆ—",
                "total_found": len(new_items),
                "added_to_queue": added_count,
                "added_items": added_items
            }
            
        except Exception as e:
            logger.error(f"æ‰«ææœ€æ–°é¡¹ç›®å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "message": f"æ‰«æå¤±è´¥: {str(e)}"
            }