from pathlib import Path
import shutil
import time
import hashlib
from datetime import datetime
import os
from typing import NamedTuple, Optional, List, Dict, Tuple
from loguru import logger
from config import Settings
import asyncio
import importlib
import json

class MediaThreshold(NamedTuple):
    """åª’ä½“æ–‡ä»¶çš„æ—¶é—´é˜ˆå€¼é…ç½®"""
    creation_days: int
    mtime_days: int

class ArchiveService:
    def __init__(self):
        self.settings = Settings()
        self._stop_flag = False
        self._is_running = False
        
        # ä»é…ç½®åŠ è½½è§†é¢‘æ–‡ä»¶æ‰©å±•å
        self.video_extensions = set(
            ext.strip() for ext in self.settings.archive_video_extensions.split(',')
        )
        
        # ä»æ–‡ä»¶åŠ è½½åª’ä½“ç±»å‹é…ç½®
        self.media_types = self._load_media_types()
        self.thresholds = {
            name: MediaThreshold(
                info["creation_days"],
                info["mtime_days"]
            ) for name, info in self.media_types.items()
        }
    
    def _get_service_manager(self):
        """åŠ¨æ€è·å–service_managerä»¥é¿å…å¾ªç¯ä¾èµ–"""
        module = importlib.import_module('services.service_manager')
        return module.service_manager
    
    def get_creation_time(self, path: Path) -> float:
        """è·å–æ–‡ä»¶æˆ–ç›®å½•çš„åˆ›å»ºæ—¶é—´"""
        try:
            stat = path.stat()
            return getattr(stat, 'st_birthtime', stat.st_mtime)
        except Exception as e:
            logger.error(f"è·å–åˆ›å»ºæ—¶é—´å¤±è´¥ {path}: {e}")
            return time.time()
    
    def get_media_type(self, path: Path) -> str:
        """æ ¹æ®è·¯å¾„åˆ¤æ–­åª’ä½“ç±»å‹ï¼Œä¼˜å…ˆåŒ¹é…æ›´å…·ä½“çš„è·¯å¾„
        
        ä¾‹å¦‚ï¼š
        - è·¯å¾„ä¸º "/video/åŠ¨æ¼«/åŠ¨ç”»ç”µå½±/xxx"
        - å¦‚æœåŒæ—¶é…ç½®äº† "åŠ¨æ¼«/åŠ¨ç”»ç”µå½±" å’Œ "åŠ¨æ¼«"
        - ä¼šä¼˜å…ˆåŒ¹é… "åŠ¨æ¼«/åŠ¨ç”»ç”µå½±" ç±»å‹
        
        åŒ¹é…è§„åˆ™ï¼š
        1. å°†è·¯å¾„è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äºsource_rootï¼‰
        2. æŒ‰ç…§é…ç½®çš„é¡ºåºï¼ˆä¼˜å…ˆçº§ï¼‰ä¾æ¬¡åŒ¹é…
        3. å¯¹äºæ¯ä¸ªåª’ä½“ç±»å‹ï¼Œæ£€æŸ¥å…¶é…ç½®çš„ç›®å½•æ˜¯å¦æ˜¯å½“å‰è·¯å¾„çš„ä¸€éƒ¨åˆ†
        4. è¿”å›ç¬¬ä¸€ä¸ªåŒ¹é…çš„ç±»å‹ï¼ˆä¼˜å…ˆçº§æœ€é«˜çš„ï¼‰
        """
        path_str = str(path)
        
        # è½¬æ¢è·¯å¾„åˆ†éš”ç¬¦ä¸ºç»Ÿä¸€æ ¼å¼
        normalized_path = path_str.replace('\\', '/').rstrip('/')
        source_root = str(self.settings.archive_source_root).replace('\\', '/').rstrip('/')
        
        # è·å–ç›¸å¯¹è·¯å¾„
        if normalized_path.startswith(source_root):
            relative_path = normalized_path[len(source_root):].lstrip('/')
        else:
            relative_path = normalized_path
            
        logger.debug(f"æ£€æŸ¥è·¯å¾„: {relative_path}")
            
        # å°†è·¯å¾„åˆ†å‰²æˆéƒ¨åˆ†
        path_parts = relative_path.split('/')
        
        # ç”±äºself.media_typesçš„é¡ºåºå·²ç»ç”±å‰ç«¯æ’åºç¡®å®šä¼˜å…ˆçº§
        # æ‰€ä»¥è¿™é‡Œç›´æ¥æŒ‰é¡ºåºåŒ¹é…ï¼Œæ‰¾åˆ°çš„ç¬¬ä¸€ä¸ªåŒ¹é…å°±æ˜¯ä¼˜å…ˆçº§æœ€é«˜çš„
        for media_type, info in self.media_types.items():
            dir_path = info['dir'].replace('\\', '/').strip('/')
            dir_parts = dir_path.split('/')
            
            logger.debug(f"å°è¯•åŒ¹é…ç±»å‹ {media_type} (ç›®å½•: {dir_path})")
            
            # æ£€æŸ¥ç›®å½•æ˜¯å¦åŒ¹é…
            # 1. é…ç½®çš„ç›®å½•éƒ¨åˆ†å¿…é¡»å®Œå…¨åŒ¹é…è·¯å¾„çš„å¼€å§‹éƒ¨åˆ†
            # 2. é…ç½®çš„ç›®å½•å±‚çº§å¿…é¡»å°äºç­‰äºå®é™…è·¯å¾„çš„å±‚çº§
            if (len(dir_parts) <= len(path_parts) and 
                all(dp == pp for dp, pp in zip(dir_parts, path_parts))):
                logger.debug(f"åŒ¹é…æˆåŠŸ: {media_type}")
                return media_type
            else:
                logger.debug(f"åŒ¹é…å¤±è´¥: è·¯å¾„éƒ¨åˆ†={path_parts[:len(dir_parts)]}, é…ç½®éƒ¨åˆ†={dir_parts}")
                
        logger.debug("æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„åª’ä½“ç±»å‹")
        return ""
    
    def calculate_file_hash(self, file_path: Path) -> Optional[str]:
        """è®¡ç®—æ–‡ä»¶çš„MD5å“ˆå¸Œå€¼"""
        try:
            md5_hash = hashlib.md5()
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    md5_hash.update(chunk)
            return md5_hash.hexdigest()
        except Exception as e:
            logger.error(f"è®¡ç®—æ–‡ä»¶å“ˆå¸Œå¤±è´¥ {file_path}: {e}")
            return None
    
    def verify_files(self, source: Path, dest: Path) -> bool:
        """éªŒè¯æºæ–‡ä»¶å’Œç›®æ ‡æ–‡ä»¶æ˜¯å¦ç›¸åŒ"""
        try:
            if not source.exists() or not dest.exists():
                return False
            
            source_hash = self.calculate_file_hash(source)
            dest_hash = self.calculate_file_hash(dest)
            
            return source_hash and dest_hash and source_hash == dest_hash
        except Exception as e:
            logger.error(f"æ–‡ä»¶éªŒè¯å¤±è´¥: {e}")
            return False
    
    async def has_recent_files(self, directory: Path, mtime_threshold: int) -> Tuple[bool, List[Path]]:
        """æ£€æŸ¥ç›®å½•ä¸­æ˜¯å¦æœ‰æœ€è¿‘ä¿®æ”¹çš„è§†é¢‘æ–‡ä»¶"""
        recent_files = []
        try:
            for file_path in directory.rglob("*"):
                if self._stop_flag:
                    break
                    
                if file_path.is_file() and file_path.suffix.lower() in self.video_extensions:
                    mtime = file_path.stat().st_mtime
                    age_days = (time.time() - mtime) / 86400
                    if age_days < mtime_threshold:
                        recent_files.append(file_path)
                        
                # è®©å‡ºæ§åˆ¶æƒ
                await asyncio.sleep(0)
        except Exception as e:
            logger.error(f"æ£€æŸ¥æœ€è¿‘æ–‡ä»¶å¤±è´¥: {e}")
            
        return bool(recent_files), recent_files
    
    def stop(self):
        """åœæ­¢å½’æ¡£å¤„ç†"""
        if not self._is_running:
            return
        self._stop_flag = True
        logger.info("æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨åœæ­¢å½’æ¡£...")
    
    async def process_directory(self, directory: Path, test_mode: bool = False) -> Dict:
        """å¤„ç†å•ä¸ªç›®å½•çš„å½’æ¡£
        
        Args:
            directory: è¦å¤„ç†çš„ç›®å½•è·¯å¾„
            test_mode: æ˜¯å¦ä¸ºæµ‹è¯•æ¨¡å¼ï¼ˆåªè¯†åˆ«ä¸æ‰§è¡Œï¼‰
            
        Returns:
            Dict: å¤„ç†ç»“æœ
        """
        result = {
            "success": False,
            "message": "",
            "moved_files": 0,
            "total_size": 0
        }
        
        try:
            # è·å–ç›®å½•çš„ç›¸å¯¹è·¯å¾„
            source_dir = Path(self.settings.archive_source_root)
            relative_path = directory.relative_to(source_dir)
            parent_dir = str(relative_path.parent)
            
            # æ£€æŸ¥æ˜¯å¦åœ¨é…ç½®çš„ç›®å½•ä¸­
            media_type = None
            for type_name, info in self.media_types.items():
                if parent_dir == info['dir']:
                    media_type = type_name
                    break
                    
            if not media_type:
                result["message"] = f"[è·³è¿‡] æœªåŒ¹é…åˆ°åª’ä½“ç±»å‹: {directory}"
                return result

            threshold = self.thresholds[media_type]
            creation_time = self.get_creation_time(directory)
            age_days = (time.time() - creation_time) / 86400

            if age_days < threshold.creation_days:
                result["message"] = (
                    f"[è·³è¿‡] {media_type}: {directory.name}\n"
                    f"åŸå› : åˆ›å»ºæ—¶é—´ä¸è¶³ ({age_days:.1f}å¤© < {threshold.creation_days}å¤©)"
                )
                return result

            has_recent, recent_files = await self.has_recent_files(directory, threshold.mtime_days)
            if has_recent:
                example_files = []
                for f in recent_files[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ªæ–‡ä»¶
                    mtime = f.stat().st_mtime
                    age_days = (time.time() - mtime) / 86400
                    example_files.append(f"{f.name} ({age_days:.1f}å¤©)")
                
                result["message"] = (
                    f"[è·³è¿‡] {media_type}: {directory.name}\n"
                    f"åŸå› : å­˜åœ¨è¿‘æœŸä¿®æ”¹çš„æ–‡ä»¶ (é˜ˆå€¼: {threshold.mtime_days}å¤©)\n"
                    f"æ–‡ä»¶: {', '.join(example_files)}"
                )
                return result

            # å‡†å¤‡å½’æ¡£
            target_dir = Path(self.settings.archive_target_root)
            destination = target_dir / relative_path
            
            if test_mode:
                # æµ‹è¯•æ¨¡å¼ä¸‹åªè¿”å›å°†è¦æ‰§è¡Œçš„æ“ä½œ
                result["message"] = (
                    f"[æµ‹è¯•] {media_type}: {directory.name} -> {destination.name}\n"
                    f"åˆ›å»ºæ—¶é—´: {age_days:.1f}å¤©, æ— è¿‘æœŸä¿®æ”¹æ–‡ä»¶"
                )
                result["success"] = True
                return result
            
            # åˆ›å»ºç›®æ ‡ç›®å½•
            destination.parent.mkdir(parents=True, exist_ok=True)
            
            # å¤åˆ¶æˆ–ç§»åŠ¨æ–‡ä»¶
            if self.settings.archive_delete_source:
                # å¦‚æœéœ€è¦åˆ é™¤æºæ–‡ä»¶ï¼Œå…ˆå¤åˆ¶å†éªŒè¯
                shutil.copytree(str(directory), str(destination), dirs_exist_ok=True)
                
                # éªŒè¯æ‰€æœ‰æ–‡ä»¶
                all_verified = True
                for src_file in directory.rglob("*"):
                    if src_file.is_file():
                        dst_file = destination / src_file.relative_to(directory)
                        if not self.verify_files(src_file, dst_file):
                            all_verified = False
                            break
                        result["total_size"] += src_file.stat().st_size
                        result["moved_files"] += 1
                
                if all_verified:
                    # éªŒè¯æˆåŠŸååˆ é™¤æºæ–‡ä»¶
                    shutil.rmtree(str(directory))
                    result["message"] = (
                        f"[å½’æ¡£] {media_type}: {directory.name} -> {destination.name}\n"
                        f"åˆ›å»ºæ—¶é—´: {age_days:.1f}å¤©, å·²éªŒè¯å¹¶åˆ é™¤æºæ–‡ä»¶"
                    )
                else:
                    result["message"] = f"[é”™è¯¯] {media_type}: {directory.name} æ–‡ä»¶éªŒè¯å¤±è´¥"
                    return result
            else:
                # å¦‚æœä¸éœ€è¦åˆ é™¤æºæ–‡ä»¶ï¼Œç›´æ¥å¤åˆ¶
                shutil.copytree(str(directory), str(destination), dirs_exist_ok=True)
                for src_file in directory.rglob("*"):
                    if src_file.is_file():
                        result["total_size"] += src_file.stat().st_size
                        result["moved_files"] += 1
                result["message"] = (
                    f"[å½’æ¡£] {media_type}: {directory.name} -> {destination.name}\n"
                    f"åˆ›å»ºæ—¶é—´: {age_days:.1f}å¤©"
                )

            result["success"] = True
            
        except Exception as e:
            result["message"] = f"[é”™è¯¯] å½’æ¡£å¤±è´¥ {directory.name}: {str(e)}"
            logger.error(f"å¤„ç†ç›®å½•å¤±è´¥ {directory}: {e}")
            
        return result
    
    async def archive(self, test_mode: bool = False):
        """æ‰§è¡Œå½’æ¡£å¤„ç†
        
        Args:
            test_mode: æ˜¯å¦ä¸ºæµ‹è¯•æ¨¡å¼ï¼ˆåªè¯†åˆ«ä¸æ‰§è¡Œï¼‰
            
        Returns:
            Dict: å¦‚æœæ˜¯æµ‹è¯•æ¨¡å¼ï¼Œè¿”å›æµ‹è¯•ç»“æœ
        """
        if self._is_running:
            logger.warning("å½’æ¡£ä»»åŠ¡å·²åœ¨è¿è¡Œä¸­")
            return
            
        try:
            self._stop_flag = False
            self._is_running = True
            
            service_manager = self._get_service_manager()
            await service_manager.telegram_service.send_message(
                "ğŸ” å¼€å§‹å½’æ¡£æµ‹è¯•..." if test_mode else "ğŸš€ å¼€å§‹å½’æ¡£å¤„ç†..."
            )
            
            source_dir = Path(self.settings.archive_source_root)
            if not source_dir.exists():
                error_msg = f"æºç›®å½•ä¸å­˜åœ¨: {source_dir}"
                logger.error(error_msg)
                await service_manager.telegram_service.send_message(f"âŒ {error_msg}")
                return
                
            total_processed = 0
            total_size = 0
            test_results = []
            
            # éå†æ¯ä¸ªé…ç½®çš„åª’ä½“ç±»å‹
            for media_type, info in self.media_types.items():
                if self._stop_flag:
                    break
                    
                # æ„å»ºå®Œæ•´çš„ç›®å½•è·¯å¾„
                type_dir = source_dir / info['dir']
                if not type_dir.exists():
                    logger.info(f"è·³è¿‡ä¸å­˜åœ¨çš„ç›®å½•: {type_dir}")
                    continue
                    
                logger.info(f"\nå¼€å§‹å¤„ç†åª’ä½“ç±»å‹ {media_type} (ç›®å½•: {type_dir})")
                
                # åªå¤„ç†è¯¥ç›®å½•ä¸‹çš„ç›´æ¥å­ç›®å½•
                try:
                    for item in type_dir.iterdir():
                        if self._stop_flag:
                            break
                            
                        if not item.is_dir():
                            continue
                            
                        logger.info(f"\nå¤„ç†ç›®å½•: {item}")
                        await service_manager.telegram_service.send_message(f"ğŸ“‚ å¤„ç†ç›®å½•: {item}")
                        
                        result = await self.process_directory(item, test_mode)
                        if result["success"]:
                            total_processed += result["moved_files"]
                            total_size += result["total_size"]
                        if test_mode:
                            test_results.append(result)
                        await service_manager.telegram_service.send_message(result["message"])
                        
                        # è®©å‡ºæ§åˆ¶æƒ
                        await asyncio.sleep(0)
                        
                except Exception as e:
                    logger.error(f"å¤„ç†åª’ä½“ç±»å‹ {media_type} æ—¶å‡ºé”™: {e}")
            
            summary = (
                f"âœ… å½’æ¡£{'æµ‹è¯•' if test_mode else ''}å®Œæˆ\n"
                f"ğŸ“ {'è¯†åˆ«' if test_mode else 'å¤„ç†'}æ–‡ä»¶: {total_processed} ä¸ª\n"
                f"ğŸ’¾ æ€»å¤§å°: {total_size / 1024 / 1024:.2f} MB"
            )
            logger.info(summary)
            await service_manager.telegram_service.send_message(summary)
            
            # å¦‚æœé…ç½®äº†è‡ªåŠ¨è¿è¡ŒSTRMæ‰«æä¸”ä¸æ˜¯æµ‹è¯•æ¨¡å¼
            if not test_mode and self.settings.archive_auto_strm and total_processed > 0:
                logger.info("å¼€å§‹è‡ªåŠ¨STRMæ‰«æ...")
                await service_manager.telegram_service.send_message("ğŸ”„ å¼€å§‹è‡ªåŠ¨STRMæ‰«æ...")
                await service_manager.strm_service.strm()
            
            if test_mode:
                return {
                    "summary": summary,
                    "results": test_results
                }
            
        except Exception as e:
            error_msg = f"âŒ å½’æ¡£{'æµ‹è¯•' if test_mode else 'å¤„ç†'}å‡ºé”™: {str(e)}"
            logger.error(error_msg)
            service_manager = self._get_service_manager()
            await service_manager.telegram_service.send_message(error_msg)
            raise
        finally:
            self._is_running = False
            self._stop_flag = False

    def _load_media_types(self) -> Dict[str, Dict]:
        """ä»config/archive.jsonåŠ è½½åª’ä½“ç±»å‹é…ç½®"""
        config_file = "config/archive.json"
        if os.path.exists(config_file):
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"åŠ è½½åª’ä½“ç±»å‹é…ç½®å¤±è´¥: {e}")
        return json.loads(self.settings.archive_media_types)

    def save_media_types(self):
        """ä¿å­˜åª’ä½“ç±»å‹é…ç½®åˆ°config/archive.json"""
        config_file = "config/archive.json"
        try:
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(self.media_types, f, ensure_ascii=False, indent=4)
            logger.info("åª’ä½“ç±»å‹é…ç½®å·²ä¿å­˜")
        except Exception as e:
            logger.error(f"ä¿å­˜åª’ä½“ç±»å‹é…ç½®å¤±è´¥: {e}") 

    async def process_file(self, source_path: Path) -> Dict:
        """å¤„ç†å•ä¸ªæ–‡ä»¶çš„å½’æ¡£
        
        Args:
            source_path: æºæ–‡ä»¶è·¯å¾„
            
        Returns:
            Dict: å¤„ç†ç»“æœï¼ŒåŒ…å«successã€messageå’Œsizeå­—æ®µ
        """
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æ˜¯æ–‡ä»¶
            if not source_path.is_file():
                return {
                    "success": False,
                    "message": f"âŒ {source_path} ä¸æ˜¯æ–‡ä»¶",
                    "size": 0
                }
            
            # è·å–æ–‡ä»¶å¤§å°
            file_size = source_path.stat().st_size
            
            # è·å–åª’ä½“ç±»å‹
            media_type = self.get_media_type(source_path)
            if not media_type:
                return {
                    "success": False,
                    "message": f"âŒ {source_path} æœªåŒ¹é…åˆ°åª’ä½“ç±»å‹",
                    "size": 0
                }
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ»¡è¶³é˜ˆå€¼æ¡ä»¶
            creation_time = self.get_creation_time(source_path)
            mtime = source_path.stat().st_mtime
            
            threshold = self.thresholds[media_type]
            creation_days = (time.time() - creation_time) / (24 * 3600)
            mtime_days = (time.time() - mtime) / (24 * 3600)
            
            if creation_days < threshold.creation_days or mtime_days < threshold.mtime_days:
                return {
                    "success": False,
                    "message": f"â³ {source_path} æœªè¾¾åˆ°å½’æ¡£é˜ˆå€¼",
                    "size": 0
                }
            
            # æ„å»ºç›®æ ‡è·¯å¾„ï¼Œä¿æŒç›¸å¯¹è·¯å¾„ç»“æ„
            relative_path = source_path.relative_to(self.settings.archive_source_root)
            dest_path = Path(self.settings.archive_target_root) / relative_path
            
            # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
            dest_path.parent.mkdir(parents=True, exist_ok=True)
            
            # å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼ŒéªŒè¯æ–‡ä»¶
            if dest_path.exists():
                if self.verify_files(source_path, dest_path):
                    # å¦‚æœé…ç½®äº†åˆ é™¤æºæ–‡ä»¶ä¸”éªŒè¯é€šè¿‡
                    if self.settings.archive_delete_source:
                        source_path.unlink()
                        return {
                            "success": True,
                            "message": f"ğŸ—‘ï¸ {source_path} å·²å­˜åœ¨äºç›®æ ‡ä½ç½®ï¼Œåˆ é™¤æºæ–‡ä»¶",
                            "size": file_size
                        }
                    return {
                        "success": False,
                        "message": f"â­ï¸ {source_path} å·²å­˜åœ¨äºç›®æ ‡ä½ç½®",
                        "size": 0
                    }
                else:
                    return {
                        "success": False,
                        "message": f"âŒ {source_path} ç›®æ ‡ä½ç½®å­˜åœ¨ä¸åŒæ–‡ä»¶",
                        "size": 0
                    }
            
            # å¤åˆ¶æ–‡ä»¶
            shutil.copy2(source_path, dest_path)
            
            # éªŒè¯å¤åˆ¶åçš„æ–‡ä»¶
            if not self.verify_files(source_path, dest_path):
                # å¦‚æœéªŒè¯å¤±è´¥ï¼Œåˆ é™¤ç›®æ ‡æ–‡ä»¶
                if dest_path.exists():
                    dest_path.unlink()
                return {
                    "success": False,
                    "message": f"âŒ {source_path} å¤åˆ¶éªŒè¯å¤±è´¥",
                    "size": 0
                }
            
            # å¦‚æœé…ç½®äº†åˆ é™¤æºæ–‡ä»¶
            if self.settings.archive_delete_source:
                source_path.unlink()
                return {
                    "success": True,
                    "message": f"âœ… {source_path} -> {dest_path} (å·²åˆ é™¤æºæ–‡ä»¶)",
                    "size": file_size
                }
            
            return {
                "success": True,
                "message": f"âœ… {source_path} -> {dest_path}",
                "size": file_size
            }
            
        except Exception as e:
            logger.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥ {source_path}: {e}")
            return {
                "success": False,
                "message": f"âŒ {source_path} å¤„ç†å¤±è´¥: {str(e)}",
                "size": 0
            } 