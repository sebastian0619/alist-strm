from pathlib import Path
import shutil
import time
import hashlib
from datetime import datetime
import os
from typing import NamedTuple, Optional, List, Dict, Tuple
from loguru import logger
from config import Settings
import asyncio
import importlib
import json

class MediaThreshold(NamedTuple):
    """åª’ä½“æ–‡ä»¶çš„æ—¶é—´é˜ˆå€¼é…ç½®"""
    creation_days: int
    mtime_days: int

class ArchiveService:
    def __init__(self):
        self.settings = Settings()
        self._stop_flag = False
        self._is_running = False
        
        # ä»é…ç½®åŠ è½½è¦æ’é™¤çš„æ–‡ä»¶æ‰©å±•å
        self.excluded_extensions = set(
            ext.strip().lower() for ext in self.settings.archive_excluded_extensions.split(',')
        )
        
        # ä»æ–‡ä»¶åŠ è½½åª’ä½“ç±»å‹é…ç½®
        self.media_types = self._load_media_types()
        self.thresholds = {
            name: MediaThreshold(
                info["creation_days"],
                info["mtime_days"]
            ) for name, info in self.media_types.items()
        }
    
    def _get_service_manager(self):
        """åŠ¨æ€è·å–service_managerä»¥é¿å…å¾ªç¯ä¾èµ–"""
        module = importlib.import_module('services.service_manager')
        return module.service_manager
    
    def get_creation_time(self, path: Path) -> float:
        """è·å–æ–‡ä»¶æˆ–ç›®å½•çš„åˆ›å»ºæ—¶é—´"""
        try:
            stat = path.stat()
            return getattr(stat, 'st_birthtime', stat.st_mtime)
        except Exception as e:
            logger.error(f"è·å–åˆ›å»ºæ—¶é—´å¤±è´¥ {path}: {e}")
            return time.time()
    
    def get_media_type(self, path: Path) -> str:
        """æ ¹æ®è·¯å¾„åˆ¤æ–­åª’ä½“ç±»å‹ï¼Œä¼˜å…ˆåŒ¹é…æ›´å…·ä½“çš„è·¯å¾„
        
        ä¾‹å¦‚ï¼š
        - è·¯å¾„ä¸º "/video/åŠ¨æ¼«/åŠ¨ç”»ç”µå½±/xxx"
        - å¦‚æœåŒæ—¶é…ç½®äº† "åŠ¨æ¼«/åŠ¨ç”»ç”µå½±" å’Œ "åŠ¨æ¼«"
        - ä¼šä¼˜å…ˆåŒ¹é… "åŠ¨æ¼«/åŠ¨ç”»ç”µå½±" ç±»å‹
        
        åŒ¹é…è§„åˆ™ï¼š
        1. å°†è·¯å¾„è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äºsource_rootï¼‰
        2. æŒ‰ç…§é…ç½®çš„é¡ºåºï¼ˆä¼˜å…ˆçº§ï¼‰ä¾æ¬¡åŒ¹é…
        3. å¯¹äºæ¯ä¸ªåª’ä½“ç±»å‹ï¼Œæ£€æŸ¥å…¶é…ç½®çš„ç›®å½•æ˜¯å¦æ˜¯å½“å‰è·¯å¾„çš„ä¸€éƒ¨åˆ†
        4. è¿”å›ç¬¬ä¸€ä¸ªåŒ¹é…çš„ç±»å‹ï¼ˆä¼˜å…ˆçº§æœ€é«˜çš„ï¼‰
        """
        path_str = str(path)
        
        # è½¬æ¢è·¯å¾„åˆ†éš”ç¬¦ä¸ºç»Ÿä¸€æ ¼å¼
        normalized_path = path_str.replace('\\', '/').rstrip('/')
        source_root = str(self.settings.archive_source_root).replace('\\', '/').rstrip('/')
        
        # è·å–ç›¸å¯¹è·¯å¾„
        if normalized_path.startswith(source_root):
            relative_path = normalized_path[len(source_root):].lstrip('/')
        else:
            relative_path = normalized_path
            
        logger.debug(f"æ£€æŸ¥è·¯å¾„: {relative_path}")
            
        # å°†è·¯å¾„åˆ†å‰²æˆéƒ¨åˆ†
        path_parts = relative_path.split('/')
        
        # ç”±äºself.media_typesçš„é¡ºåºå·²ç»ç”±å‰ç«¯æ’åºç¡®å®šä¼˜å…ˆçº§
        # æ‰€ä»¥è¿™é‡Œç›´æ¥æŒ‰é¡ºåºåŒ¹é…ï¼Œæ‰¾åˆ°çš„ç¬¬ä¸€ä¸ªåŒ¹é…å°±æ˜¯ä¼˜å…ˆçº§æœ€é«˜çš„
        for media_type, info in self.media_types.items():
            dir_path = info['dir'].replace('\\', '/').strip('/')
            dir_parts = dir_path.split('/')
            
            logger.debug(f"å°è¯•åŒ¹é…ç±»å‹ {media_type} (ç›®å½•: {dir_path})")
            
            # æ£€æŸ¥ç›®å½•æ˜¯å¦åŒ¹é…
            # 1. é…ç½®çš„ç›®å½•éƒ¨åˆ†å¿…é¡»å®Œå…¨åŒ¹é…è·¯å¾„çš„å¼€å§‹éƒ¨åˆ†
            # 2. é…ç½®çš„ç›®å½•å±‚çº§å¿…é¡»å°äºç­‰äºå®é™…è·¯å¾„çš„å±‚çº§
            if (len(dir_parts) <= len(path_parts) and 
                all(dp == pp for dp, pp in zip(dir_parts, path_parts))):
                logger.debug(f"åŒ¹é…æˆåŠŸ: {media_type}")
                return media_type
            else:
                logger.debug(f"åŒ¹é…å¤±è´¥: è·¯å¾„éƒ¨åˆ†={path_parts[:len(dir_parts)]}, é…ç½®éƒ¨åˆ†={dir_parts}")
                
        logger.debug("æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„åª’ä½“ç±»å‹")
        return ""
    
    def calculate_file_hash(self, file_path: Path) -> Optional[str]:
        """è®¡ç®—æ–‡ä»¶çš„MD5å“ˆå¸Œå€¼"""
        try:
            md5_hash = hashlib.md5()
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    md5_hash.update(chunk)
            return md5_hash.hexdigest()
        except Exception as e:
            logger.error(f"è®¡ç®—æ–‡ä»¶å“ˆå¸Œå¤±è´¥ {file_path}: {e}")
            return None
    
    def verify_files(self, source: Path, dest: Path) -> bool:
        """éªŒè¯æºæ–‡ä»¶å’Œç›®æ ‡æ–‡ä»¶æ˜¯å¦ç›¸åŒ"""
        try:
            if not source.exists() or not dest.exists():
                return False
            
            source_hash = self.calculate_file_hash(source)
            dest_hash = self.calculate_file_hash(dest)
            
            return source_hash and dest_hash and source_hash == dest_hash
        except Exception as e:
            logger.error(f"æ–‡ä»¶éªŒè¯å¤±è´¥: {e}")
            return False
    
    async def has_recent_files(self, directory: Path, mtime_threshold: int) -> Tuple[bool, List[Path]]:
        """æ£€æŸ¥ç›®å½•ä¸­æ˜¯å¦æœ‰æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶ï¼ˆæ’é™¤æŒ‡å®šæ‰©å±•åï¼‰"""
        recent_files = []
        try:
            for file_path in directory.rglob("*"):
                if self._stop_flag:
                    break
                    
                if file_path.is_file() and file_path.suffix.lower() not in self.excluded_extensions:
                    mtime = file_path.stat().st_mtime
                    age_days = (time.time() - mtime) / 86400
                    if age_days < mtime_threshold:
                        recent_files.append(file_path)
                        
                # è®©å‡ºæ§åˆ¶æƒ
                await asyncio.sleep(0)
        except Exception as e:
            logger.error(f"æ£€æŸ¥æœ€è¿‘æ–‡ä»¶å¤±è´¥: {e}")
            
        return bool(recent_files), recent_files
    
    def stop(self):
        """åœæ­¢å½’æ¡£å¤„ç†"""
        if not self._is_running:
            return
        self._stop_flag = True
        logger.info("æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨åœæ­¢å½’æ¡£...")
    
    async def process_directory(self, directory: Path, test_mode: bool = False) -> Dict:
        """å¤„ç†å•ä¸ªç›®å½•çš„å½’æ¡£
        
        Args:
            directory: è¦å¤„ç†çš„ç›®å½•è·¯å¾„
            test_mode: æ˜¯å¦ä¸ºæµ‹è¯•æ¨¡å¼ï¼ˆåªè¯†åˆ«ä¸æ‰§è¡Œï¼‰
            
        Returns:
            Dict: å¤„ç†ç»“æœ
        """
        result = {
            "success": False,
            "message": "",
            "moved_files": 0,
            "total_size": 0
        }
        
        try:
            # æ£€æŸ¥ç›®å½•ä¸­çš„æ–‡ä»¶ä¿®æ”¹æ—¶é—´
            recent_files = []
            for root, _, files in os.walk(directory):
                root_path = Path(root)
                for file in files:
                    # æ£€æŸ¥æ–‡ä»¶æ‰©å±•åæ˜¯å¦åœ¨æ’é™¤åˆ—è¡¨ä¸­
                    if any(file.lower().endswith(ext.strip().lower()) for ext in self.excluded_extensions):
                        continue
                        
                    file_path = root_path / file
                    stats = file_path.stat()
                    mtime = stats.st_mtime
                    ctime = stats.st_ctime
                    
                    # è®¡ç®—æ–‡ä»¶çš„åˆ›å»ºæ—¶é—´å’Œä¿®æ”¹æ—¶é—´è·ä»Šçš„å¤©æ•°
                    mtime_days = (time.time() - mtime) / 86400
                    ctime_days = (time.time() - ctime) / 86400
                    
                    # å¦‚æœæ–‡ä»¶çš„åˆ›å»ºæ—¶é—´æˆ–ä¿®æ”¹æ—¶é—´åœ¨é˜ˆå€¼å†…ï¼Œæ·»åŠ åˆ°æœ€è¿‘æ–‡ä»¶åˆ—è¡¨
                    if mtime_days < 30 or ctime_days < 30:  # ä½¿ç”¨30å¤©ä½œä¸ºé»˜è®¤é˜ˆå€¼
                        recent_files.append((file_path, min(mtime_days, ctime_days)))

            if recent_files:
                # æŒ‰æ—¶é—´æ’åºï¼Œå±•ç¤ºæœ€è¿‘çš„3ä¸ªæ–‡ä»¶
                recent_files.sort(key=lambda x: x[1])
                example_files = []
                for f, days in recent_files[:3]:
                    example_files.append(f"{f.name} ({days:.1f}å¤©)")
                
                result["message"] = (
                    f"[è·³è¿‡] {directory.name}\n"
                    f"åŸå› : å­˜åœ¨è¿‘æœŸåˆ›å»ºæˆ–ä¿®æ”¹çš„æ–‡ä»¶\n"
                    f"æ–‡ä»¶: {', '.join(example_files)}"
                )
                return result

            if test_mode:
                result["message"] = f"[æµ‹è¯•] {directory.name} å¯ä»¥å½’æ¡£ï¼Œæ— è¿‘æœŸæ–‡ä»¶"
                result["success"] = True
                return result
            
            # å‡†å¤‡å½’æ¡£
            target_dir = Path(self.settings.archive_target_root)
            relative_path = directory.relative_to(self.settings.archive_source_root)
            destination = target_dir / relative_path
            
            # åˆ›å»ºç›®æ ‡ç›®å½•
            destination.parent.mkdir(parents=True, exist_ok=True)
            
            # å¤åˆ¶æˆ–ç§»åŠ¨æ–‡ä»¶
            if self.settings.archive_delete_source:
                # å¦‚æœéœ€è¦åˆ é™¤æºæ–‡ä»¶ï¼Œå…ˆå¤åˆ¶å†éªŒè¯
                shutil.copytree(str(directory), str(destination), dirs_exist_ok=True)
                
                # éªŒè¯æ‰€æœ‰æ–‡ä»¶
                all_verified = True
                for src_file in directory.rglob("*"):
                    if src_file.is_file():
                        # è·³è¿‡æ’é™¤çš„æ–‡ä»¶æ ¼å¼
                        if any(src_file.name.lower().endswith(ext.strip().lower()) for ext in self.excluded_extensions):
                            continue
                            
                        dst_file = destination / src_file.relative_to(directory)
                        if not self.verify_files(src_file, dst_file):
                            all_verified = False
                            break
                        result["total_size"] += src_file.stat().st_size
                        result["moved_files"] += 1
                
                if all_verified:
                    # éªŒè¯æˆåŠŸååˆ é™¤æºæ–‡ä»¶
                    shutil.rmtree(str(directory))
                    result["message"] = (
                        f"[å½’æ¡£] {directory.name} -> {destination.name}\n"
                        f"å·²éªŒè¯å¹¶åˆ é™¤æºæ–‡ä»¶"
                    )
                else:
                    result["message"] = f"[é”™è¯¯] {directory.name} æ–‡ä»¶éªŒè¯å¤±è´¥"
                    return result
            else:
                # å¦‚æœä¸éœ€è¦åˆ é™¤æºæ–‡ä»¶ï¼Œç›´æ¥å¤åˆ¶
                # ä½¿ç”¨è‡ªå®šä¹‰çš„copytreeæ¥æ’é™¤ç‰¹å®šæ ¼å¼çš„æ–‡ä»¶
                def custom_copy(src, dst):
                    if not dst.exists():
                        dst.mkdir(parents=True, exist_ok=True)
                    for item in src.iterdir():
                        if item.is_file():
                            # è·³è¿‡æ’é™¤çš„æ–‡ä»¶æ ¼å¼
                            if any(item.name.lower().endswith(ext.strip().lower()) for ext in self.excluded_extensions):
                                continue
                            shutil.copy2(str(item), str(dst / item.name))
                            result["total_size"] += item.stat().st_size
                            result["moved_files"] += 1
                        elif item.is_dir():
                            custom_copy(item, dst / item.name)
                
                custom_copy(directory, destination)
                result["message"] = (
                    f"[å½’æ¡£] {directory.name} -> {destination.name}"
                )

            result["success"] = True
            
        except Exception as e:
            result["message"] = f"[é”™è¯¯] å½’æ¡£å¤±è´¥ {directory.name}: {str(e)}"
            logger.error(f"å¤„ç†ç›®å½•å¤±è´¥ {directory}: {e}")
            
        return result
    
    async def archive(self, test_mode: bool = False):
        """æ‰§è¡Œå½’æ¡£å¤„ç†
        
        Args:
            test_mode: æ˜¯å¦ä¸ºæµ‹è¯•æ¨¡å¼ï¼ˆåªè¯†åˆ«ä¸æ‰§è¡Œï¼‰
            
        Returns:
            Dict: å¦‚æœæ˜¯æµ‹è¯•æ¨¡å¼ï¼Œè¿”å›æµ‹è¯•ç»“æœ
        """
        if self._is_running:
            logger.warning("å½’æ¡£ä»»åŠ¡å·²åœ¨è¿è¡Œä¸­")
            return
            
        try:
            self._stop_flag = False
            self._is_running = True
            
            service_manager = self._get_service_manager()
            await service_manager.telegram_service.send_message(
                "ğŸ” å¼€å§‹å½’æ¡£æµ‹è¯•..." if test_mode else "ğŸš€ å¼€å§‹å½’æ¡£å¤„ç†..."
            )
            
            source_dir = Path(self.settings.archive_source_root)
            if not source_dir.exists():
                error_msg = f"æºç›®å½•ä¸å­˜åœ¨: {source_dir}"
                logger.error(error_msg)
                await service_manager.telegram_service.send_message(f"âŒ {error_msg}")
                return
                
            total_processed = 0
            total_size = 0
            test_results = []
            all_results = []
            
            # åªéå†é…ç½®çš„ç›®å½•
            for media_type, info in self.media_types.items():
                if self._stop_flag:
                    break
                    
                target_dir = source_dir / info['dir'].lstrip('/')
                if not target_dir.exists():
                    logger.warning(f"é…ç½®çš„ç›®å½•ä¸å­˜åœ¨: {target_dir}")
                    continue
                    
                logger.info(f"\nå¼€å§‹å¤„ç†åª’ä½“ç±»å‹ {media_type} çš„ç›®å½•: {target_dir}")
                
                # éå†ç›®æ ‡ç›®å½•ä¸‹çš„æ‰€æœ‰å­ç›®å½•
                for root, dirs, files in os.walk(target_dir):
                    if self._stop_flag:
                        break
                        
                    root_path = Path(root)
                    # åªå¤„ç†åŒ…å«æ–‡ä»¶çš„ç›®å½•ï¼ˆå¶å­ç›®å½•ï¼‰
                    if files and not any(d.startswith('.') for d in root_path.parts):
                        logger.info(f"\nå¤„ç†ç›®å½•: {root_path}")
                        
                        result = await self.process_directory(root_path, test_mode)
                        if result["success"]:
                            total_processed += result["moved_files"]
                            total_size += result["total_size"]
                        if test_mode:
                            test_results.append(result)
                            
                        # åªæ”¶é›†æœ‰æ„ä¹‰çš„ç»“æœï¼ˆè·³è¿‡ã€å½’æ¡£æˆ–é”™è¯¯ï¼‰
                        if "[è·³è¿‡]" in result["message"] or "[å½’æ¡£]" in result["message"] or "[é”™è¯¯]" in result["message"]:
                            all_results.append(result["message"])
                        
                        # è®©å‡ºæ§åˆ¶æƒ
                        await asyncio.sleep(0)
            
            # ç”Ÿæˆæ±‡æ€»æ¶ˆæ¯
            if all_results:
                summary_message = "å½’æ¡£å¤„ç†ç»“æœ:\n\n" + "\n\n".join(all_results)
                # å¦‚æœæ¶ˆæ¯å¤ªé•¿ï¼Œåªä¿ç•™å‰20ä¸ªç»“æœ
                if len(summary_message) > 3000:
                    all_results = all_results[:20]
                    summary_message = "å½’æ¡£å¤„ç†ç»“æœï¼ˆä»…æ˜¾ç¤ºå‰20ä¸ªï¼‰:\n\n" + "\n\n".join(all_results)
                await service_manager.telegram_service.send_message(summary_message)
            
            summary = (
                f"âœ… å½’æ¡£{'æµ‹è¯•' if test_mode else ''}å®Œæˆ\n"
                f"ğŸ“ {'è¯†åˆ«' if test_mode else 'å¤„ç†'}æ–‡ä»¶: {total_processed} ä¸ª\n"
                f"ğŸ’¾ æ€»å¤§å°: {total_size / 1024 / 1024:.2f} MB"
            )
            logger.info(summary)
            await service_manager.telegram_service.send_message(summary)
            
            # å¦‚æœé…ç½®äº†è‡ªåŠ¨è¿è¡ŒSTRMæ‰«æä¸”ä¸æ˜¯æµ‹è¯•æ¨¡å¼
            if not test_mode and self.settings.archive_auto_strm and total_processed > 0:
                logger.info("å¼€å§‹è‡ªåŠ¨STRMæ‰«æ...")
                await service_manager.telegram_service.send_message("ğŸ”„ å¼€å§‹è‡ªåŠ¨STRMæ‰«æ...")
                await service_manager.strm_service.strm()
            
            if test_mode:
                return {
                    "summary": summary,
                    "results": test_results
                }
            
        except Exception as e:
            error_msg = f"âŒ å½’æ¡£{'æµ‹è¯•' if test_mode else 'å¤„ç†'}å‡ºé”™: {str(e)}"
            logger.error(error_msg)
            service_manager = self._get_service_manager()
            await service_manager.telegram_service.send_message(error_msg)
            raise
        finally:
            self._is_running = False
            self._stop_flag = False

    def _load_media_types(self) -> Dict[str, Dict]:
        """ä»config/archive.jsonåŠ è½½åª’ä½“ç±»å‹é…ç½®"""
        config_file = "config/archive.json"
        if os.path.exists(config_file):
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"åŠ è½½åª’ä½“ç±»å‹é…ç½®å¤±è´¥: {e}")
        return json.loads(self.settings.archive_media_types)

    def save_media_types(self):
        """ä¿å­˜åª’ä½“ç±»å‹é…ç½®åˆ°config/archive.json"""
        config_file = "config/archive.json"
        try:
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(self.media_types, f, ensure_ascii=False, indent=4)
            logger.info("åª’ä½“ç±»å‹é…ç½®å·²ä¿å­˜")
        except Exception as e:
            logger.error(f"ä¿å­˜åª’ä½“ç±»å‹é…ç½®å¤±è´¥: {e}") 

    async def process_file(self, source_path: Path) -> Dict:
        """å¤„ç†å•ä¸ªæ–‡ä»¶çš„å½’æ¡£
        
        Args:
            source_path: æºæ–‡ä»¶è·¯å¾„
            
        Returns:
            Dict: å¤„ç†ç»“æœï¼ŒåŒ…å«successã€messageå’Œsizeå­—æ®µ
        """
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æ˜¯æ–‡ä»¶
            if not source_path.is_file():
                return {
                    "success": False,
                    "message": f"âŒ {source_path} ä¸æ˜¯æ–‡ä»¶",
                    "size": 0
                }
            
            # è·å–æ–‡ä»¶å¤§å°
            file_size = source_path.stat().st_size
            
            # è·å–åª’ä½“ç±»å‹
            media_type = self.get_media_type(source_path)
            if not media_type:
                return {
                    "success": False,
                    "message": f"âŒ {source_path} æœªåŒ¹é…åˆ°åª’ä½“ç±»å‹",
                    "size": 0
                }
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ»¡è¶³é˜ˆå€¼æ¡ä»¶
            creation_time = self.get_creation_time(source_path)
            mtime = source_path.stat().st_mtime
            
            threshold = self.thresholds[media_type]
            creation_days = (time.time() - creation_time) / (24 * 3600)
            mtime_days = (time.time() - mtime) / (24 * 3600)
            
            if creation_days < threshold.creation_days or mtime_days < threshold.mtime_days:
                return {
                    "success": False,
                    "message": f"â³ {source_path} æœªè¾¾åˆ°å½’æ¡£é˜ˆå€¼",
                    "size": 0
                }
            
            # æ„å»ºç›®æ ‡è·¯å¾„ï¼Œä¿æŒç›¸å¯¹è·¯å¾„ç»“æ„
            relative_path = source_path.relative_to(self.settings.archive_source_root)
            dest_path = Path(self.settings.archive_target_root) / relative_path
            
            # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
            dest_path.parent.mkdir(parents=True, exist_ok=True)
            
            # å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼ŒéªŒè¯æ–‡ä»¶
            if dest_path.exists():
                if self.verify_files(source_path, dest_path):
                    # å¦‚æœé…ç½®äº†åˆ é™¤æºæ–‡ä»¶ä¸”éªŒè¯é€šè¿‡
                    if self.settings.archive_delete_source:
                        source_path.unlink()
                        return {
                            "success": True,
                            "message": f"ğŸ—‘ï¸ {source_path} å·²å­˜åœ¨äºç›®æ ‡ä½ç½®ï¼Œåˆ é™¤æºæ–‡ä»¶",
                            "size": file_size
                        }
                    return {
                        "success": False,
                        "message": f"â­ï¸ {source_path} å·²å­˜åœ¨äºç›®æ ‡ä½ç½®",
                        "size": 0
                    }
                else:
                    return {
                        "success": False,
                        "message": f"âŒ {source_path} ç›®æ ‡ä½ç½®å­˜åœ¨ä¸åŒæ–‡ä»¶",
                        "size": 0
                    }
            
            # å¤åˆ¶æ–‡ä»¶
            shutil.copy2(source_path, dest_path)
            
            # éªŒè¯å¤åˆ¶åçš„æ–‡ä»¶
            if not self.verify_files(source_path, dest_path):
                # å¦‚æœéªŒè¯å¤±è´¥ï¼Œåˆ é™¤ç›®æ ‡æ–‡ä»¶
                if dest_path.exists():
                    dest_path.unlink()
                return {
                    "success": False,
                    "message": f"âŒ {source_path} å¤åˆ¶éªŒè¯å¤±è´¥",
                    "size": 0
                }
            
            # å¦‚æœé…ç½®äº†åˆ é™¤æºæ–‡ä»¶
            if self.settings.archive_delete_source:
                source_path.unlink()
                return {
                    "success": True,
                    "message": f"âœ… {source_path} -> {dest_path} (å·²åˆ é™¤æºæ–‡ä»¶)",
                    "size": file_size
                }
            
            return {
                "success": True,
                "message": f"âœ… {source_path} -> {dest_path}",
                "size": file_size
            }
            
        except Exception as e:
            logger.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥ {source_path}: {e}")
            return {
                "success": False,
                "message": f"âŒ {source_path} å¤„ç†å¤±è´¥: {str(e)}",
                "size": 0
            } 