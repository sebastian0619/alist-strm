from pathlib import Path
import shutil
import time
import hashlib
from datetime import datetime
import os
from typing import NamedTuple, Optional, List, Dict, Tuple
from loguru import logger
from config import Settings
import asyncio
import importlib
import json
from services.alist_client import AlistClient
import re

class MediaThreshold(NamedTuple):
    """åª’ä½“æ–‡ä»¶çš„æ—¶é—´é˜ˆå€¼é…ç½®"""
    creation_days: int
    mtime_days: int

class ArchiveService:
    def __init__(self):
        self.settings = Settings()
        self._stop_flag = False
        self._is_running = False
        
        # æ·»åŠ æ—¥å¿—å†å²è®°å½•åˆ—è¡¨
        self.logger_history = []
        # æ·»åŠ æ—¥å¿—å¤„ç†å™¨
        self._setup_logger_handler()
        
        # ä»é…ç½®åŠ è½½è¦æ’é™¤çš„æ–‡ä»¶æ‰©å±•å
        self.excluded_extensions = set(
            ext.strip().lower() for ext in self.settings.archive_excluded_extensions.split(',')
        )
        
        # ä»æ–‡ä»¶åŠ è½½åª’ä½“ç±»å‹é…ç½®
        self._media_types = self._load_media_types()
        # åˆå§‹åŒ–é˜ˆå€¼é…ç½®
        self.thresholds = {
            name: MediaThreshold(
                info["creation_days"],
                info["mtime_days"]
            ) for name, info in self._media_types.items()
        }
        
        # å®šä¹‰å¾…åˆ é™¤æ–‡ä»¶åˆ—è¡¨çš„JSONæ–‡ä»¶è·¯å¾„
        self._pending_deletions_file = os.path.join("config", "pending_deletions.json")
        # åˆå§‹åŒ–å¾…åˆ é™¤æ–‡ä»¶é˜Ÿåˆ—
        self._pending_deletions = self._load_pending_deletions()
        # åˆ é™¤å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰- ä»é…ç½®ä¸­è¯»å–
        self._deletion_delay = self.settings.archive_delete_delay_days * 24 * 3600  # è½¬æ¢ä¸ºç§’
        
        # åˆå§‹åŒ–AlistClient
        self.alist_client = AlistClient(
            self.settings.alist_url,
            self.settings.alist_token
        )
        
        # åˆ é™¤æ£€æŸ¥ä»»åŠ¡å°†åœ¨initializeæ–¹æ³•ä¸­å¯åŠ¨
        self._deletion_check_task = None
    
    def _load_pending_deletions(self) -> list:
        """ä»JSONæ–‡ä»¶åŠ è½½å¾…åˆ é™¤åˆ—è¡¨"""
        try:
            # ç¡®ä¿configç›®å½•å­˜åœ¨
            os.makedirs("config", exist_ok=True)
            if os.path.exists(self._pending_deletions_file):
                with open(self._pending_deletions_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    # è½¬æ¢è·¯å¾„å­—ç¬¦ä¸²å›Pathå¯¹è±¡
                    for item in data:
                        if 'path' in item and isinstance(item['path'], str):
                            item['path'] = Path(item['path'])
                    return data
        except Exception as e:
            logger.error(f"åŠ è½½å¾…åˆ é™¤åˆ—è¡¨å¤±è´¥: {e}")
        return []
    
    def _save_pending_deletions(self):
        """å°†å¾…åˆ é™¤åˆ—è¡¨ä¿å­˜åˆ°JSONæ–‡ä»¶"""
        try:
            # ç¡®ä¿configç›®å½•å­˜åœ¨
            os.makedirs("config", exist_ok=True)
            
            # å°†Pathå¯¹è±¡è½¬æ¢ä¸ºå­—ç¬¦ä¸²ä»¥ä¾¿JSONåºåˆ—åŒ–
            data_to_save = []
            for item in self._pending_deletions:
                data_item = item.copy()
                if 'path' in data_item and isinstance(data_item['path'], Path):
                    data_item['path'] = str(data_item['path'])
                data_to_save.append(data_item)
                
            with open(self._pending_deletions_file, 'w', encoding='utf-8') as f:
                json.dump(data_to_save, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜å¾…åˆ é™¤åˆ—è¡¨å¤±è´¥: {e}")
    
    def _setup_logger_handler(self):
        """è®¾ç½®æ—¥å¿—å¤„ç†å™¨ï¼Œè®°å½•æ—¥å¿—å†å²"""
        class LoggerHistoryHandler:
            def __init__(self, history_list):
                self.history_list = history_list
                
            def write(self, record):
                # ä¿®å¤ï¼šå¤„ç†ä¸åŒç±»å‹çš„record
                if isinstance(record, dict) and "message" in record:
                    # æ—§æ ¼å¼ï¼Œä¿æŒå…¼å®¹
                    message = record["message"]
                else:
                    # æ–°æ ¼å¼ï¼Œrecordç›´æ¥æ˜¯æ¶ˆæ¯å­—ç¬¦ä¸²
                    message = str(record)
                    
                self.history_list.append(message)
                # ä¿æŒæ—¥å¿—å†å²åœ¨ä¸€ä¸ªåˆç†çš„å¤§å°
                if len(self.history_list) > 1000:
                    self.history_list.pop(0)
        
        # æ·»åŠ è‡ªå®šä¹‰å¤„ç†å™¨åˆ°logger
        logger.add(LoggerHistoryHandler(self.logger_history).write)
    
    async def initialize(self):
        """åˆå§‹åŒ–æœåŠ¡ï¼Œå¯åŠ¨åå°ä»»åŠ¡"""
        if not self._deletion_check_task:
            self._deletion_check_task = asyncio.create_task(self._check_pending_deletions())
    
    async def shutdown(self):
        """å…³é—­æœåŠ¡ï¼Œæ¸…ç†èµ„æº"""
        if self._deletion_check_task:
            self._deletion_check_task.cancel()
            try:
                await self._deletion_check_task
            except asyncio.CancelledError:
                pass
            self._deletion_check_task = None
        
        if self.alist_client:
            await self.alist_client.close()
    
    def _get_service_manager(self):
        """åŠ¨æ€è·å–service_managerä»¥é¿å…å¾ªç¯ä¾èµ–"""
        module = importlib.import_module('services.service_manager')
        return module.service_manager
    
    def get_creation_time(self, path: Path) -> float:
        """è·å–æ–‡ä»¶æˆ–ç›®å½•çš„åˆ›å»ºæ—¶é—´"""
        try:
            stat = path.stat()
            return getattr(stat, 'st_birthtime', stat.st_mtime)
        except Exception as e:
            logger.error(f"è·å–åˆ›å»ºæ—¶é—´å¤±è´¥ {path}: {e}")
            return time.time()
    
    def get_media_type(self, path: Path) -> str:
        """æ ¹æ®è·¯å¾„åˆ¤æ–­åª’ä½“ç±»å‹ï¼Œä¼˜å…ˆåŒ¹é…æ›´å…·ä½“çš„è·¯å¾„
        
        ä¾‹å¦‚ï¼š
        - è·¯å¾„ä¸º "/video/åŠ¨æ¼«/åŠ¨ç”»ç”µå½±/xxx"
        - å¦‚æœåŒæ—¶é…ç½®äº† "åŠ¨æ¼«/åŠ¨ç”»ç”µå½±" å’Œ "åŠ¨æ¼«"
        - ä¼šä¼˜å…ˆåŒ¹é… "åŠ¨æ¼«/åŠ¨ç”»ç”µå½±" ç±»å‹
        
        åŒ¹é…è§„åˆ™ï¼š
        1. å°†è·¯å¾„è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äºsource_rootï¼‰
        2. æŒ‰ç…§é…ç½®çš„é¡ºåºï¼ˆä¼˜å…ˆçº§ï¼‰ä¾æ¬¡åŒ¹é…
        3. å¯¹äºæ¯ä¸ªåª’ä½“ç±»å‹ï¼Œæ£€æŸ¥å…¶é…ç½®çš„ç›®å½•æ˜¯å¦æ˜¯å½“å‰è·¯å¾„çš„ä¸€éƒ¨åˆ†
        4. è¿”å›ç¬¬ä¸€ä¸ªåŒ¹é…çš„ç±»å‹ï¼ˆä¼˜å…ˆçº§æœ€é«˜çš„ï¼‰
        """
        path_str = str(path)
        
        # è½¬æ¢è·¯å¾„åˆ†éš”ç¬¦ä¸ºç»Ÿä¸€æ ¼å¼
        normalized_path = path_str.replace('\\', '/').rstrip('/')
        source_root = str(self.settings.archive_source_root).replace('\\', '/').rstrip('/')
        
        # è·å–ç›¸å¯¹è·¯å¾„
        if normalized_path.startswith(source_root):
            relative_path = normalized_path[len(source_root):].lstrip('/')
        else:
            relative_path = normalized_path
            
        logger.debug(f"æ£€æŸ¥è·¯å¾„: {relative_path}")
            
        # å°†è·¯å¾„åˆ†å‰²æˆéƒ¨åˆ†
        path_parts = relative_path.split('/')
        
        # ä½¿ç”¨æœ€é•¿åŒ¹é…åŸåˆ™ï¼Œå…ˆå°è¯•åŒ¹é…æœ€å…·ä½“çš„è·¯å¾„
        matched_type = ""
        max_match_length = 0
        
        for media_type, info in self.media_types.items():
            if "dir" not in info:
                continue
                
            dir_path = info['dir'].replace('\\', '/').strip('/')
            dir_parts = dir_path.split('/')
            
            logger.debug(f"å°è¯•åŒ¹é…ç±»å‹ {media_type} (ç›®å½•: {dir_path})")
            
            # æ£€æŸ¥ç›®å½•æ˜¯å¦åŒ¹é…
            # 1. é…ç½®çš„ç›®å½•éƒ¨åˆ†å¿…é¡»å®Œå…¨åŒ¹é…è·¯å¾„çš„å¼€å§‹éƒ¨åˆ†
            # 2. é…ç½®çš„ç›®å½•å±‚çº§å¿…é¡»å°äºç­‰äºå®é™…è·¯å¾„çš„å±‚çº§
            if (len(dir_parts) <= len(path_parts) and 
                all(dp == pp for dp, pp in zip(dir_parts, path_parts))):
                
                # æ‰¾åˆ°åŒ¹é…ï¼Œä½†ä½¿ç”¨æœ€é•¿åŒ¹é…åŸåˆ™
                if len(dir_parts) > max_match_length:
                    max_match_length = len(dir_parts)
                    matched_type = media_type
                    logger.debug(f"æ‰¾åˆ°æ›´ä¼˜åŒ¹é…: {media_type}, åŒ¹é…é•¿åº¦: {len(dir_parts)}")
            else:
                logger.debug(f"åŒ¹é…å¤±è´¥: è·¯å¾„éƒ¨åˆ†={path_parts[:len(dir_parts)]}, é…ç½®éƒ¨åˆ†={dir_parts}")
        
        if matched_type:
            logger.debug(f"æœ€ç»ˆåŒ¹é…: {matched_type}")
            return matched_type
        else:        
            logger.debug("æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„åª’ä½“ç±»å‹")
            return ""
    
    def calculate_file_hash(self, file_path: Path) -> Optional[str]:
        """è®¡ç®—æ–‡ä»¶çš„MD5å“ˆå¸Œå€¼"""
        try:
            md5_hash = hashlib.md5()
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    md5_hash.update(chunk)
            return md5_hash.hexdigest()
        except Exception as e:
            logger.error(f"è®¡ç®—æ–‡ä»¶å“ˆå¸Œå¤±è´¥ {file_path}: {e}")
            return None
    
    def verify_files(self, source: Path, dest: Path) -> bool:
        """éªŒè¯æºæ–‡ä»¶å’Œç›®æ ‡æ–‡ä»¶æ˜¯å¦ç›¸åŒ"""
        try:
            if not source.exists() or not dest.exists():
                return False
            
            source_hash = self.calculate_file_hash(source)
            dest_hash = self.calculate_file_hash(dest)
            
            return source_hash and dest_hash and source_hash == dest_hash
        except Exception as e:
            logger.error(f"æ–‡ä»¶éªŒè¯å¤±è´¥: {e}")
            return False
    
    async def has_recent_files(self, directory: Path, mtime_threshold: int) -> Tuple[bool, List[Path]]:
        """æ£€æŸ¥ç›®å½•ä¸­æ˜¯å¦æœ‰æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶ï¼ˆæ’é™¤æŒ‡å®šæ‰©å±•åï¼‰"""
        recent_files = []
        try:
            for file_path in directory.rglob("*"):
                if self._stop_flag:
                    break
                    
                if file_path.is_file() and file_path.suffix.lower() not in self.excluded_extensions:
                    mtime = file_path.stat().st_mtime
                    age_days = (time.time() - mtime) / 86400
                    if age_days < mtime_threshold:
                        recent_files.append(file_path)
                        
                # è®©å‡ºæ§åˆ¶æƒ
                await asyncio.sleep(0)
        except Exception as e:
            logger.error(f"æ£€æŸ¥æœ€è¿‘æ–‡ä»¶å¤±è´¥: {e}")
            
        return bool(recent_files), recent_files
    
    def stop(self):
        """åœæ­¢å½’æ¡£å¤„ç†"""
        if not self._is_running:
            return
        self._stop_flag = True
        logger.info("æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨åœæ­¢å½’æ¡£...")
    
    async def _check_pending_deletions(self):
        """å®šæœŸæ£€æŸ¥å¾…åˆ é™¤æ–‡ä»¶ï¼Œåˆ é™¤è¶…è¿‡å»¶è¿Ÿæ—¶é—´çš„æ–‡ä»¶"""
        logger.info("å¾…åˆ é™¤æ–‡ä»¶æ£€æŸ¥ä»»åŠ¡å·²å¯åŠ¨")
        
        # åˆå§‹åŠ è½½ï¼Œç¡®ä¿æœ‰æœ€æ–°æ•°æ®
        self._pending_deletions = self._load_pending_deletions()
        logger.info(f"åˆå§‹åŒ–æ—¶å¾…åˆ é™¤æ–‡ä»¶æ•°é‡: {len(self._pending_deletions)}")
        
        while True:
            try:
                current_time = time.time()
                items_to_delete = []
                
                # ç¡®ä¿ä½¿ç”¨æœ€æ–°åˆ—è¡¨
                if len(self._pending_deletions) > 0:
                    logger.info(f"æ£€æŸ¥å¾…åˆ é™¤æ–‡ä»¶åˆ—è¡¨ï¼Œå…± {len(self._pending_deletions)} ä¸ªé¡¹ç›®")
                
                # è¯†åˆ«éœ€è¦åˆ é™¤çš„é¡¹ç›®
                for item in self._pending_deletions:
                    if current_time >= item["delete_time"]:
                        items_to_delete.append(item)
                
                # æ‰§è¡Œåˆ é™¤æ“ä½œ
                for item in items_to_delete:
                    path = item["path"]
                    try:
                        if path.is_dir():
                            shutil.rmtree(str(path))
                        else:
                            path.unlink()
                        logger.info(f"å·²åˆ é™¤å»¶è¿Ÿæ–‡ä»¶: {path}")
                        self._pending_deletions.remove(item)
                    except Exception as e:
                        logger.error(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {path}: {e}")
                
                # å¦‚æœæœ‰åˆ é™¤æ“ä½œï¼Œä¿å­˜æ›´æ–°åçš„åˆ—è¡¨
                if items_to_delete:
                    self._save_pending_deletions()
                    logger.info(f"å·²åˆ é™¤ {len(items_to_delete)} ä¸ªè¿‡æœŸæ–‡ä»¶ï¼Œå‰©ä½™ {len(self._pending_deletions)} ä¸ªå¾…åˆ é™¤é¡¹ç›®")
                    
            except Exception as e:
                logger.error(f"æ£€æŸ¥å¾…åˆ é™¤æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            finally:
                await asyncio.sleep(3600)  # æ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡

    def _add_to_pending_deletion(self, path: Path):
        """æ·»åŠ æ–‡ä»¶åˆ°å¾…åˆ é™¤é˜Ÿåˆ—"""
        self._pending_deletions.append({
            "path": path,
            "delete_time": time.time() + self._deletion_delay
        })
        # ä¿å­˜å¾…åˆ é™¤åˆ—è¡¨åˆ°JSONæ–‡ä»¶
        self._save_pending_deletions()
        logger.info(f"å·²æ·»åŠ åˆ°å»¶è¿Ÿåˆ é™¤é˜Ÿåˆ—: {path}, å°†åœ¨ {self._deletion_delay/86400:.1f} å¤©ååˆ é™¤")

    def _should_skip_directory(self, path: Path) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡æŸä¸ªç›®å½•"""
        # ç³»ç»Ÿç›®å½•
        if any(skip_dir in str(path) for skip_dir in self._skip_dirs):
            logger.debug(f"è·³è¿‡ç³»ç»Ÿç›®å½•: {path}")
            return True
        
        # ç”¨æˆ·é…ç½®çš„ç›®å½•
        if any(skip_folder in str(path) for skip_folder in self.settings.skip_folders_list):
            logger.debug(f"è·³è¿‡ç”¨æˆ·é…ç½®çš„ç›®å½•: {path}")
            return True
        
        # æ£€æŸ¥ç”¨æˆ·é…ç½®çš„æ¨¡å¼
        if any(re.search(pattern, str(path)) for pattern in self.settings.skip_patterns_list):
            logger.debug(f"è·³è¿‡åŒ¹é…æ¨¡å¼çš„ç›®å½•: {path}")
            return True
        
        return False

    async def process_directory(self, directory: Path, test_mode: bool = False) -> Dict:
        """å¤„ç†å•ä¸ªç›®å½•çš„å½’æ¡£
        
        Args:
            directory: è¦å½’æ¡£çš„ç›®å½•
            test_mode: æ˜¯å¦ä¸ºæµ‹è¯•æ¨¡å¼ï¼ˆåªè¯†åˆ«ä¸æ‰§è¡Œï¼‰
            
        Returns:
            Dict: å¤„ç†ç»“æœ
        """
        result = {
            "success": False,
            "message": "",
            "moved_files": 0,
            "total_size": 0
        }
        
        try:
            logger.info(f"å¼€å§‹å¤„ç†ç›®å½•: {directory}")
            rel_path = directory.relative_to(self.settings.archive_source_root)
            logger.debug(f"- ç›¸å¯¹è·¯å¾„: {rel_path}")
            
            # è·å–æœ€åçš„æ–‡ä»¶å¤¹åç§°
            folder_name = directory.name
            
            # è·å–å®Œæ•´çš„å‰§é›†åç§°ï¼ˆå¦‚æœæ˜¯å­£ç›®å½•ï¼‰
            full_folder_name = folder_name
            parent_dir_name = ""
            
            if re.search(r'(?i)season\s*\d+|s\d+|ç¬¬.+?å­£', folder_name):
                parent_dir = directory.parent
                if parent_dir.name and parent_dir != self.settings.archive_source_root:
                    parent_dir_name = parent_dir.name
                    # è®°å½•ç”µè§†å‰§åç§°ç”¨äºæ—¥å¿—
                    logger.debug(f"- ç”µè§†å‰§åç§°: {parent_dir_name}")
                    # æ„å»ºå®Œæ•´çš„æ˜¾ç¤ºåç§°(ä½¿ç”¨ - è€Œä¸æ˜¯ç‰¹æ®Šå­—ç¬¦)
                    full_folder_name = f"{parent_dir_name} - {folder_name}"
            
            # å¤„ç†ç‰¹æ®Šå­—ç¬¦ï¼Œç¡®ä¿è·¯å¾„å®‰å…¨
            safe_folder_name = re.sub(r'[:\\*?\"<>|]', '_', full_folder_name)
            if safe_folder_name != full_folder_name:
                logger.debug(f"- å¤„ç†åçš„å®‰å…¨åç§°: {safe_folder_name}")
            
            # æ£€æŸ¥ç›®å½•ä¸­çš„æ–‡ä»¶ä¿®æ”¹æ—¶é—´
            recent_files = []
            # è·å–åª’ä½“ç±»å‹
            media_type = self.get_media_type(directory)
            if not media_type:
                result["message"] = (
                    f"[è·³è¿‡] {full_folder_name}\n"
                    f"åŸå› : æœªåŒ¹é…åˆ°åª’ä½“ç±»å‹"
                )
                logger.debug(f"ç›®å½• {directory} æœªåŒ¹é…åˆ°åª’ä½“ç±»å‹")
                return result
            
            logger.info(f"åŒ¹é…åˆ°åª’ä½“ç±»å‹: {media_type}")
            
            # è·å–é˜ˆå€¼é…ç½®
            threshold = self.thresholds[media_type]
            logger.debug(f"é˜ˆå€¼è®¾ç½®: åˆ›å»ºæ—¶é—´ {threshold.creation_days} å¤©, ä¿®æ”¹æ—¶é—´ {threshold.mtime_days} å¤©")
            
            # æ‰«ææ–‡ä»¶
            logger.debug("å¼€å§‹æ‰«ææ–‡ä»¶æ—¶é—´...")
            
            # é¢„å…ˆç»Ÿè®¡æ–‡ä»¶ä¿¡æ¯
            files_info = []
            total_size = 0
            for root, _, files in os.walk(directory):
                root_path = Path(root)
                for file in files:
                    # æ£€æŸ¥æ–‡ä»¶æ‰©å±•åæ˜¯å¦åœ¨æ’é™¤åˆ—è¡¨ä¸­
                    if any(file.lower().endswith(ext.strip().lower()) for ext in self.excluded_extensions):
                        logger.debug(f"è·³è¿‡æ’é™¤çš„æ–‡ä»¶: {file}")
                        continue
                        
                    file_path = root_path / file
                    stats = file_path.stat()
                    mtime = stats.st_mtime
                    ctime = self.get_creation_time(file_path)
                    
                    # è®¡ç®—æ–‡ä»¶çš„åˆ›å»ºæ—¶é—´å’Œä¿®æ”¹æ—¶é—´è·ä»Šçš„å¤©æ•°
                    mtime_days = (time.time() - mtime) / 86400
                    ctime_days = (time.time() - ctime) / 86400
                    
                    logger.debug(f"æ–‡ä»¶: {file}")
                    logger.debug(f"- åˆ›å»ºæ—¶é—´: {ctime_days:.1f} å¤©å‰")
                    logger.debug(f"- ä¿®æ”¹æ—¶é—´: {mtime_days:.1f} å¤©å‰")
                    
                    # ä½¿ç”¨é…ç½®çš„é˜ˆå€¼
                    if ctime_days < threshold.creation_days or mtime_days < threshold.mtime_days:
                        recent_files.append((file_path, min(mtime_days, ctime_days)))
                        logger.debug(f"- çŠ¶æ€: æœªè¾¾åˆ°é˜ˆå€¼")
                    else:
                        logger.debug(f"- çŠ¶æ€: å·²è¾¾åˆ°é˜ˆå€¼")
                        # è®°å½•éœ€è¦å¤„ç†çš„æ–‡ä»¶ä¿¡æ¯
                        file_size = stats.st_size
                        total_size += file_size
                        files_info.append({
                            "path": file_path,
                            "size": file_size,
                            "relative_path": file_path.relative_to(directory)
                        })
            
            if recent_files:
                # æŒ‰æ—¶é—´æ’åºï¼Œå±•ç¤ºæœ€è¿‘çš„3ä¸ªæ–‡ä»¶
                recent_files.sort(key=lambda x: x[1])
                example_files = []
                for f, days in recent_files[:3]:
                    example_files.append(f"{f.name} ({days:.1f}å¤©)")
                
                result["message"] = (
                    f"[è·³è¿‡] {full_folder_name}\n"
                    f"åŸå› : å­˜åœ¨è¿‘æœŸåˆ›å»ºæˆ–ä¿®æ”¹çš„æ–‡ä»¶\n"
                    f"æ–‡ä»¶: {', '.join(example_files)}"
                )
                logger.debug(f"ç›®å½•åŒ…å«è¿‘æœŸæ–‡ä»¶ï¼Œè·³è¿‡å¤„ç†")
                logger.debug(f"è¿‘æœŸæ–‡ä»¶ç¤ºä¾‹: {', '.join(example_files)}")
                return result

            # è·å–ç›®æ ‡è·¯å¾„
            relative_path = directory.relative_to(self.settings.archive_source_root)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å­£æ–‡ä»¶å¤¹ï¼Œå¦‚æœæ˜¯åˆ™å¤„ç†è·¯å¾„
            if parent_dir_name and re.search(r'(?i)season\s*\d+|s\d+|ç¬¬.+?å­£', folder_name):
                # å¦‚æœæ˜¯å­£æ–‡ä»¶å¤¹ï¼Œè·å–çˆ¶ç›®å½•å’Œå½“å‰ç›®å½•å¯¹åº”çš„alistè·¯å¾„
                parent_relative_path = directory.parent.relative_to(self.settings.archive_source_root)
                source_alist_path = str(Path(self.settings.archive_source_alist) / relative_path).replace('\\', '/').lstrip("/")
                
                # ç›®æ ‡è·¯å¾„ä½¿ç”¨åŸæœ‰çš„æ–¹å¼æ„å»º
                dest_alist_path = str(Path(self.settings.archive_target_root) / relative_path).replace('\\', '/').lstrip("/")
                
                # è®°å½•è¯¦ç»†ä¿¡æ¯ï¼Œæ–¹ä¾¿è°ƒè¯•
                logger.debug(f"- å¤„ç†å­£ç›®å½•è·¯å¾„:")
                logger.debug(f"  - çˆ¶ç›®å½•: {parent_dir_name}")
                logger.debug(f"  - å­£ç›®å½•: {folder_name}")
                logger.debug(f"  - å®Œæ•´åç§°: {full_folder_name}")
                logger.debug(f"  - å®‰å…¨åç§°: {safe_folder_name}")
            else:
                # éå­£æ–‡ä»¶å¤¹ï¼Œä½¿ç”¨å¸¸è§„æ–¹å¼æ„å»ºè·¯å¾„
                source_alist_path = str(Path(self.settings.archive_source_alist) / relative_path).replace('\\', '/').lstrip("/")
                dest_alist_path = str(Path(self.settings.archive_target_root) / relative_path).replace('\\', '/').lstrip("/")
                
                # ç¡®è®¤è·¯å¾„ä¸åŒ…å«éæ³•å­—ç¬¦ï¼ˆä¸åŒ…æ‹¬æ–œæ ï¼‰
                safe_source_path = re.sub(r'[:\\*?\"<>|]', '_', source_alist_path)
                safe_dest_path = re.sub(r'[:\\*?\"<>|]', '_', dest_alist_path)
                
                if safe_source_path != source_alist_path or safe_dest_path != dest_alist_path:
                    logger.warning(f"è·¯å¾„åŒ…å«ç‰¹æ®Šå­—ç¬¦ï¼Œå°†è¢«æ›¿æ¢ï¼ˆä¿ç•™è·¯å¾„åˆ†éš”ç¬¦ï¼‰:")
                    logger.warning(f"  åŸå§‹æºè·¯å¾„: {source_alist_path}")
                    logger.warning(f"  å®‰å…¨æºè·¯å¾„: {safe_source_path}")
                    source_alist_path = safe_source_path
                    dest_alist_path = safe_dest_path
            
            logger.info(f"å‡†å¤‡å½’æ¡£: {full_folder_name}")
            logger.debug(f"- æºAlistè·¯å¾„: {source_alist_path}")
            logger.debug(f"- ç›®æ ‡Alistè·¯å¾„: {dest_alist_path}")
            logger.debug(f"- æ–‡ä»¶æ•°é‡: {len(files_info)}")
            logger.debug(f"- æ€»å¤§å°: {total_size / 1024 / 1024 / 1024:.2f} GB")

            if test_mode:
                result["message"] = (
                    f"[æµ‹è¯•] {full_folder_name}\n"
                    f"çŠ¶æ€: å¯ä»¥å½’æ¡£ï¼Œæ— è¿‘æœŸæ–‡ä»¶\n"
                    f"æ–‡ä»¶æ•°: {len(files_info)}\n"
                    f"æ€»å¤§å°: {total_size / 1024 / 1024 / 1024:.2f} GB"
                )
                result["success"] = True
                result["moved_files"] = len(files_info)
                result["total_size"] = total_size
                return result
            
            # ä½¿ç”¨Alist APIå¤åˆ¶ç›®å½•
            logger.info("å¼€å§‹ä½¿ç”¨Alist APIå¤åˆ¶ç›®å½•...")
            
            # è¯¦ç»†è®°å½•æºè·¯å¾„å’Œç›®æ ‡è·¯å¾„ï¼Œä»¥ä¾¿äºè°ƒè¯•
            logger.info(f"æºå®Œæ•´è·¯å¾„: {source_alist_path}")
            logger.info(f"ç›®æ ‡å®Œæ•´è·¯å¾„: {dest_alist_path}")
            
            success = await self.alist_client.copy_directory(source_alist_path, dest_alist_path)
            
            if success:
                logger.info("ç›®å½•å¤åˆ¶æˆåŠŸï¼Œå¼€å§‹éªŒè¯æ–‡ä»¶...")
                # éªŒè¯ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
                all_verified = True
                moved_files = 0
                
                for file_info in files_info:
                    # è·å–æœ¬åœ°å’ŒAlistçš„ç›¸å¯¹è·¯å¾„
                    dst_file = Path(self.settings.archive_target_root) / relative_path / file_info["relative_path"]
                    
                    logger.debug(f"éªŒè¯æ–‡ä»¶: {file_info['path'].name}")
                    if not self.verify_files(file_info["path"], dst_file):
                        logger.error(f"æ–‡ä»¶éªŒè¯å¤±è´¥: {file_info['path'].name}")
                        all_verified = False
                        break
                    moved_files += 1
                    logger.debug(f"- éªŒè¯æˆåŠŸ")
                
                if all_verified:
                    result["total_size"] = total_size
                    result["moved_files"] = moved_files
                    
                    logger.info(f"æ‰€æœ‰æ–‡ä»¶éªŒè¯æˆåŠŸ")
                    logger.info(f"- ç§»åŠ¨æ–‡ä»¶æ•°: {moved_files}")
                    logger.info(f"- æ€»å¤§å°: {total_size / 1024 / 1024 / 1024:.2f} GB")
                    
                    # æ·»åŠ åˆ°åˆ é™¤é˜Ÿåˆ—
                    if self.settings.archive_delete_source:
                        self._add_to_pending_deletion(directory)
                        logger.info(f"å·²å°†ç›®å½•æ·»åŠ åˆ°å¾…åˆ é™¤é˜Ÿåˆ—: {directory}")
                    
                    result["message"] = (
                        f"[å½’æ¡£] {full_folder_name}\n"
                        f"æ–‡ä»¶æ•°: {moved_files}\n"
                        f"æ€»å¤§å°: {total_size / 1024 / 1024 / 1024:.2f} GB"
                    )
                    
                    result["success"] = True
                else:
                    # å¦‚æœéªŒè¯å¤±è´¥ï¼Œåˆ é™¤ç›®æ ‡ç›®å½•
                    logger.error("æ–‡ä»¶éªŒè¯å¤±è´¥ï¼Œæ­£åœ¨åˆ é™¤ç›®æ ‡ç›®å½•...")
                    await self.alist_client.delete(dest_alist_path)
                    result["message"] = f"[é”™è¯¯] {full_folder_name}\næ–‡ä»¶éªŒè¯å¤±è´¥\næºè·¯å¾„: {source_alist_path}"
            else:
                logger.error("Alist APIå¤åˆ¶ç›®å½•å¤±è´¥")
                result["message"] = f"[é”™è¯¯] {full_folder_name}\nå¤åˆ¶å¤±è´¥\næºè·¯å¾„: {source_alist_path}\nç›®æ ‡è·¯å¾„: {dest_alist_path}"
            
        except Exception as e:
            result["message"] = f"[é”™è¯¯] å½’æ¡£å¤±è´¥ {full_folder_name}: {str(e)}"
            logger.error(f"å¤„ç†ç›®å½•å¤±è´¥ {directory}: {e}", exc_info=True)
            
        return result
    
    async def archive(self, test_mode: bool = False):
        """æ‰§è¡Œå½’æ¡£å¤„ç†
        
        Args:
            test_mode: æ˜¯å¦ä¸ºæµ‹è¯•æ¨¡å¼ï¼ˆåªè¯†åˆ«ä¸æ‰§è¡Œï¼‰
            
        Returns:
            Dict: å¤„ç†ç»“æœæ‘˜è¦å’Œè¯¦æƒ…
        """
        if self._is_running:
            logger.warning("å½’æ¡£ä»»åŠ¡å·²åœ¨è¿è¡Œä¸­")
            return {
                "summary": "å½’æ¡£ä»»åŠ¡å·²åœ¨è¿è¡Œä¸­",
                "total_processed": 0,
                "total_size": 0,
                "results": []
            }
            
        try:
            self._stop_flag = False
            self._is_running = True
            
            service_manager = self._get_service_manager()
            
            # åˆå§‹åŒ–ç»“æœå˜é‡
            total_processed = 0
            total_size = 0
            success_results = []
            all_results = []  # æ–°å¢ï¼šä¿å­˜æ‰€æœ‰å¤„ç†ç»“æœ
            
            # åœ¨å¼€å§‹å½’æ¡£æ—¶å‘é€Telegramé€šçŸ¥
            start_msg = "ğŸ” å¼€å§‹å½’æ¡£æµ‹è¯•..." if test_mode else "ğŸš€ å¼€å§‹å½’æ¡£å¤„ç†..."
            logger.info(start_msg)
            await service_manager.telegram_service.send_message(start_msg)
            
            # æ£€æŸ¥é…ç½®
            logger.debug(f"å½“å‰é…ç½®:")
            logger.debug(f"- æœ¬åœ°æºç›®å½•: {self.settings.archive_source_root}")
            logger.debug(f"- Alistæºç›®å½•: {self.settings.archive_source_alist}")
            logger.debug(f"- ç›®æ ‡ç›®å½•: {self.settings.archive_target_root}")
            
            # æ£€æŸ¥æœ¬åœ°æºç›®å½•
            source_dir = Path(self.settings.archive_source_root)
            if not source_dir.exists():
                error_msg = f"æœ¬åœ°æºç›®å½•ä¸å­˜åœ¨: {source_dir}"
                logger.error(error_msg)
                await service_manager.telegram_service.send_message(f"âŒ {error_msg}")
                return {
                    "summary": error_msg,
                    "total_processed": 0,
                    "total_size": 0,
                    "results": []
                }
            
            # æ£€æŸ¥ç›®å½•æƒé™
            try:
                test_file = source_dir / ".archive_test"
                test_file.touch()
                test_file.unlink()
            except Exception as e:
                error_msg = f"æœ¬åœ°æºç›®å½•æƒé™æ£€æŸ¥å¤±è´¥: {source_dir}, é”™è¯¯: {str(e)}"
                logger.error(error_msg)
                await service_manager.telegram_service.send_message(f"âŒ {error_msg}")
                return {
                    "summary": error_msg,
                    "total_processed": 0,
                    "total_size": 0,
                    "results": []
                }
            
            # è¦å¤„ç†çš„ç›®æ ‡ç›®å½•
            target_dir = Path(self.settings.archive_source_root)
            
            # éå†ç›®æ ‡ç›®å½•ä¸‹çš„æ‰€æœ‰å­ç›®å½•
            for root, dirs, files in os.walk(target_dir):
                if self._stop_flag:
                    break
                    
                root_path = Path(root)
                # åªå¤„ç†åŒ…å«æ–‡ä»¶çš„ç›®å½•ï¼ˆå¶å­ç›®å½•ï¼‰
                if files and not any(d.startswith('.') for d in root_path.parts):
                    # ä»…å¯¹åŒ…å«æ–‡ä»¶çš„ç›®å½•è®°å½•è¯¦ç»†æ—¥å¿—
                    if len(files) > 0:
                        logger.debug(f"\nå¤„ç†ç›®å½•: {root_path}")
                        logger.debug(f"- ç›¸å¯¹è·¯å¾„: {root_path.relative_to(source_dir)}")
                        logger.debug(f"- åŒ…å«æ–‡ä»¶æ•°: {len(files)}")
                    
                    result = await self.process_directory(root_path, test_mode)
                    if result["success"]:
                        total_processed += result["moved_files"]
                        total_size += result["total_size"]
                        if "[å½’æ¡£]" in result["message"]:
                            success_results.append(result["message"])
                    
                    # æ— è®ºæ˜¯å¦æˆåŠŸï¼Œéƒ½æ·»åŠ åˆ°æ‰€æœ‰ç»“æœä¸­
                    all_results.append(result)
                    
                    # è®©å‡ºæ§åˆ¶æƒ
                    await asyncio.sleep(0)
            
            # ç”Ÿæˆæ±‡æ€»æ¶ˆæ¯
            summary = (
                f"âœ… å½’æ¡£{'æµ‹è¯•' if test_mode else ''}å®Œæˆ\n"
                f"ğŸ“ {'è¯†åˆ«' if test_mode else 'å¤„ç†'}æ–‡ä»¶: {total_processed} ä¸ª\n"
                f"ğŸ’¾ æ€»å¤§å°: {total_size / 1024 / 1024 / 1024:.2f} GB"
            )
            logger.info(summary)
            
            # å‘é€æœ€ç»ˆçš„æ±‡æ€»æ¶ˆæ¯åˆ°Telegram
            await service_manager.telegram_service.send_message(summary)
            
            # å¦‚æœæœ‰æˆåŠŸå½’æ¡£çš„ç»“æœï¼Œå•ç‹¬å‘é€åˆ°Telegram
            if success_results:
                # æ ¼å¼åŒ–æ¯ä¸ªç»“æœï¼Œå¢å¼ºç”µè§†å‰§ç›®å½•çš„æ˜¾ç¤º
                formatted_results = []
                for result in success_results:
                    # ä»ç»“æœæ¶ˆæ¯ä¸­æå–ç›¸å…³ä¿¡æ¯
                    folder_name = ""
                    file_count = 0
                    total_size_gb = 0.0
                    
                    # æå– [å½’æ¡£] åé¢çš„æ–‡ä»¶å¤¹åç§°
                    if folder_match := re.search(r'\[å½’æ¡£\] ([^\n]+)', result):
                        folder_name = folder_match.group(1)
                    
                    # æå–æ–‡ä»¶æ•°é‡
                    if files_match := re.search(r'æ–‡ä»¶æ•°: (\d+)', result):
                        file_count = int(files_match.group(1))
                    
                    # æå–æ–‡ä»¶å¤§å°
                    if size_match := re.search(r'æ€»å¤§å°: ([0-9.]+) GB', result):
                        total_size_gb = float(size_match.group(1))
                    
                    # æŸ¥æ‰¾è¯¥æ–‡ä»¶å¤¹å¯¹åº”çš„å‰§é›†ä¿¡æ¯
                    show_name = ""
                    for log_entry in self.logger_history:
                        if f"å¼€å§‹å¤„ç†ç›®å½•" in log_entry and folder_name in log_entry:
                            # æ‰¾åˆ°äº†å¤„ç†è¯¥ç›®å½•çš„æ—¥å¿—ï¼ŒæŸ¥æ‰¾åç»­çš„ç”µè§†å‰§åç§°
                            index = self.logger_history.index(log_entry)
                            # æŸ¥æ‰¾åé¢å‡ æ¡æ—¥å¿—ä¸­æ˜¯å¦æœ‰ç”µè§†å‰§åç§°
                            for i in range(index, min(index + 5, len(self.logger_history))):
                                if "ç”µè§†å‰§åç§°" in self.logger_history[i]:
                                    show_name_match = re.search(r'- ç”µè§†å‰§åç§°: (.+)', self.logger_history[i])
                                    if show_name_match:
                                        show_name = show_name_match.group(1)
                                        break
                            break
                    
                    # æ„å»ºæ ¼å¼åŒ–çš„ç»“æœå­—ç¬¦ä¸²
                    if show_name and ("Season" in folder_name or "season" in folder_name):
                        # è¿™æ˜¯ä¸€ä¸ªç”µè§†å‰§å­£æ–‡ä»¶å¤¹ï¼Œæ˜¾ç¤ºå‰§åå’Œå­£ä¿¡æ¯
                        formatted_results.append(f"{show_name} - {folder_name} ({file_count}ä¸ªæ–‡ä»¶, {total_size_gb:.2f} GB)")
                    else:
                        # å…¶ä»–æ–‡ä»¶å¤¹ï¼Œåªæ˜¾ç¤ºæ–‡ä»¶å¤¹å
                        formatted_results.append(f"{folder_name} ({file_count}ä¸ªæ–‡ä»¶, {total_size_gb:.2f} GB)")
                
                success_message = "å½’æ¡£æˆåŠŸçš„æ–‡ä»¶å¤¹:\n\n" + "\n".join(formatted_results)
                # å¦‚æœæ¶ˆæ¯å¤ªé•¿ï¼Œåªä¿ç•™å‰20ä¸ªç»“æœ
                if len(success_message) > 3000:
                    formatted_results = formatted_results[:20]
                    success_message = "å½’æ¡£æˆåŠŸçš„æ–‡ä»¶å¤¹ï¼ˆä»…æ˜¾ç¤ºå‰20ä¸ªï¼‰:\n\n" + "\n".join(formatted_results)
                await service_manager.telegram_service.send_message(success_message)
            
            # å¦‚æœé…ç½®äº†è‡ªåŠ¨è¿è¡ŒSTRMæ‰«æä¸”ä¸æ˜¯æµ‹è¯•æ¨¡å¼
            if not test_mode and self.settings.archive_auto_strm and total_processed > 0:
                logger.info("å¼€å§‹è‡ªåŠ¨STRMæ‰«æ...")
                await service_manager.telegram_service.send_message("ğŸ”„ å¼€å§‹è‡ªåŠ¨STRMæ‰«æ...")
                await service_manager.strm_service.strm()
            
            # è¿”å›ç»“æœ
            return {
                "summary": summary,
                "total_processed": total_processed,
                "total_size": total_size,
                "results": all_results  # ä¿®æ”¹ï¼šæ— è®ºæ˜¯æµ‹è¯•æ¨¡å¼è¿˜æ˜¯æ­£å¸¸æ¨¡å¼ï¼Œéƒ½è¿”å›å®Œæ•´ç»“æœ
            }
            
        except Exception as e:
            error_msg = f"âŒ å½’æ¡£{'æµ‹è¯•' if test_mode else 'å¤„ç†'}å‡ºé”™: {str(e)}"
            logger.error(error_msg)
            service_manager = self._get_service_manager()
            await service_manager.telegram_service.send_message(error_msg)
            return {
                "summary": error_msg,
                "total_processed": 0,
                "total_size": 0,
                "results": []
            }
        finally:
            self._is_running = False

    def _load_media_types(self) -> Dict[str, Dict]:
        """ä»config/archive.jsonåŠ è½½åª’ä½“ç±»å‹é…ç½®"""
        config_file = "config/archive.json"
        if os.path.exists(config_file):
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"åŠ è½½åª’ä½“ç±»å‹é…ç½®å¤±è´¥: {e}")
        return json.loads(self.settings.archive_media_types)

    def save_media_types(self):
        """ä¿å­˜åª’ä½“ç±»å‹é…ç½®åˆ°config/archive.json"""
        config_file = "config/archive.json"
        try:
            # ç¡®ä¿configç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(config_file), exist_ok=True)
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(self.media_types, f, ensure_ascii=False, indent=4)
            logger.info("åª’ä½“ç±»å‹é…ç½®å·²ä¿å­˜")
        except Exception as e:
            logger.error(f"ä¿å­˜åª’ä½“ç±»å‹é…ç½®å¤±è´¥: {e}")
            
    @property
    def media_types(self) -> Dict[str, Dict]:
        return self._media_types
        
    @media_types.setter
    def media_types(self, value: Dict[str, Dict]):
        self._media_types = value
        # å½“media_typesè¢«æ›´æ–°æ—¶ï¼Œè‡ªåŠ¨ä¿å­˜åˆ°æ–‡ä»¶
        self.save_media_types()
        # æ›´æ–°é˜ˆå€¼é…ç½®
        self.thresholds = {
            name: MediaThreshold(
                info["creation_days"],
                info["mtime_days"]
            ) for name, info in self._media_types.items()
        }

    async def process_file(self, source_path: Path) -> Dict:
        """å¤„ç†å•ä¸ªæ–‡ä»¶çš„å½’æ¡£
        
        Args:
            source_path: æºæ–‡ä»¶è·¯å¾„
            
        Returns:
            Dict: å¤„ç†ç»“æœï¼ŒåŒ…å«successã€messageå’Œsizeå­—æ®µ
        """
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æ˜¯æ–‡ä»¶
            if not source_path.is_file():
                return {
                    "success": False,
                    "message": f"âŒ {source_path} ä¸æ˜¯æ–‡ä»¶",
                    "size": 0
                }
            
            # è·å–æ–‡ä»¶å¤§å°
            file_size = source_path.stat().st_size
            
            # è·å–åª’ä½“ç±»å‹
            media_type = self.get_media_type(source_path)
            if not media_type:
                return {
                    "success": False,
                    "message": f"âŒ {source_path} æœªåŒ¹é…åˆ°åª’ä½“ç±»å‹",
                    "size": 0
                }
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ»¡è¶³é˜ˆå€¼æ¡ä»¶
            creation_time = self.get_creation_time(source_path)
            mtime = source_path.stat().st_mtime
            
            threshold = self.thresholds[media_type]
            creation_days = (time.time() - creation_time) / (24 * 3600)
            mtime_days = (time.time() - mtime) / (24 * 3600)
            
            if creation_days < threshold.creation_days or mtime_days < threshold.mtime_days:
                return {
                    "success": False,
                    "message": f"â³ {source_path} æœªè¾¾åˆ°å½’æ¡£é˜ˆå€¼",
                    "size": 0
                }
            
            # æ„å»ºç›®æ ‡è·¯å¾„ï¼Œä¿æŒç›¸å¯¹è·¯å¾„ç»“æ„
            relative_path = source_path.relative_to(self.settings.archive_source_root)
            dest_path = Path(self.settings.archive_target_root) / relative_path
            
            # æ„å»ºAlistè·¯å¾„
            source_alist_path = str(source_path).replace(str(self.settings.archive_source_root), "").lstrip("/")
            dest_alist_path = str(dest_path).replace(str(self.settings.archive_target_root), "").lstrip("/")
            
            # å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼ŒéªŒè¯æ–‡ä»¶
            if dest_path.exists():
                if self.verify_files(source_path, dest_path):
                    # å¦‚æœé…ç½®äº†åˆ é™¤æºæ–‡ä»¶ä¸”éªŒè¯é€šè¿‡
                    if self.settings.archive_delete_source:
                        self._add_to_pending_deletion(source_path)
                        return {
                            "success": True,
                            "message": f"ğŸ—‘ï¸ {source_path} å·²å­˜åœ¨äºç›®æ ‡ä½ç½®ï¼Œå·²åŠ å…¥å»¶è¿Ÿåˆ é™¤é˜Ÿåˆ—",
                            "size": file_size
                        }
                    return {
                        "success": False,
                        "message": f"â­ï¸ {source_path} å·²å­˜åœ¨äºç›®æ ‡ä½ç½®",
                        "size": 0
                    }
                else:
                    return {
                        "success": False,
                        "message": f"âŒ {source_path} ç›®æ ‡ä½ç½®å­˜åœ¨ä¸åŒæ–‡ä»¶",
                        "size": 0
                    }
            
            # ä½¿ç”¨Alist APIå¤åˆ¶æ–‡ä»¶
            success = await self.alist_client.copy_file(source_alist_path, dest_alist_path)
            
            if not success:
                return {
                    "success": False,
                    "message": f"âŒ {source_path} å¤åˆ¶å¤±è´¥",
                    "size": 0
                }
            
            # éªŒè¯å¤åˆ¶åçš„æ–‡ä»¶
            if not self.verify_files(source_path, dest_path):
                # å¦‚æœéªŒè¯å¤±è´¥ï¼Œåˆ é™¤ç›®æ ‡æ–‡ä»¶
                await self.alist_client.delete(dest_alist_path)
                return {
                    "success": False,
                    "message": f"âŒ {source_path} å¤åˆ¶éªŒè¯å¤±è´¥",
                    "size": 0
                }
            
            # å¦‚æœé…ç½®äº†åˆ é™¤æºæ–‡ä»¶
            if self.settings.archive_delete_source:
                self._add_to_pending_deletion(source_path)
                return {
                    "success": True,
                    "message": f"âœ… {source_path} -> {dest_path} (å·²åŠ å…¥å»¶è¿Ÿåˆ é™¤é˜Ÿåˆ—)",
                    "size": file_size
                }
            
            return {
                "success": True,
                "message": f"âœ… {source_path} -> {dest_path}",
                "size": file_size
            }
            
        except Exception as e:
            logger.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥ {source_path}: {e}")
            return {
                "success": False,
                "message": f"âŒ {source_path} å¤„ç†å¤±è´¥: {str(e)}",
                "size": 0
            } 