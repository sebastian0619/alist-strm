from pathlib import Path
import shutil
import time
import hashlib
from datetime import datetime
import os
from typing import NamedTuple, Optional, List, Dict, Tuple
from loguru import logger
from config import Settings
import asyncio
import importlib
import json
from services.alist_client import AlistClient
import re

class MediaThreshold(NamedTuple):
    """åª’ä½“æ–‡ä»¶çš„æ—¶é—´é˜ˆå€¼é…ç½®"""
    creation_days: int
    mtime_days: int

class ArchiveService:
    def __init__(self):
        self.settings = Settings()
        self._stop_flag = False
        self._is_running = False
        self._current_media_type = None  # å½“å‰å¤„ç†çš„åª’ä½“ç±»å‹
        
        # æ·»åŠ æ—¥å¿—å†å²è®°å½•åˆ—è¡¨
        self.logger_history = []
        # æ·»åŠ æ—¥å¿—å¤„ç†å™¨
        self._setup_logger_handler()
        
        # ä»é…ç½®åŠ è½½è¦æ’é™¤çš„æ–‡ä»¶æ‰©å±•å
        self.excluded_extensions = set(
            ext.strip().lower() for ext in self.settings.archive_excluded_extensions.split(',')
        )
        
        # ä»æ–‡ä»¶åŠ è½½åª’ä½“ç±»å‹é…ç½®
        self._media_types = self._load_media_types()
        # åˆå§‹åŒ–é˜ˆå€¼é…ç½®
        self.thresholds = {
            name: MediaThreshold(
                info["creation_days"],
                info["mtime_days"]
            ) for name, info in self._media_types.items()
        }
        
        # å®šä¹‰å¾…åˆ é™¤æ–‡ä»¶åˆ—è¡¨çš„JSONæ–‡ä»¶è·¯å¾„
        self._pending_deletions_file = os.path.join("/app/cache", "pending_deletions.json")
        # åˆå§‹åŒ–å¾…åˆ é™¤æ–‡ä»¶é˜Ÿåˆ—
        self._pending_deletions = self._load_pending_deletions()
        # åˆ é™¤å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰- ä»é…ç½®ä¸­è¯»å–
        self._deletion_delay = self.settings.archive_delete_delay_days * 24 * 3600  # è½¬æ¢ä¸ºç§’
        
        # åˆå§‹åŒ–AlistClient
        self.alist_client = AlistClient(
            self.settings.alist_url,
            self.settings.alist_token
        )
        
        # åˆ é™¤æ£€æŸ¥ä»»åŠ¡å°†åœ¨initializeæ–¹æ³•ä¸­å¯åŠ¨
        self._deletion_check_task = None
    
    def _load_pending_deletions(self) -> list:
        """ä»JSONæ–‡ä»¶åŠ è½½å¾…åˆ é™¤åˆ—è¡¨"""
        try:
            # ç¡®ä¿cacheç›®å½•å­˜åœ¨
            os.makedirs("/app/cache", exist_ok=True)
            if os.path.exists(self._pending_deletions_file):
                with open(self._pending_deletions_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    # è½¬æ¢è·¯å¾„å­—ç¬¦ä¸²å›Pathå¯¹è±¡
                    for item in data:
                        if 'path' in item and isinstance(item['path'], str):
                            item['path'] = Path(item['path'])
                    logger.info(f"ä» {self._pending_deletions_file} åŠ è½½äº† {len(data)} ä¸ªå¾…åˆ é™¤é¡¹ç›®")
                    return data
            else:
                logger.info(f"å¾…åˆ é™¤æ–‡ä»¶åˆ—è¡¨ä¸å­˜åœ¨: {self._pending_deletions_file}")
        except Exception as e:
            logger.error(f"åŠ è½½å¾…åˆ é™¤åˆ—è¡¨å¤±è´¥: {e}")
        return []
    
    def _save_pending_deletions(self):
        """å°†å¾…åˆ é™¤åˆ—è¡¨ä¿å­˜åˆ°JSONæ–‡ä»¶"""
        try:
            # ç¡®ä¿cacheç›®å½•å­˜åœ¨
            os.makedirs("/app/cache", exist_ok=True)
            
            # å°†Pathå¯¹è±¡è½¬æ¢ä¸ºå­—ç¬¦ä¸²ä»¥ä¾¿JSONåºåˆ—åŒ–
            data_to_save = []
            for item in self._pending_deletions:
                data_item = item.copy()
                if 'path' in data_item and isinstance(data_item['path'], Path):
                    data_item['path'] = str(data_item['path'])
                data_to_save.append(data_item)
                
            with open(self._pending_deletions_file, 'w', encoding='utf-8') as f:
                json.dump(data_to_save, f, ensure_ascii=False, indent=2)
            logger.info(f"æˆåŠŸä¿å­˜ {len(data_to_save)} ä¸ªå¾…åˆ é™¤é¡¹ç›®åˆ° {self._pending_deletions_file}")
        except Exception as e:
            logger.error(f"ä¿å­˜å¾…åˆ é™¤åˆ—è¡¨å¤±è´¥: {e}")
    
    def _setup_logger_handler(self):
        """è®¾ç½®æ—¥å¿—å¤„ç†å™¨ï¼Œè®°å½•æ—¥å¿—å†å²"""
        class LoggerHistoryHandler:
            def __init__(self, history_list):
                self.history_list = history_list
                
            def write(self, record):
                # ä¿®å¤ï¼šå¤„ç†ä¸åŒç±»å‹çš„record
                if isinstance(record, dict) and "message" in record:
                    # æ—§æ ¼å¼ï¼Œä¿æŒå…¼å®¹
                    message = record["message"]
                else:
                    # æ–°æ ¼å¼ï¼Œrecordç›´æ¥æ˜¯æ¶ˆæ¯å­—ç¬¦ä¸²
                    message = str(record)
                    
                self.history_list.append(message)
                # ä¿æŒæ—¥å¿—å†å²åœ¨ä¸€ä¸ªåˆç†çš„å¤§å°
                if len(self.history_list) > 1000:
                    self.history_list.pop(0)
        
        # æ·»åŠ è‡ªå®šä¹‰å¤„ç†å™¨åˆ°logger
        logger.add(LoggerHistoryHandler(self.logger_history).write)
    
    async def initialize(self):
        """åˆå§‹åŒ–æœåŠ¡ï¼Œå¯åŠ¨åå°ä»»åŠ¡"""
        if not self._deletion_check_task:
            self._deletion_check_task = asyncio.create_task(self._check_pending_deletions())
    
    async def shutdown(self):
        """å…³é—­æœåŠ¡ï¼Œæ¸…ç†èµ„æº"""
        if self._deletion_check_task:
            self._deletion_check_task.cancel()
            try:
                await self._deletion_check_task
            except asyncio.CancelledError:
                pass
            self._deletion_check_task = None
        
        if self.alist_client:
            await self.alist_client.close()
    
    def _get_service_manager(self):
        """åŠ¨æ€è·å–service_managerä»¥é¿å…å¾ªç¯ä¾èµ–"""
        module = importlib.import_module('services.service_manager')
        return module.service_manager
    
    def get_creation_time(self, path: Path) -> float:
        """è·å–æ–‡ä»¶æˆ–ç›®å½•çš„åˆ›å»ºæ—¶é—´"""
        try:
            stat = path.stat()
            return getattr(stat, 'st_birthtime', stat.st_mtime)
        except Exception as e:
            logger.error(f"è·å–åˆ›å»ºæ—¶é—´å¤±è´¥ {path}: {e}")
            return time.time()
    
    def calculate_file_hash(self, file_path: Path) -> Optional[str]:
        """è®¡ç®—æ–‡ä»¶çš„MD5å“ˆå¸Œå€¼"""
        try:
            md5_hash = hashlib.md5()
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    md5_hash.update(chunk)
            return md5_hash.hexdigest()
        except Exception as e:
            logger.error(f"è®¡ç®—æ–‡ä»¶å“ˆå¸Œå¤±è´¥ {file_path}: {e}")
            return None
    
    def verify_files(self, source: Path, dest: Path) -> bool:
        """éªŒè¯æºæ–‡ä»¶å’Œç›®æ ‡æ–‡ä»¶æ˜¯å¦ç›¸åŒ"""
        try:
            if not source.exists() or not dest.exists():
                return False
            
            source_hash = self.calculate_file_hash(source)
            dest_hash = self.calculate_file_hash(dest)
            
            return source_hash and dest_hash and source_hash == dest_hash
        except Exception as e:
            logger.error(f"æ–‡ä»¶éªŒè¯å¤±è´¥: {e}")
            return False
    
    async def has_recent_files(self, directory: Path, mtime_threshold: int) -> Tuple[bool, List[Path]]:
        """æ£€æŸ¥ç›®å½•ä¸­æ˜¯å¦æœ‰æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶ï¼ˆæ’é™¤æŒ‡å®šæ‰©å±•åï¼‰"""
        recent_files = []
        try:
            for file_path in directory.rglob("*"):
                if self._stop_flag:
                    break
                    
                if file_path.is_file() and file_path.suffix.lower() not in self.excluded_extensions:
                    mtime = file_path.stat().st_mtime
                    age_days = (time.time() - mtime) / 86400
                    if age_days < mtime_threshold:
                        recent_files.append(file_path)
                        
                # è®©å‡ºæ§åˆ¶æƒ
                await asyncio.sleep(0)
        except Exception as e:
            logger.error(f"æ£€æŸ¥æœ€è¿‘æ–‡ä»¶å¤±è´¥: {e}")
            
        return bool(recent_files), recent_files
    
    def stop(self):
        """åœæ­¢å½’æ¡£å¤„ç†"""
        if not self._is_running:
            return
        self._stop_flag = True
        logger.info("æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨åœæ­¢å½’æ¡£...")
    
    async def _check_pending_deletions(self):
        """å®šæœŸæ£€æŸ¥å¾…åˆ é™¤æ–‡ä»¶ï¼Œåˆ é™¤è¶…è¿‡å»¶è¿Ÿæ—¶é—´çš„æ–‡ä»¶"""
        logger.info("å¾…åˆ é™¤æ–‡ä»¶æ£€æŸ¥ä»»åŠ¡å·²å¯åŠ¨")
        
        # åˆå§‹åŠ è½½ï¼Œç¡®ä¿æœ‰æœ€æ–°æ•°æ®
        self._pending_deletions = self._load_pending_deletions()
        logger.info(f"åˆå§‹åŒ–æ—¶å¾…åˆ é™¤æ–‡ä»¶æ•°é‡: {len(self._pending_deletions)}")
        
        while True:
            try:
                current_time = time.time()
                items_to_delete = []
                items_to_remove = []  # è®°å½•éœ€è¦ä»åˆ—è¡¨ä¸­ç§»é™¤çš„é¡¹ç›®
                
                # ç¡®ä¿ä½¿ç”¨æœ€æ–°åˆ—è¡¨
                if len(self._pending_deletions) > 0:
                    logger.info(f"æ£€æŸ¥å¾…åˆ é™¤æ–‡ä»¶åˆ—è¡¨ï¼Œå…± {len(self._pending_deletions)} ä¸ªé¡¹ç›®")
                
                # æ£€æŸ¥æ¯ä¸ªé¡¹ç›®
                for item in self._pending_deletions:
                    path = item["path"]
                    
                    # å¦‚æœæ–‡ä»¶å·²ç»ä¸å­˜åœ¨ï¼Œç›´æ¥ä»åˆ—è¡¨ä¸­ç§»é™¤
                    if not path.exists():
                        items_to_remove.append(item)
                        logger.info(f"æ–‡ä»¶å·²ä¸å­˜åœ¨ï¼Œå°†ä»å¾…åˆ é™¤åˆ—è¡¨ä¸­ç§»é™¤: {path}")
                        continue
                    
                    # å¦‚æœå·²åˆ°åˆ é™¤æ—¶é—´ï¼Œæ·»åŠ åˆ°å¾…åˆ é™¤åˆ—è¡¨
                    if current_time >= item["delete_time"]:
                        items_to_delete.append(item)
                
                # å¤„ç†éœ€è¦ä»åˆ—è¡¨ä¸­ç§»é™¤çš„é¡¹ç›®ï¼ˆæ–‡ä»¶ä¸å­˜åœ¨çš„æƒ…å†µï¼‰
                for item in items_to_remove:
                    self._pending_deletions.remove(item)
                    # å‘é€é€šçŸ¥
                    service_manager = self._get_service_manager()
                    notification_msg = f"ğŸ“ ä»å¾…åˆ é™¤åˆ—è¡¨ç§»é™¤ä¸å­˜åœ¨çš„æ–‡ä»¶:\n{item['path']}"
                    await service_manager.telegram_service.send_message(notification_msg)
                
                # æ‰§è¡Œåˆ é™¤æ“ä½œ
                successful_deletions = []  # è®°å½•æˆåŠŸåˆ é™¤çš„é¡¹ç›®ï¼Œæ–¹ä¾¿åç»­ä»é˜Ÿåˆ—ç§»é™¤
                for item in items_to_delete:
                    path = item["path"]
                    try:
                        delete_success = await self._delete_file(path)
                        if delete_success:
                            logger.info(f"å·²åˆ é™¤å»¶è¿Ÿæ–‡ä»¶: {path}")
                            successful_deletions.append(item)  # åªæœ‰æˆåŠŸåˆ é™¤çš„æ‰æ·»åŠ åˆ°æ­¤åˆ—è¡¨
                            
                            # å‘é€åˆ é™¤é€šçŸ¥
                            service_manager = self._get_service_manager()
                            notification_msg = f"ğŸ—‘ï¸ å·²åˆ é™¤å»¶è¿Ÿæ–‡ä»¶:\n{path}"
                            await service_manager.telegram_service.send_message(notification_msg)
                        else:
                            logger.warning(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ï¼Œå°†ä¿ç•™åœ¨é˜Ÿåˆ—ä¸­ç¨åé‡è¯•: {path}")
                    except Exception as e:
                        logger.error(f"åˆ é™¤æ–‡ä»¶æ—¶å‘ç”Ÿå¼‚å¸¸ {path}: {e}")
                        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä»åˆ—è¡¨ä¸­ç§»é™¤
                        if not path.exists():
                            successful_deletions.append(item)
                            logger.info(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå·²ä»å¾…åˆ é™¤åˆ—è¡¨ä¸­ç§»é™¤: {path}")
                
                # ä»é˜Ÿåˆ—ä¸­ç§»é™¤æˆåŠŸåˆ é™¤çš„é¡¹ç›®
                for item in successful_deletions:
                    if item in self._pending_deletions:
                        self._pending_deletions.remove(item)
                
                # å¦‚æœæœ‰ä»»ä½•æ›´æ”¹ï¼Œä¿å­˜æ›´æ–°åçš„åˆ—è¡¨
                if successful_deletions or items_to_remove:
                    self._save_pending_deletions()
                    logger.info(f"å·²åˆ é™¤ {len(successful_deletions)} ä¸ªè¿‡æœŸæ–‡ä»¶ï¼Œç§»é™¤ {len(items_to_remove)} ä¸ªä¸å­˜åœ¨çš„è®°å½•ï¼Œå‰©ä½™ {len(self._pending_deletions)} ä¸ªå¾…åˆ é™¤é¡¹ç›®")
                    
            except Exception as e:
                logger.error(f"æ£€æŸ¥å¾…åˆ é™¤æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            finally:
                await asyncio.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡ï¼Œç¡®ä¿åŠæ—¶å¤„ç†

    def _add_to_pending_deletion(self, path: Path):
        """å°†æ–‡ä»¶æˆ–ç›®å½•æ·»åŠ åˆ°å¾…åˆ é™¤åˆ—è¡¨
        
        Args:
            path: è¦åˆ é™¤çš„æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„
        """
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç»åœ¨å¾…åˆ é™¤åˆ—è¡¨ä¸­
            for item in self._pending_deletions:
                if str(item["path"]) == str(path):
                    logger.info(f"æ–‡ä»¶å·²åœ¨å¾…åˆ é™¤åˆ—è¡¨ä¸­: {path}")
                    return
            
            # è®¡ç®—åˆ é™¤æ—¶é—´ï¼ˆå½“å‰æ—¶é—´ + å»¶è¿Ÿæ—¶é—´ï¼‰
            delete_time = time.time() + self._deletion_delay
            
            # æ·»åŠ åˆ°å¾…åˆ é™¤åˆ—è¡¨
            self._pending_deletions.append({
                "path": path,
                "delete_time": delete_time
            })
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            self._save_pending_deletions()
            
            # è®°å½•æ·»åŠ ä¿¡æ¯
            logger.info(f"å·²å°†æ–‡ä»¶æ·»åŠ åˆ°å¾…åˆ é™¤åˆ—è¡¨: {path}")
            
            # å‘é€é€šçŸ¥
            try:
                service_manager = self._get_service_manager()
                delete_time_str = datetime.fromtimestamp(delete_time).strftime("%Y-%m-%d %H:%M:%S")
                notification_msg = f"ğŸ“ æ–‡ä»¶å·²åŠ å…¥å¾…åˆ é™¤åˆ—è¡¨:\n{path}\nè®¡åˆ’åˆ é™¤æ—¶é—´: {delete_time_str}"
                asyncio.create_task(service_manager.telegram_service.send_message(notification_msg))
            except Exception as e:
                logger.error(f"å‘é€é€šçŸ¥å¤±è´¥: {e}")
            
        except Exception as e:
            logger.error(f"æ·»åŠ æ–‡ä»¶åˆ°å¾…åˆ é™¤åˆ—è¡¨å¤±è´¥: {e}")

    async def _delete_file(self, path: Path) -> bool:
        """åˆ é™¤æ–‡ä»¶æˆ–ç›®å½•
        
        Args:
            path: è¦åˆ é™¤çš„æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸåˆ é™¤
        """
        try:
            if not path.exists():
                logger.info(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— éœ€åˆ é™¤: {path}")
                return True
                
            if path.is_dir():
                shutil.rmtree(str(path))
            else:
                path.unlink()
                
            # è®©å‡ºæ§åˆ¶æƒ
            await asyncio.sleep(0)
                
            logger.info(f"æˆåŠŸåˆ é™¤æ–‡ä»¶: {path}")
            return True
        except Exception as e:
            logger.error(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {path}: {e}")
            return False

    def _should_skip_directory(self, path: Path) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡æŸä¸ªç›®å½•"""
        # ç³»ç»Ÿç›®å½•
        if any(skip_dir in str(path) for skip_dir in self._skip_dirs):
            logger.debug(f"è·³è¿‡ç³»ç»Ÿç›®å½•: {path}")
            return True
        
        # ç”¨æˆ·é…ç½®çš„ç›®å½•
        if any(skip_folder in str(path) for skip_folder in self.settings.skip_folders_list):
            logger.debug(f"è·³è¿‡ç”¨æˆ·é…ç½®çš„ç›®å½•: {path}")
            return True
        
        # æ£€æŸ¥ç”¨æˆ·é…ç½®çš„æ¨¡å¼
        if any(re.search(pattern, str(path)) for pattern in self.settings.skip_patterns_list):
            logger.debug(f"è·³è¿‡åŒ¹é…æ¨¡å¼çš„ç›®å½•: {path}")
            return True
        
        return False

    async def process_directory(self, directory: Path, test_mode: bool = False) -> Dict:
        """å¤„ç†å•ä¸ªç›®å½•çš„å½’æ¡£
        
        Args:
            directory: è¦å½’æ¡£çš„ç›®å½•
            test_mode: æ˜¯å¦ä¸ºæµ‹è¯•æ¨¡å¼ï¼ˆåªè¯†åˆ«ä¸æ‰§è¡Œï¼‰
            
        Returns:
            Dict: å¤„ç†ç»“æœ
        """
        result = {
            "success": False,
            "message": "",
            "moved_files": 0,
            "total_size": 0
        }
        
        try:
            logger.info(f"å¼€å§‹å¤„ç†ç›®å½•: {directory}")
            
            # è·å–ç›¸å¯¹äºæºç›®å½•çš„è·¯å¾„
            source_dir = Path(self.settings.archive_source_root)
            try:
                rel_path = directory.relative_to(source_dir)
                logger.debug(f"- ç›¸å¯¹è·¯å¾„: {rel_path}")
            except ValueError:
                # å¦‚æœä¸æ˜¯source_dirçš„å­ç›®å½•ï¼Œè®°å½•é”™è¯¯å¹¶å°è¯•ä»ç»å¯¹è·¯å¾„è·å–ç›¸å¯¹è·¯å¾„
                logger.warning(f"ç›®å½• {directory} ä¸æ˜¯æºç›®å½• {source_dir} çš„å­ç›®å½•")
                
                # å°è¯•è·å–æœ€åˆé€‚çš„ç›¸å¯¹è·¯å¾„è¡¨ç¤º
                rel_str = str(directory)
                source_str = str(source_dir)
                if rel_str.startswith(source_str):
                    rel_path = Path(rel_str[len(source_str):].lstrip('/'))
                    logger.info(f"- è®¡ç®—çš„ç›¸å¯¹è·¯å¾„: {rel_path}")
                else:
                    rel_path = directory.name
                    logger.warning(f"- æ— æ³•è·å–ç›¸å¯¹è·¯å¾„ï¼Œä½¿ç”¨ç›®å½•å: {rel_path}")
            
            # è·å–æœ€åçš„æ–‡ä»¶å¤¹åç§°
            folder_name = directory.name
            
            # è·å–å®Œæ•´çš„å‰§é›†åç§°ï¼ˆå¦‚æœæ˜¯å­£ç›®å½•ï¼‰
            full_folder_name = folder_name
            parent_dir_name = ""
            
            if re.search(r'(?i)season\s*\d+|s\d+|ç¬¬.+?å­£', folder_name):
                parent_dir = directory.parent
                if parent_dir.name and parent_dir != source_dir:
                    parent_dir_name = parent_dir.name
                    # è®°å½•ç”µè§†å‰§åç§°ç”¨äºæ—¥å¿—
                    logger.debug(f"- ç”µè§†å‰§åç§°: {parent_dir_name}")
                    # æ„å»ºå®Œæ•´çš„æ˜¾ç¤ºåç§°(ä½¿ç”¨ - è€Œä¸æ˜¯ç‰¹æ®Šå­—ç¬¦)
                    full_folder_name = f"{parent_dir_name} - {folder_name}"
            
            # å¤„ç†ç‰¹æ®Šå­—ç¬¦ï¼Œç¡®ä¿è·¯å¾„å®‰å…¨
            safe_folder_name = re.sub(r'[:\\*?\"<>|]', '_', full_folder_name)
            if safe_folder_name != full_folder_name:
                logger.debug(f"- å¤„ç†åçš„å®‰å…¨åç§°: {safe_folder_name}")
            
            # ä½¿ç”¨å¤–éƒ¨è®¾ç½®çš„åª’ä½“ç±»å‹ï¼Œè€Œä¸æ˜¯å°è¯•åŒ¹é…
            media_type = getattr(self, '_current_media_type', None)
            if not media_type:
                result["message"] = (
                    f"[è·³è¿‡] {full_folder_name}\n"
                    f"åŸå› : æœªæŒ‡å®šåª’ä½“ç±»å‹"
                )
                logger.debug(f"ç›®å½• {directory} æœªæŒ‡å®šåª’ä½“ç±»å‹")
                return result
            
            logger.info(f"ä½¿ç”¨åª’ä½“ç±»å‹: {media_type}")
            
            # è·å–é˜ˆå€¼é…ç½®
            threshold = self.thresholds[media_type]
            logger.debug(f"é˜ˆå€¼è®¾ç½®: åˆ›å»ºæ—¶é—´ {threshold.creation_days} å¤©, ä¿®æ”¹æ—¶é—´ {threshold.mtime_days} å¤©")
            
            # åˆå§‹åŒ–è®°å½•æœ€è¿‘æ–‡ä»¶çš„åˆ—è¡¨
            recent_files = []
            
            # æ‰«ææ–‡ä»¶
            logger.debug("å¼€å§‹æ‰«ææ–‡ä»¶æ—¶é—´...")
            
            # é¢„å…ˆç»Ÿè®¡æ–‡ä»¶ä¿¡æ¯
            files_info = []
            total_size = 0
            for root, _, files in os.walk(directory):
                root_path = Path(root)
                for file in files:
                    # æ£€æŸ¥æ–‡ä»¶æ‰©å±•åæ˜¯å¦åœ¨æ’é™¤åˆ—è¡¨ä¸­
                    if any(file.lower().endswith(ext.strip().lower()) for ext in self.excluded_extensions):
                        logger.debug(f"è·³è¿‡æ’é™¤çš„æ–‡ä»¶: {file}")
                        continue
                        
                    file_path = root_path / file
                    stats = file_path.stat()
                    mtime = stats.st_mtime
                    ctime = self.get_creation_time(file_path)
                    
                    # è®¡ç®—æ–‡ä»¶çš„åˆ›å»ºæ—¶é—´å’Œä¿®æ”¹æ—¶é—´è·ä»Šçš„å¤©æ•°
                    mtime_days = (time.time() - mtime) / 86400
                    ctime_days = (time.time() - ctime) / 86400
                    
                    logger.debug(f"æ–‡ä»¶: {file}")
                    logger.debug(f"- åˆ›å»ºæ—¶é—´: {ctime_days:.1f} å¤©å‰")
                    logger.debug(f"- ä¿®æ”¹æ—¶é—´: {mtime_days:.1f} å¤©å‰")
                    
                    # ä½¿ç”¨é…ç½®çš„é˜ˆå€¼
                    if ctime_days < threshold.creation_days or mtime_days < threshold.mtime_days:
                        recent_files.append((file_path, min(mtime_days, ctime_days)))
                        logger.debug(f"- çŠ¶æ€: æœªè¾¾åˆ°é˜ˆå€¼")
                    else:
                        logger.debug(f"- çŠ¶æ€: å·²è¾¾åˆ°é˜ˆå€¼")
                        # è®°å½•éœ€è¦å¤„ç†çš„æ–‡ä»¶ä¿¡æ¯
                        file_size = stats.st_size
                        total_size += file_size
                        files_info.append({
                            "path": file_path,
                            "size": file_size,
                            "relative_path": file_path.relative_to(directory)
                        })
            
            # å¦‚æœæœ‰æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶ï¼Œè®°å½•å¹¶è¿”å›
            if recent_files:
                recent_files.sort(key=lambda x: x[1])  # æŒ‰æ—¶é—´å‡åºæ’åº
                most_recent = recent_files[0]
                days = most_recent[1]
                
                result["message"] = (
                    f"[è·³è¿‡] {full_folder_name}\n"
                    f"åŸå› : å­˜åœ¨æœ€è¿‘æ–‡ä»¶\n"
                    f"æœ€è¿‘æ–‡ä»¶: {most_recent[0].name}\n"
                    f"è·ä»Šæ—¶é—´: {days:.1f} å¤©"
                )
                return result

            # å¦‚æœæ²¡æœ‰æ–‡ä»¶éœ€è¦å¤„ç†ï¼Œè·³è¿‡
            if not files_info:
                result["message"] = (
                    f"[è·³è¿‡] {full_folder_name}\n"
                    f"åŸå› : ç›®å½•ä¸­æ²¡æœ‰éœ€è¦å¤„ç†çš„æ–‡ä»¶"
                )
                return result
            
            # æ„å»ºæºå’Œç›®æ ‡çš„ç›¸å¯¹è·¯å¾„
            # é¦–å…ˆï¼Œç¡®ä¿è·å–çš„æ˜¯ç›¸å¯¹äºsource_rootçš„è·¯å¾„
            source_relative_path = rel_path  # æˆ‘ä»¬åœ¨ä¸Šé¢å·²ç»è®¡ç®—è¿‡rel_pathäº†
            
            # æ„å»ºAlistè·¯å¾„æ—¶ï¼Œä½¿ç”¨æ­£æ–œæ å¹¶ç§»é™¤å¼€å¤´çš„æ–œæ 
            if self.settings.archive_source_alist.endswith('/'):
                source_alist = self.settings.archive_source_alist.rstrip('/')
            else:
                source_alist = self.settings.archive_source_alist
                
            if self.settings.archive_target_root.endswith('/'):
                target_root = self.settings.archive_target_root.rstrip('/')
            else:
                target_root = self.settings.archive_target_root
                
            # ç¡®ä¿ç›¸å¯¹è·¯å¾„ä¸ä»¥æ–œæ å¼€å¤´
            rel_path_str = str(source_relative_path).lstrip('/')
            
            # æ­£ç¡®æ„å»ºå®Œæ•´çš„Alistè·¯å¾„
            source_alist_path = f"{source_alist}/{rel_path_str}".replace('\\', '/').lstrip("/")
            dest_alist_path = f"{target_root}/{rel_path_str}".replace('\\', '/').lstrip("/")
            
            logger.debug(f"- ç›¸å¯¹è·¯å¾„ç”¨äºAlist: {rel_path_str}")
            logger.debug(f"- å®Œæ•´æºAlistè·¯å¾„: {source_alist_path}")
            logger.debug(f"- å®Œæ•´ç›®æ ‡Alistè·¯å¾„: {dest_alist_path}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å­£æ–‡ä»¶å¤¹ï¼Œå¦‚æœæ˜¯åˆ™è®°å½•é¢å¤–ä¿¡æ¯
            if parent_dir_name and re.search(r'(?i)season\s*\d+|s\d+|ç¬¬.+?å­£', folder_name):
                # è®°å½•è¯¦ç»†ä¿¡æ¯ï¼Œæ–¹ä¾¿è°ƒè¯•
                logger.debug(f"- å¤„ç†å­£ç›®å½•è·¯å¾„:")
                logger.debug(f"  - çˆ¶ç›®å½•: {parent_dir_name}")
                logger.debug(f"  - å­£ç›®å½•: {folder_name}")
                logger.debug(f"  - å®Œæ•´åç§°: {full_folder_name}")
                logger.debug(f"  - å®‰å…¨åç§°: {safe_folder_name}")
            
            # ç¡®è®¤è·¯å¾„ä¸åŒ…å«éæ³•å­—ç¬¦ï¼ˆä¸åŒ…æ‹¬æ–œæ ï¼‰
            safe_source_path = re.sub(r'[:\\*?\"<>|]', '_', source_alist_path)
            safe_dest_path = re.sub(r'[:\\*?\"<>|]', '_', dest_alist_path)
            
            if safe_source_path != source_alist_path or safe_dest_path != dest_alist_path:
                logger.warning(f"è·¯å¾„åŒ…å«ç‰¹æ®Šå­—ç¬¦ï¼Œå°†è¢«æ›¿æ¢ï¼ˆä¿ç•™è·¯å¾„åˆ†éš”ç¬¦ï¼‰:")
                logger.warning(f"  åŸå§‹æºè·¯å¾„: {source_alist_path}")
                logger.warning(f"  å®‰å…¨æºè·¯å¾„: {safe_source_path}")
                source_alist_path = safe_source_path
                dest_alist_path = safe_dest_path
            
            logger.info(f"å‡†å¤‡å½’æ¡£: {full_folder_name}")
            logger.debug(f"- æºAlistè·¯å¾„: {source_alist_path}")
            logger.debug(f"- ç›®æ ‡Alistè·¯å¾„: {dest_alist_path}")
            logger.debug(f"- æ–‡ä»¶æ•°é‡: {len(files_info)}")
            logger.debug(f"- æ€»å¤§å°: {total_size / 1024 / 1024 / 1024:.2f} GB")

            if test_mode:
                result["message"] = (
                    f"[æµ‹è¯•] {full_folder_name}\n"
                    f"çŠ¶æ€: å¯ä»¥å½’æ¡£ï¼Œæ— è¿‘æœŸæ–‡ä»¶\n"
                    f"æ–‡ä»¶æ•°: {len(files_info)}\n"
                    f"æ€»å¤§å°: {total_size / 1024 / 1024 / 1024:.2f} GB"
                )
                result["success"] = True
                result["moved_files"] = len(files_info)
                result["total_size"] = total_size
                return result
            
            # ä½¿ç”¨Alist APIå¤åˆ¶ç›®å½•
            logger.info("å¼€å§‹ä½¿ç”¨Alist APIå¤åˆ¶ç›®å½•...")
            
            # è¯¦ç»†è®°å½•æºè·¯å¾„å’Œç›®æ ‡è·¯å¾„ï¼Œä»¥ä¾¿äºè°ƒè¯•
            logger.info(f"æºå®Œæ•´è·¯å¾„: {source_alist_path}")
            logger.info(f"ç›®æ ‡å®Œæ•´è·¯å¾„: {dest_alist_path}")
            
            copy_result = await self.alist_client.copy_directory(source_alist_path, dest_alist_path)
            
            # æ£€æŸ¥å¤åˆ¶ç»“æœ
            if copy_result["success"]:
                # å¤„ç†æ–‡ä»¶å·²å­˜åœ¨çš„æƒ…å†µ
                if copy_result["file_exists"]:
                    logger.info(f"ç›®æ ‡ä½ç½®å·²å­˜åœ¨æ–‡ä»¶: {copy_result['message']}")
                    # å¤„ç†åŒå·²å­˜åœ¨ç›¸åŒ
                    if self.settings.archive_delete_source:
                        self._add_to_pending_deletion(directory)
                        logger.info(f"å·²å°†åŸç›®å½•æ·»åŠ åˆ°å¾…åˆ é™¤é˜Ÿåˆ—: {directory}")
                    
                    result["message"] = (
                        f"[å·²å­˜åœ¨] {full_folder_name}\n"
                        f"æ–‡ä»¶æ•°: {len(files_info)}\n"
                        f"æ€»å¤§å°: {total_size / 1024 / 1024 / 1024:.2f} GB\n"
                        f"ä¿¡æ¯: {copy_result['message']}"
                    )
                    result["success"] = True
                    result["moved_files"] = len(files_info)
                    result["total_size"] = total_size
                    
                    # æ— è®ºæ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼Œéƒ½ç¡®ä¿STRMæ–‡ä»¶å­˜åœ¨
                    try:
                        strm_generated = await self.generate_strm_for_target(dest_alist_path, directory, files_info)
                        if strm_generated:
                            logger.info(f"å·²ç”ŸæˆæŒ‡å‘ç›®æ ‡ç›®å½•çš„STRMæ–‡ä»¶: {dest_alist_path}")
                    except Exception as e:
                        logger.error(f"ç”ŸæˆSTRMæ–‡ä»¶å¤±è´¥: {str(e)}")
                        
                    return result
                
                # æ­£å¸¸å¤åˆ¶æˆåŠŸæƒ…å†µ - ç®€åŒ–é€»è¾‘ï¼Œä¸å†ç­‰å¾…ä»»åŠ¡å®Œæˆå’ŒéªŒè¯æ–‡ä»¶
                logger.info("ç›®å½•å¤åˆ¶è¯·æ±‚æˆåŠŸï¼Œä»»åŠ¡å·²åˆ›å»º")
                result["total_size"] = total_size
                result["moved_files"] = len(files_info)
                
                # ç«‹å³ç”ŸæˆSTRMæ–‡ä»¶ï¼Œä¸ç­‰å¾…å¤åˆ¶å®Œæˆ
                try:
                    strm_generated = await self.generate_strm_for_target(dest_alist_path, directory, files_info)
                    if strm_generated:
                        logger.info(f"å·²ç”ŸæˆæŒ‡å‘ç›®æ ‡ç›®å½•çš„STRMæ–‡ä»¶: {dest_alist_path}")
                except Exception as e:
                    logger.error(f"ç”ŸæˆSTRMæ–‡ä»¶å¤±è´¥: {str(e)}")
                
                # æ·»åŠ åˆ°åˆ é™¤é˜Ÿåˆ—
                if self.settings.archive_delete_source:
                    self._add_to_pending_deletion(directory)
                    logger.info(f"å·²å°†åŸç›®å½•æ·»åŠ åˆ°å¾…åˆ é™¤é˜Ÿåˆ—: {directory}")
                
                result["message"] = (
                    f"[å½’æ¡£] {full_folder_name}\n"
                    f"æ–‡ä»¶æ•°: {len(files_info)}\n"
                    f"æ€»å¤§å°: {total_size / 1024 / 1024 / 1024:.2f} GB"
                )
                
                result["success"] = True
                return result
            else:
                logger.error(f"Alist APIå¤åˆ¶ç›®å½•å¤±è´¥: {copy_result['message']}")
                result["message"] = f"[é”™è¯¯] {full_folder_name}\nå¤åˆ¶å¤±è´¥\næºè·¯å¾„: {source_alist_path}\nç›®æ ‡è·¯å¾„: {dest_alist_path}\nè¯¦æƒ…: {copy_result['message']}"
            
        except Exception as e:
            result["message"] = f"[é”™è¯¯] å½’æ¡£å¤±è´¥ {full_folder_name}: {str(e)}"
            logger.error(f"å¤„ç†ç›®å½•å¤±è´¥ {directory}: {e}", exc_info=True)
            
        return result
    
    async def generate_strm_for_target(self, target_alist_path: str, source_directory: Path, files_info: list) -> bool:
        """æ ¹æ®ç›®æ ‡Alistè·¯å¾„ç”ŸæˆSTRMæ–‡ä»¶ï¼Œä¸ç­‰å¾…å¤åˆ¶å®Œæˆ
        
        Args:
            target_alist_path: ç›®æ ‡Alistè·¯å¾„
            source_directory: æºç›®å½•Pathå¯¹è±¡
            files_info: æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸç”ŸæˆSTRMæ–‡ä»¶
        """
        try:
            logger.info(f"ç«‹å³ä¸ºç›®æ ‡è·¯å¾„ç”ŸæˆSTRMæ–‡ä»¶: {target_alist_path}")
            service_manager = self._get_service_manager()
            strm_service = service_manager.strm_service
            
            # è·å–ç›¸å¯¹è·¯å¾„
            source_rel_path = source_directory.relative_to(self.settings.archive_source_root)
            
            # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆä¸åŸå§‹strm_serviceä¿æŒä¸€è‡´ï¼‰- ç¡®ä¿ä¿ç•™ç›®å½•ç»“æ„
            output_base_dir = strm_service.settings.output_dir
            output_rel_dir = str(source_rel_path)
            output_dir = os.path.join(output_base_dir, output_rel_dir)
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(output_dir, exist_ok=True)
            
            # ç»Ÿè®¡å¤„ç†æ–‡ä»¶æ•°
            strm_count = 0
            generated_strm_files = []
            
            # éå†æ–‡ä»¶åˆ—è¡¨ï¼Œä¸ºæ¯ä¸ªè§†é¢‘æ–‡ä»¶ç”Ÿæˆstrm
            for file_info in files_info:
                file_path = file_info["path"]
                filename = file_path.name
                
                # åªå¤„ç†è§†é¢‘æ–‡ä»¶
                if not strm_service._is_video_file(filename):
                    continue
                    
                # æ£€æŸ¥æ–‡ä»¶å¤§å°
                if file_info.get("size", 0) < strm_service.settings.min_file_size * 1024 * 1024:
                    logger.debug(f"è·³è¿‡å°è§†é¢‘æ–‡ä»¶: {filename}")
                    continue
                    
                # æ„å»ºç›¸å¯¹è·¯å¾„
                rel_file_path = str(file_info["relative_path"]).replace('\\', '/')
                
                # æ„å»ºå®Œæ•´çš„ç›®æ ‡Alistè·¯å¾„ï¼ˆä¸ç¼–ç ï¼‰
                # æ£€æŸ¥è·¯å¾„ä¸­æ˜¯å¦å·²åŒ…å«æ–‡ä»¶åï¼Œé¿å…é‡å¤
                filename = os.path.basename(rel_file_path)
                target_path_dir = os.path.dirname(target_alist_path)
                if os.path.basename(target_alist_path) == filename:
                    # ç›®æ ‡è·¯å¾„å·²åŒ…å«æ–‡ä»¶åï¼Œä¸éœ€è¦å†æ·»åŠ 
                    target_file_path = target_alist_path
                else:
                    target_file_path = f"{target_alist_path}/{rel_file_path}"
                
                logger.debug(f"åŸå§‹ç›®æ ‡æ–‡ä»¶è·¯å¾„: {target_file_path}")
                
                # ä»æ–‡ä»¶åä¸­è·å–åŸºæœ¬åç§°ï¼ˆä¸åŒ…å«æ‰©å±•åï¼‰
                output_base_name = os.path.splitext(filename)[0]
                
                # ç›´æ¥åœ¨å½“å‰ç›®å½•ä¸‹ç”ŸæˆSTRMæ–‡ä»¶ï¼Œä¸åˆ›å»ºé¢å¤–çš„å­ç›®å½•
                strm_path = os.path.join(output_dir, f"{output_base_name}.strm")
                
                # æ„å»ºstrmæ–‡ä»¶å†…å®¹ - æ ¹æ®å…¨å±€ç¼–ç è®¾ç½®å†³å®šæ˜¯å¦è¿›è¡ŒURLç¼–ç 
                from urllib.parse import quote
                if not target_file_path.startswith('/'):
                    path_for_url = '/' + target_file_path
                else:
                    path_for_url = target_file_path
                
                # æ ¹æ®å…¨å±€è®¾ç½®å†³å®šæ˜¯å¦è¿›è¡ŒURLç¼–ç 
                if strm_service.settings.encode:
                    # è¿›è¡ŒURLç¼–ç ï¼Œä½†ä¿ç•™è·¯å¾„åˆ†éš”ç¬¦
                    encoded_path = quote(path_for_url)
                    strm_url = f"{strm_service.settings.alist_url}/d{encoded_path}"
                    logger.debug(f"å·²ç¼–ç çš„STRM URL: {strm_url}")
                else:
                    # ä¸è¿›è¡ŒURLç¼–ç 
                    strm_url = f"{strm_service.settings.alist_url}/d{path_for_url}"
                    logger.debug(f"æœªç¼–ç çš„STRM URL: {strm_url}")
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ä¸”å†…å®¹ç›¸åŒ
                if os.path.exists(strm_path):
                    try:
                        with open(strm_path, 'r', encoding='utf-8') as f:
                            existing_content = f.read().strip()
                        if existing_content == strm_url:
                            logger.debug(f"STRMæ–‡ä»¶å·²å­˜åœ¨ä¸”å†…å®¹ç›¸åŒ: {strm_path}")
                            continue
                    except Exception as e:
                        logger.warning(f"è¯»å–ç°æœ‰STRMæ–‡ä»¶å¤±è´¥: {str(e)}")
                
                # å†™å…¥strmæ–‡ä»¶
                with open(strm_path, 'w', encoding='utf-8') as f:
                    f.write(strm_url)
                
                logger.info(f"å·²åˆ›å»ºSTRMæ–‡ä»¶: {strm_path}")
                strm_count += 1
                
                # å°†STRMæ–‡ä»¶æ·»åŠ åˆ°å¥åº·çŠ¶æ€æœåŠ¡
                service_manager.health_service.add_strm_file(strm_path, target_file_path)
                
                # è®°å½•ç”Ÿæˆçš„STRMæ–‡ä»¶è·¯å¾„ï¼Œç”¨äºåç»­æ·»åŠ åˆ°åˆ·æ–°é˜Ÿåˆ—
                generated_strm_files.append(strm_path)
            
            # å°†ç”Ÿæˆçš„STRMæ–‡ä»¶æ·»åŠ åˆ°Embyåˆ·æ–°é˜Ÿåˆ—
            if generated_strm_files and hasattr(service_manager, 'emby_service') and service_manager.emby_service:
                for strm_path in generated_strm_files:
                    service_manager.emby_service.add_to_refresh_queue(strm_path)
                logger.info(f"å·²å°† {len(generated_strm_files)} ä¸ªSTRMæ–‡ä»¶æ·»åŠ åˆ°Embyåˆ·æ–°é˜Ÿåˆ—")
            
            logger.info(f"æˆåŠŸç”Ÿæˆ {strm_count} ä¸ªSTRMæ–‡ä»¶ï¼ŒæŒ‡å‘ç›®æ ‡è·¯å¾„: {target_alist_path}")
            return strm_count > 0
            
        except Exception as e:
            logger.error(f"ç”ŸæˆSTRMæ–‡ä»¶å¤±è´¥: {str(e)}", exc_info=True)
            return False

    def _load_media_types(self) -> Dict[str, Dict]:
        """ä»config/archive.jsonåŠ è½½åª’ä½“ç±»å‹é…ç½®"""
        config_file = "config/archive.json"
        if os.path.exists(config_file):
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"åŠ è½½åª’ä½“ç±»å‹é…ç½®å¤±è´¥: {e}")
        return json.loads(self.settings.archive_media_types)

    def save_media_types(self):
        """ä¿å­˜åª’ä½“ç±»å‹é…ç½®åˆ°config/archive.json"""
        config_file = "config/archive.json"
        try:
            # ç¡®ä¿configç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(config_file), exist_ok=True)
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(self.media_types, f, ensure_ascii=False, indent=4)
            logger.info("åª’ä½“ç±»å‹é…ç½®å·²ä¿å­˜")
        except Exception as e:
            logger.error(f"ä¿å­˜åª’ä½“ç±»å‹é…ç½®å¤±è´¥: {e}")
            
    @property
    def media_types(self) -> Dict[str, Dict]:
        return self._media_types
        
    @media_types.setter
    def media_types(self, value: Dict[str, Dict]):
        # éªŒè¯æ•°æ®ç»“æ„
        processed_value = {}
        try:
            # éå†å¹¶éªŒè¯æ¯ä¸ªåª’ä½“ç±»å‹
            for name, info in value.items():
                if not isinstance(info, dict):
                    logger.warning(f"åª’ä½“ç±»å‹'{name}'çš„é…ç½®ä¸æ˜¯å­—å…¸ç±»å‹ï¼Œè·³è¿‡")
                    continue
                    
                # ç¡®ä¿å¿…é¡»çš„å­—æ®µå­˜åœ¨
                if "dir" not in info or "creation_days" not in info or "mtime_days" not in info:
                    logger.warning(f"åª’ä½“ç±»å‹'{name}'ç¼ºå°‘å¿…è¦å­—æ®µï¼Œä½¿ç”¨é»˜è®¤å€¼")
                    dir_value = info.get("dir", "")
                    creation_days = info.get("creation_days", 30)
                    mtime_days = info.get("mtime_days", 7)
                else:
                    dir_value = info["dir"]
                    # ç¡®ä¿æ˜¯æ•°å€¼ç±»å‹
                    try:
                        creation_days = int(float(info["creation_days"]))
                        mtime_days = int(float(info["mtime_days"]))
                    except (ValueError, TypeError):
                        logger.warning(f"åª’ä½“ç±»å‹'{name}'çš„å¤©æ•°å€¼æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤å€¼")
                        creation_days = 30
                        mtime_days = 7
                
                # åˆ›å»ºå¤„ç†åçš„é…ç½®
                processed_value[name] = {
                    "dir": str(dir_value),
                    "creation_days": creation_days,
                    "mtime_days": mtime_days
                }
                
            # è®¾ç½®å¤„ç†åçš„å€¼
            self._media_types = processed_value
            
            # æ›´æ–°é˜ˆå€¼é…ç½®
            self.thresholds = {
                name: MediaThreshold(
                    info["creation_days"],
                    info["mtime_days"]
                ) for name, info in self._media_types.items()
            }
                
            # è®°å½•æ›´æ–°ä¿¡æ¯
            logger.info(f"å·²æ›´æ–°åª’ä½“ç±»å‹é…ç½®ï¼Œå…±{len(self._media_types)}ä¸ªç±»å‹")
            
            # è‡ªåŠ¨ä¿å­˜åˆ°æ–‡ä»¶
            self.save_media_types()
        except Exception as e:
            logger.error(f"è®¾ç½®åª’ä½“ç±»å‹é…ç½®å¤±è´¥: {str(e)}", exc_info=True)
            raise

    async def process_file(self, source_path: Path) -> Dict:
        """å¤„ç†å•ä¸ªæ–‡ä»¶çš„å½’æ¡£
        
        Args:
            source_path: æºæ–‡ä»¶è·¯å¾„
            
        Returns:
            Dict: å¤„ç†ç»“æœï¼ŒåŒ…å«successã€messageå’Œsizeå­—æ®µ
        """
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æ˜¯æ–‡ä»¶
            if not source_path.is_file():
                return {
                    "success": False,
                    "message": f"âŒ {source_path} ä¸æ˜¯æ–‡ä»¶",
                    "size": 0
                }
            
            # è·å–æ–‡ä»¶å¤§å°
            file_size = source_path.stat().st_size
            
            # ä½¿ç”¨å½“å‰åª’ä½“ç±»å‹
            media_type = getattr(self, '_current_media_type', None)
            if not media_type:
                return {
                    "success": False,
                    "message": f"âŒ {source_path} æœªæŒ‡å®šåª’ä½“ç±»å‹",
                    "size": 0
                }
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ»¡è¶³é˜ˆå€¼æ¡ä»¶
            creation_time = self.get_creation_time(source_path)
            mtime = source_path.stat().st_mtime
            
            threshold = self.thresholds[media_type]
            creation_days = (time.time() - creation_time) / (24 * 3600)
            mtime_days = (time.time() - mtime) / (24 * 3600)
            
            if creation_days < threshold.creation_days or mtime_days < threshold.mtime_days:
                return {
                    "success": False,
                    "message": f"â³ {source_path} æœªè¾¾åˆ°å½’æ¡£é˜ˆå€¼",
                    "size": 0
                }
            
            # æ„å»ºç›®æ ‡è·¯å¾„ï¼Œä¿æŒç›¸å¯¹è·¯å¾„ç»“æ„
            try:
                relative_path = source_path.relative_to(self.settings.archive_source_root)
            except ValueError:
                # å¦‚æœä¸æ˜¯source_dirçš„å­ç›®å½•ï¼Œå°è¯•ä»ç»å¯¹è·¯å¾„è·å–ç›¸å¯¹è·¯å¾„
                rel_str = str(source_path)
                source_str = str(self.settings.archive_source_root)
                if rel_str.startswith(source_str):
                    relative_path = Path(rel_str[len(source_str):].lstrip('/'))
                else:
                    # æ— æ³•è·å–ç›¸å¯¹è·¯å¾„æ—¶ï¼Œè¿”å›é”™è¯¯
                    return {
                        "success": False,
                        "message": f"âŒ {source_path} ä¸åœ¨æºç›®å½• {self.settings.archive_source_root} ä¸­",
                        "size": 0
                    }
            
            # å¤„ç†ç›¸å¯¹è·¯å¾„ï¼Œç¡®ä¿ä¸ä»¥æ–œæ å¼€å¤´
            rel_path_str = str(relative_path).lstrip('/')
            
            # æ„å»ºdest_pathç”¨äºæ˜¾ç¤ºå’ŒéªŒè¯
            dest_path = Path(self.settings.archive_target_root) / relative_path
            
            # å‡†å¤‡Alistè·¯å¾„éƒ¨åˆ†
            if self.settings.archive_source_alist.endswith('/'):
                source_alist = self.settings.archive_source_alist.rstrip('/')
            else:
                source_alist = self.settings.archive_source_alist
                
            if self.settings.archive_target_root.endswith('/'):
                target_root = self.settings.archive_target_root.rstrip('/')
            else:
                target_root = self.settings.archive_target_root
            
            # æ„å»ºAlistè·¯å¾„ï¼ˆä¿æŒä¸process_directoryä¸€è‡´ï¼‰
            source_alist_path = f"{source_alist}/{rel_path_str}".replace('\\', '/').lstrip("/")
            dest_alist_path = f"{target_root}/{rel_path_str}".replace('\\', '/').lstrip("/")
            
            logger.debug(f"- æºæ–‡ä»¶è·¯å¾„: {source_path}")
            logger.debug(f"- ç›®æ ‡æ–‡ä»¶è·¯å¾„: {dest_path}")
            logger.debug(f"- æºAlistè·¯å¾„: {source_alist_path}")
            logger.debug(f"- ç›®æ ‡Alistè·¯å¾„: {dest_alist_path}")
            
            # ä½¿ç”¨Alist APIå¤åˆ¶æ–‡ä»¶
            copy_result = await self.alist_client.copy_file(source_alist_path, dest_alist_path)

            # æ£€æŸ¥å¤åˆ¶ç»“æœ
            if not copy_result["success"]:
                return {
                    "success": False,
                    "message": f"âŒ {source_path} å¤åˆ¶å¤±è´¥: {copy_result['message']}",
                    "size": 0
                }
                
            # å¤„ç†æ–‡ä»¶å·²å­˜åœ¨çš„æƒ…å†µ
            if copy_result["file_exists"]:
                logger.info(f"ç›®æ ‡ä½ç½®å·²å­˜åœ¨æ–‡ä»¶: {copy_result['message']}")
                # å¦‚æœé…ç½®äº†åˆ é™¤æºæ–‡ä»¶
                if self.settings.archive_delete_source:
                    self._add_to_pending_deletion(source_path)
                    return {
                        "success": True,
                        "message": f"ğŸ—‘ï¸ {source_path} å·²å­˜åœ¨äºç›®æ ‡ä½ç½®ï¼Œå·²åŠ å…¥å»¶è¿Ÿåˆ é™¤é˜Ÿåˆ—",
                        "size": file_size
                    }
                return {
                    "success": False,
                    "message": f"â­ï¸ {source_path} å·²å­˜åœ¨äºç›®æ ‡ä½ç½®",
                    "size": 0
                }
            
            # éªŒè¯å¤åˆ¶åçš„æ–‡ä»¶
            if not self.verify_files(source_path, dest_path):
                # å¦‚æœéªŒè¯å¤±è´¥ï¼Œåˆ é™¤ç›®æ ‡æ–‡ä»¶
                try:
                    await self.alist_client.delete(dest_alist_path)
                except Exception as e:
                    logger.error(f"åˆ é™¤å¤±è´¥çš„ç›®æ ‡æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                    
                return {
                    "success": False,
                    "message": f"âŒ {source_path} å¤åˆ¶éªŒè¯å¤±è´¥",
                    "size": 0
                }
            
            # å¦‚æœé…ç½®äº†åˆ é™¤æºæ–‡ä»¶
            if self.settings.archive_delete_source:
                self._add_to_pending_deletion(source_path)
                return {
                    "success": True,
                    "message": f"âœ… {source_path} -> {dest_path} (å·²åŠ å…¥å»¶è¿Ÿåˆ é™¤é˜Ÿåˆ—)",
                    "size": file_size
                }
            
            return {
                "success": True,
                "message": f"âœ… {source_path} -> {dest_path}",
                "size": file_size
            }
            
        except Exception as e:
            logger.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥ {source_path}: {e}")
            return {
                "success": False,
                "message": f"âŒ {source_path} å¤„ç†å¤±è´¥: {str(e)}",
                "size": 0
            }

    async def archive(self, test_mode: bool = False):
        """æ‰§è¡Œå½’æ¡£å¤„ç†
        
        Args:
            test_mode: æ˜¯å¦ä¸ºæµ‹è¯•æ¨¡å¼ï¼ˆåªè¯†åˆ«ä¸æ‰§è¡Œï¼‰
            
        Returns:
            Dict: å¤„ç†ç»“æœæ‘˜è¦å’Œè¯¦æƒ…
        """
        if self._is_running:
            logger.warning("å½’æ¡£ä»»åŠ¡å·²åœ¨è¿è¡Œä¸­")
            return {
                "summary": "å½’æ¡£ä»»åŠ¡å·²åœ¨è¿è¡Œä¸­",
                "total_processed": 0,
                "total_size": 0,
                "results": []
            }
            
        try:
            self._stop_flag = False
            self._is_running = True
            
            service_manager = self._get_service_manager()
            
            # åˆå§‹åŒ–ç»“æœå˜é‡
            total_processed = 0
            total_size = 0
            success_results = []
            all_results = []  # ä¿å­˜æ‰€æœ‰å¤„ç†ç»“æœ
            
            # åœ¨å¼€å§‹å½’æ¡£æ—¶å‘é€Telegramé€šçŸ¥
            start_msg = "ğŸ” å¼€å§‹å½’æ¡£æµ‹è¯•..." if test_mode else "ğŸš€ å¼€å§‹å½’æ¡£å¤„ç†..."
            logger.info(start_msg)
            await service_manager.telegram_service.send_message(start_msg)
            
            # æ£€æŸ¥é…ç½®
            logger.debug(f"å½“å‰é…ç½®:")
            logger.debug(f"- æœ¬åœ°æºç›®å½•: {self.settings.archive_source_root}")
            logger.debug(f"- Alistæºç›®å½•: {self.settings.archive_source_alist}")
            logger.debug(f"- ç›®æ ‡ç›®å½•: {self.settings.archive_target_root}")
            
            # ç¡®ä¿æºç›®å½•æ˜¯ç»å¯¹è·¯å¾„
            source_dir = Path(self.settings.archive_source_root)
            if not source_dir.is_absolute():
                logger.warning(f"æºç›®å½•ä¸æ˜¯ç»å¯¹è·¯å¾„: {source_dir}")
                # å°è¯•è·å–ç»å¯¹è·¯å¾„
                source_dir = source_dir.absolute()
                logger.info(f"å·²è½¬æ¢ä¸ºç»å¯¹è·¯å¾„: {source_dir}")
                
            if not source_dir.exists():
                error_msg = f"æœ¬åœ°æºç›®å½•ä¸å­˜åœ¨: {source_dir}"
                logger.error(error_msg)
                await service_manager.telegram_service.send_message(f"âŒ {error_msg}")
                return {
                    "summary": error_msg,
                    "total_processed": 0,
                    "total_size": 0,
                    "results": []
                }
            
            # æ£€æŸ¥ç›®å½•æƒé™
            try:
                test_file = source_dir / ".archive_test"
                test_file.touch()
                test_file.unlink()
            except Exception as e:
                error_msg = f"æœ¬åœ°æºç›®å½•æƒé™æ£€æŸ¥å¤±è´¥: {source_dir}, é”™è¯¯: {str(e)}"
                logger.error(error_msg)
                await service_manager.telegram_service.send_message(f"âŒ {error_msg}")
                return {
                    "summary": error_msg,
                    "total_processed": 0,
                    "total_size": 0,
                    "results": []
                }
            
            # ç›´æ¥å¤„ç†é…ç½®çš„åª’ä½“ç±»å‹ç›®å½•
            for media_type, config in self.media_types.items():
                if self._stop_flag:
                    break
                
                # è·å–è¯¥åª’ä½“ç±»å‹çš„ç›®å½•é…ç½®
                media_dir = config.get('dir', '')
                if not media_dir:
                    logger.warning(f"åª’ä½“ç±»å‹ '{media_type}' æœªé…ç½®ç›®å½•ï¼Œè·³è¿‡")
                    continue
                
                # æ„å»ºå®Œæ•´çš„åª’ä½“ç±»å‹ç›®å½•è·¯å¾„
                media_path = None
                # åˆ é™¤ç»å¯¹è·¯å¾„çš„åˆ¤æ–­ï¼Œå°†æ‰€æœ‰è·¯å¾„éƒ½è§†ä¸ºç›¸å¯¹è·¯å¾„
                # å³ä½¿ä»¥/å¼€å¤´çš„è·¯å¾„ä¹Ÿè¢«è§†ä¸ºç›¸å¯¹è·¯å¾„
                if media_dir.startswith('/'):
                    # ç§»é™¤å¼€å¤´çš„æ–œæ ï¼Œä»¥ä¾¿ä¸source_diræ­£ç¡®æ‹¼æ¥
                    media_dir = media_dir.lstrip('/')
                    logger.info(f"åª’ä½“ç±»å‹ '{media_type}' è·¯å¾„ä»¥/å¼€å¤´ï¼Œå·²å¤„ç†ä¸ºç›¸å¯¹è·¯å¾„: {media_dir}")
                
                # ä¸æºç›®å½•æ‹¼æ¥
                media_path = source_dir / media_dir
                logger.info(f"åª’ä½“ç±»å‹ '{media_type}' æœ€ç»ˆè·¯å¾„: {media_path}")
                
                if not media_path.exists():
                    logger.warning(f"åª’ä½“ç±»å‹ '{media_type}' çš„ç›®å½•ä¸å­˜åœ¨: {media_path}")
                    continue
                
                logger.info(f"å¼€å§‹å¤„ç†åª’ä½“ç±»å‹ '{media_type}' çš„ç›®å½•: {media_path}")
                
                # è®¾ç½®è¯¥åª’ä½“ç±»å‹çš„é˜ˆå€¼
                threshold = self.thresholds.get(media_type)
                if not threshold:
                    logger.warning(f"åª’ä½“ç±»å‹ '{media_type}' æ²¡æœ‰å¯¹åº”çš„é˜ˆå€¼é…ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                    threshold = MediaThreshold(30, 7)  # é»˜è®¤å€¼
                
                logger.debug(f"- é˜ˆå€¼è®¾ç½®: åˆ›å»ºæ—¶é—´ {threshold.creation_days} å¤©, ä¿®æ”¹æ—¶é—´ {threshold.mtime_days} å¤©")
                
                # éå†å½“å‰åª’ä½“ç±»å‹ç›®å½•ä¸‹çš„æ‰€æœ‰å­ç›®å½•
                for sub_path in media_path.glob("**/*"):
                    if self._stop_flag:
                        break
                    
                    # åªå¤„ç†ç›®å½•
                    if not sub_path.is_dir():
                        continue
                    
                    # è·å–è¯¥ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ï¼ˆéé€’å½’ï¼‰
                    files = [f for f in sub_path.iterdir() if f.is_file()]
                    
                    # å¦‚æœç›®å½•åŒ…å«æ–‡ä»¶
                    if files:
                        # è®°å½•è¯¦ç»†ä¿¡æ¯ï¼Œæ–¹ä¾¿è°ƒè¯•
                        logger.debug(f"\nå¤„ç†ç›®å½•: {sub_path}")
                        logger.debug(f"- åŒ…å«æ–‡ä»¶æ•°: {len(files)}")
                        
                        # åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„å¤„ç†ä¸Šä¸‹æ–‡ï¼ŒåŒ…å«åª’ä½“ç±»å‹ä¿¡æ¯
                        self._current_media_type = media_type
                        
                        # å¤„ç†ç›®å½•
                        result = await self.process_directory(sub_path, test_mode)

                        # æ¸…é™¤ä¸´æ—¶ä¸Šä¸‹æ–‡
                        self._current_media_type = None
                        
                        if result["success"]:
                            total_processed += result["moved_files"]
                            total_size += result["total_size"]
                            if "[å½’æ¡£]" in result["message"]:
                                success_results.append(result["message"])
                        
                        # æ— è®ºæ˜¯å¦æˆåŠŸï¼Œéƒ½æ·»åŠ åˆ°æ‰€æœ‰ç»“æœä¸­
                        all_results.append(result)
                    
                    # è®©å‡ºæ§åˆ¶æƒ
                    await asyncio.sleep(0)
            
            # ç”Ÿæˆæ±‡æ€»æ¶ˆæ¯
            summary = (
                f"âœ… å½’æ¡£{'æµ‹è¯•' if test_mode else ''}å®Œæˆ\n"
                f"ğŸ“ {'è¯†åˆ«' if test_mode else 'å¤„ç†'}æ–‡ä»¶: {total_processed} ä¸ª\n"
                f"ğŸ’¾ æ€»å¤§å°: {total_size / 1024 / 1024 / 1024:.2f} GB"
            )
            logger.info(summary)
            
            # å‘é€æœ€ç»ˆçš„æ±‡æ€»æ¶ˆæ¯åˆ°Telegram
            await service_manager.telegram_service.send_message(summary)
            
            # å¦‚æœæœ‰æˆåŠŸå½’æ¡£çš„ç»“æœï¼Œå•ç‹¬å‘é€åˆ°Telegram
            if success_results:
                # æ ¼å¼åŒ–æ¯ä¸ªç»“æœï¼Œå¢å¼ºç”µè§†å‰§ç›®å½•çš„æ˜¾ç¤º
                formatted_results = []
                for result in success_results:
                    # ä»ç»“æœæ¶ˆæ¯ä¸­æå–ç›¸å…³ä¿¡æ¯
                    folder_name = ""
                    file_count = 0
                    total_size_gb = 0.0
                    
                    # æå– [å½’æ¡£] åé¢çš„æ–‡ä»¶å¤¹åç§°
                    if folder_match := re.search(r'\[å½’æ¡£\] ([^\n]+)', result):
                        folder_name = folder_match.group(1)
                    
                    # æå–æ–‡ä»¶æ•°é‡
                    if files_match := re.search(r'æ–‡ä»¶æ•°: (\d+)', result):
                        file_count = int(files_match.group(1))
                    
                    # æå–æ–‡ä»¶å¤§å°
                    if size_match := re.search(r'æ€»å¤§å°: ([0-9.]+) GB', result):
                        total_size_gb = float(size_match.group(1))
                    
                    # æŸ¥æ‰¾è¯¥æ–‡ä»¶å¤¹å¯¹åº”çš„å‰§é›†ä¿¡æ¯
                    show_name = ""
                    for log_entry in self.logger_history:
                        if f"å¼€å§‹å¤„ç†ç›®å½•" in log_entry and folder_name in log_entry:
                            # æ‰¾åˆ°äº†å¤„ç†è¯¥ç›®å½•çš„æ—¥å¿—ï¼ŒæŸ¥æ‰¾åç»­çš„ç”µè§†å‰§åç§°
                            index = self.logger_history.index(log_entry)
                            # æŸ¥æ‰¾åé¢å‡ æ¡æ—¥å¿—ä¸­æ˜¯å¦æœ‰ç”µè§†å‰§åç§°
                            for i in range(index, min(index + 5, len(self.logger_history))):
                                if "ç”µè§†å‰§åç§°" in self.logger_history[i]:
                                    show_name_match = re.search(r'- ç”µè§†å‰§åç§°: (.+)', self.logger_history[i])
                                    if show_name_match:
                                        show_name = show_name_match.group(1)
                                        break
                            break
                    
                    # æ„å»ºæ ¼å¼åŒ–çš„ç»“æœå­—ç¬¦ä¸²
                    if show_name and ("Season" in folder_name or "season" in folder_name):
                        # è¿™æ˜¯ä¸€ä¸ªç”µè§†å‰§å­£æ–‡ä»¶å¤¹ï¼Œæ˜¾ç¤ºå‰§åå’Œå­£ä¿¡æ¯
                        formatted_results.append(f"{show_name} - {folder_name} ({file_count}ä¸ªæ–‡ä»¶, {total_size_gb:.2f} GB)")
                    else:
                        # å…¶ä»–æ–‡ä»¶å¤¹ï¼Œåªæ˜¾ç¤ºæ–‡ä»¶å¤¹å
                        formatted_results.append(f"{folder_name} ({file_count}ä¸ªæ–‡ä»¶, {total_size_gb:.2f} GB)")
                
                success_message = "å½’æ¡£æˆåŠŸçš„æ–‡ä»¶å¤¹:\n\n" + "\n".join(formatted_results)
                # å¦‚æœæ¶ˆæ¯å¤ªé•¿ï¼Œåªä¿ç•™å‰20ä¸ªç»“æœ
                if len(success_message) > 3000:
                    formatted_results = formatted_results[:20]
                    success_message = "å½’æ¡£æˆåŠŸçš„æ–‡ä»¶å¤¹ï¼ˆä»…æ˜¾ç¤ºå‰20ä¸ªï¼‰:\n\n" + "\n".join(formatted_results)
                await service_manager.telegram_service.send_message(success_message)
            
            # å¦‚æœé…ç½®äº†è‡ªåŠ¨è¿è¡ŒSTRMæ‰«æä¸”ä¸æ˜¯æµ‹è¯•æ¨¡å¼
            if not test_mode and self.settings.archive_auto_strm and total_processed > 0:
                logger.info("å¼€å§‹è‡ªåŠ¨STRMæ‰«æ...")
                await service_manager.telegram_service.send_message("ğŸ”„ å¼€å§‹è‡ªåŠ¨STRMæ‰«æ...")
                await service_manager.strm_service.strm()
            
            # è¿”å›ç»“æœ
            return {
                "summary": summary,
                "total_processed": total_processed,
                "total_size": total_size,
                "results": all_results  # ä¿®æ”¹ï¼šæ— è®ºæ˜¯æµ‹è¯•æ¨¡å¼è¿˜æ˜¯æ­£å¸¸æ¨¡å¼ï¼Œéƒ½è¿”å›å®Œæ•´ç»“æœ
            }
            
        except Exception as e:
            error_msg = f"âŒ å½’æ¡£{'æµ‹è¯•' if test_mode else 'å¤„ç†'}å‡ºé”™: {str(e)}"
            logger.error(error_msg)
            service_manager = self._get_service_manager()
            await service_manager.telegram_service.send_message(error_msg)
            return {
                "summary": error_msg,
                "total_processed": 0,
                "total_size": 0,
                "results": []
            }
        finally:
            self._is_running = False 